{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f822da8",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2c1d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import matplotlib\n",
    "import geopandas as gpd\n",
    "from datetime import datetime, timedelta\n",
    "import jenkspy\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da76f80b",
   "metadata": {},
   "source": [
    "# Define country and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97c8461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select target country\n",
    "country = 'Colombia'\n",
    "\n",
    "# Set country-specific parameters: ISO codes and buffer size (in meters)\n",
    "if country == 'Argentina':\n",
    "    country_short = 'ARG'   # ISO 3-letter code\n",
    "    country_code = 'AR'     # ISO 2-letter code\n",
    "elif country == 'Chile':\n",
    "    country_short = 'CHL'\n",
    "    country_code = 'CL'\n",
    "elif country == 'Colombia':\n",
    "    country_short = 'COL'\n",
    "    country_code = 'CO'\n",
    "# Uncomment the following if Mexico is to be included in the analysis\n",
    "# elif country == 'Mexico':\n",
    "#     country_short = 'MEX'\n",
    "#     country_code = 'MX'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8481d539",
   "metadata": {},
   "source": [
    "# Set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819ea10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define working directory path\n",
    "wd = (\n",
    "#     '/your/path/to/working/directory/'\n",
    "    '/Users/carmen/Library/CloudStorage/OneDrive-TheUniversityofLiverpool/research/latin-mobility-covid'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba47785",
   "metadata": {},
   "source": [
    "# Choose category type: density or rdi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed52b73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change to 'density' or 'rdi' or 'old'\n",
    "category = 'old'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae045d8",
   "metadata": {},
   "source": [
    "# Is stringenty index used as predictor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faef6a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "stringency = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58b76ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if stringency == True:\n",
    "    df = pd.read_csv(wd + '/data/outputs/' + country_short + '/mov-analysis/by-' + category + '/data_trend_outflows_param_tidy_results_os_new.csv')\n",
    "    df_m3_re = pd.read_csv(wd + '/data/outputs/' + country_short + '/mov-analysis/by-' + category + '/data_trend_param_quad_m3os_re_new.csv')\n",
    "    df_m4_re = pd.read_csv(wd + '/data/outputs/' + country_short + '/mov-analysis/by-' + category + '/data_trend_param_quad_m4os_re_new.csv')\n",
    "    df_m5_re = pd.read_csv(wd + '/data/outputs/' + country_short + '/mov-analysis/by-' + category + '/data_trend_param_quad_m5os_re_new.csv')\n",
    "    df_m6_re = pd.read_csv(wd + '/data/outputs/' + country_short + '/mov-analysis/by-' + category + '/data_trend_param_quad_m6os_re_new.csv')\n",
    "    df_m7_re = pd.read_csv(wd + '/data/outputs/' + country_short + '/mov-analysis/by-' + category + '/data_trend_param_quad_m7os_re_new.csv')\n",
    "\n",
    "else:\n",
    "    df = pd.read_csv(wd + '/data/outputs/' + country_short + '/mov-analysis/by-' + category + '/data_trend_outflows_param_tidy_results_o_new.csv')\n",
    "    df_m3_re = pd.read_csv(wd + '/data/outputs/' + country_short + '/mov-analysis/by-' + category + '/data_trend_param_quad_m3o_re_new.csv')\n",
    "    df_m4_re = pd.read_csv(wd + '/data/outputs/' + country_short + '/mov-analysis/by-' + category + '/data_trend_param_quad_m4o_re_new.csv')\n",
    "    df_m5_re = pd.read_csv(wd + '/data/outputs/' + country_short + '/mov-analysis/by-' + category + '/data_trend_param_quad_m5o_re_new.csv')\n",
    "    df_m6_re = pd.read_csv(wd + '/data/outputs/' + country_short + '/mov-analysis/by-' + category + '/data_trend_param_quad_m6o_re_new.csv')\n",
    "    df_m7_re = pd.read_csv(wd + '/data/outputs/' + country_short + '/mov-analysis/by-' + category + '/data_trend_param_quad_m7o_re_new.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e5371e",
   "metadata": {},
   "source": [
    "# Select model\n",
    "Choose between Model 5 or 6\n",
    "- Model 5: Doesn't include quadratic effects. Random intercept and linear time term. Use when model 6 doesn't converge.\n",
    "- Model 6: Includes quadratic time term with fixed effects only. Random intercept and linear time term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c070e3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 6\n",
    "\n",
    "# Filter dataframe for the selected model and reset index\n",
    "df_model = df[df['model'] == model].reset_index(drop=True)\n",
    "\n",
    "# Extract fixed effect intercept estimate\n",
    "fe_intercept = (\n",
    "    df_model[df_model['term'].str.contains('Intercept')]['estimate']\n",
    "    .reset_index(drop=True)\n",
    "    .loc[0]\n",
    ")\n",
    "\n",
    "# Depending on model, extract random effects intercept and sum with fixed effect\n",
    "if model == 6:\n",
    "    re_intercept = df_m6_re[df_m6_re['facet'].str.contains('Intercept')].reset_index(drop=True)\n",
    "    intercept = [\n",
    "        fe_intercept + re_intercept['estimate'].loc[i]\n",
    "        for i in range(len(np.unique(df_m6_re['term'])))\n",
    "    ]\n",
    "elif model == 5:\n",
    "    re_intercept = df_m5_re[df_m5_re['facet'].str.contains('Intercept')].reset_index(drop=True)\n",
    "    intercept = [\n",
    "        fe_intercept + re_intercept['estimate'].loc[i]\n",
    "        for i in range(len(np.unique(df_m5_re['term'])))\n",
    "    ]\n",
    "\n",
    "# Extract fixed effect slope estimate for 'time'\n",
    "fe_slope = df_model[df_model['term'] == 'time']['estimate'].reset_index(drop=True).loc[0]\n",
    "\n",
    "# Extract random effects slope and add to fixed effect slope per model\n",
    "if model == 6:\n",
    "    re_slope = df_m6_re[df_m6_re['facet'] == 'time'].reset_index(drop=True)\n",
    "    slope = [\n",
    "        fe_slope + re_slope['estimate'].loc[i]\n",
    "        for i in range(len(np.unique(df_m6_re['term'])))\n",
    "    ]\n",
    "elif model == 5:\n",
    "    re_slope = df_m5_re[df_m5_re['facet'] == 'time'].reset_index(drop=True)\n",
    "    slope = [\n",
    "        fe_slope + re_slope['estimate'].loc[i]\n",
    "        for i in range(len(np.unique(df_m5_re['term'])))\n",
    "    ]\n",
    "\n",
    "# Try to get fixed effect of 'stringency_index'; if missing, default to 0\n",
    "try:\n",
    "    stringency = [\n",
    "        df_model[df_model['term'] == 'stringency_index']['estimate']\n",
    "        .reset_index(drop=True)\n",
    "        .loc[0]\n",
    "        for _ in range(len(intercept))\n",
    "    ]\n",
    "except KeyError:\n",
    "    stringency = [0 for _ in range(len(intercept))]\n",
    "\n",
    "# Add stringency effect to slope estimates\n",
    "slope = [slope[i] + stringency[i] for i in range(len(slope))]\n",
    "\n",
    "# Extract quadratic term estimates if model 6\n",
    "if model == 6:\n",
    "    quad = [\n",
    "        df_model[df_model['term'] == 'time2']['estimate']\n",
    "        .reset_index(drop=True)\n",
    "        .loc[0]\n",
    "        for _ in range(len(intercept))\n",
    "    ]\n",
    "\n",
    "# Fixed effect intercept standard error\n",
    "fe_intercept_std = (\n",
    "    df_model[df_model['term'].str.contains('Intercept')]['std.error']\n",
    "    .reset_index(drop=True)\n",
    "    .loc[0]\n",
    ")\n",
    "\n",
    "# Extract random effects intercept for standard error calculation\n",
    "if model == 6:\n",
    "    re_intercept = df_m6_re[df_m6_re['facet'].str.contains('Intercept')].reset_index(drop=True)\n",
    "elif model == 5:\n",
    "    re_intercept = df_m5_re[df_m5_re['facet'].str.contains('Intercept')].reset_index(drop=True)\n",
    "\n",
    "# Calculate confidence interval width for random intercept\n",
    "re_intercept_ci = [\n",
    "    re_intercept.loc[i, 'conf.high'] - re_intercept.loc[i, 'conf.low']\n",
    "    for i in range(len(re_intercept))\n",
    "]\n",
    "\n",
    "# Convert CI width to standard deviation assuming Gaussian distribution\n",
    "re_intercept_std = [ci / (2 * 1.96) for ci in re_intercept_ci]\n",
    "\n",
    "# Combine fixed effect and random effect intercept standard deviations\n",
    "# Commented out original combination including random std; using only fixed effect std here\n",
    "# intercept_std = [np.sqrt(fe_intercept_std ** 2 + std ** 2) for std in re_intercept_std]\n",
    "intercept_std = [np.sqrt(fe_intercept_std ** 2) for _ in re_intercept_std]\n",
    "\n",
    "# Fixed effect slope standard error\n",
    "fe_time_std = df_model[df_model['term'] == 'time']['std.error'].reset_index(drop=True).loc[0]\n",
    "\n",
    "# Try to extract fixed effect stringency standard error; default to 0 if missing\n",
    "try:\n",
    "    fe_stringency_std = (\n",
    "        df_model[df_model['term'] == 'stringency_index']['std.error']\n",
    "        .reset_index(drop=True)\n",
    "        .loc[0]\n",
    "    )\n",
    "except KeyError:\n",
    "    fe_stringency_std = 0\n",
    "\n",
    "# Extract random effects slope standard errors per model\n",
    "if model == 6:\n",
    "    re_time = df_m6_re[df_m6_re['facet'].str.contains('time')].reset_index(drop=True)\n",
    "elif model == 5:\n",
    "    re_time = df_m5_re[df_m5_re['facet'].str.contains('time')].reset_index(drop=True)\n",
    "\n",
    "# Calculate confidence interval width for random slope\n",
    "re_time_ci = [\n",
    "    re_time.loc[i, 'conf.high'] - re_time.loc[i, 'conf.low']\n",
    "    for i in range(len(re_time))\n",
    "]\n",
    "\n",
    "# Convert CI width to standard deviation assuming Gaussian distribution\n",
    "re_time_std = [ci / (2 * 1.96) for ci in re_time_ci]\n",
    "\n",
    "# Combine fixed effects and random effects slope standard deviations\n",
    "# Commented out combination including random std; using fixed effect std only here\n",
    "# slope_std = [np.sqrt(fe_time_std ** 2 + fe_stringency_std ** 2 + std ** 2) for std in re_time_std]\n",
    "slope_std = [np.sqrt(fe_time_std ** 2 + fe_stringency_std ** 2) for _ in re_time_std]\n",
    "\n",
    "# Extract fixed effect quadratic term standard error for model 6; else zero\n",
    "if model == 6:\n",
    "    fe_quad_std = df_model[df_model['term'] == 'time2']['std.error'].reset_index(drop=True).loc[0]\n",
    "else:\n",
    "    fe_quad_std = 0\n",
    "\n",
    "# Create list of quadratic term standard errors\n",
    "quad_std = [fe_quad_std for _ in range(len(slope_std))]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124ace8a",
   "metadata": {},
   "source": [
    "# Compute recovery times at recovery thresholds 1-100%\n",
    "Compute also the propagated uncertainties of these times, based on uncertainty of model estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2131a616",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = np.arange(1, 100)\n",
    "times = []\n",
    "times_std = []\n",
    "\n",
    "for thr in thresholds:\n",
    "    times_thr = []\n",
    "    times_thr_std = []\n",
    "    for i in range(len(intercept)):\n",
    "        # If intercept and slope are both positive, append -1 (special case)\n",
    "        if intercept[i] > 0 and slope[i] > 0:\n",
    "            times_thr.append(-1)\n",
    "        else:\n",
    "            if model == 6:\n",
    "                discriminant = slope[i]**2 - 4 * quad[i] * (thr / 100) * intercept[i]\n",
    "\n",
    "                # Check if discriminant is non-negative for real roots\n",
    "                if discriminant >= 0:\n",
    "                    sqrt_discriminant = np.sqrt(discriminant)\n",
    "                    # Calculate first root\n",
    "                    time_thr = (-slope[i] + sqrt_discriminant) / (2 * quad[i])\n",
    "                    if time_thr > 0:\n",
    "                        times_thr.append(time_thr)\n",
    "\n",
    "                        partial_intercept = (-(thr / 100)) / sqrt_discriminant\n",
    "                        partial_slope = (1 / quad[i]) * (-1 + slope[i] / sqrt_discriminant)\n",
    "                        partial_quad = (-(thr / 100) * intercept[i]) / (quad[i] * sqrt_discriminant) + \\\n",
    "                            (slope[i] - sqrt_discriminant) / (2 * quad[i]**2)\n",
    "                    else:\n",
    "                        # Calculate second root if first root not positive\n",
    "                        time_thr = (-slope[i] - sqrt_discriminant) / (2 * quad[i])\n",
    "                        times_thr.append(time_thr)\n",
    "\n",
    "                        partial_intercept = (thr / 100) / sqrt_discriminant\n",
    "                        partial_slope = (1 / quad[i]) * (-1 - slope[i] / sqrt_discriminant)\n",
    "                        partial_quad = ((thr / 100) * intercept[i]) / (quad[i] * sqrt_discriminant) + \\\n",
    "                            (slope[i] + sqrt_discriminant) / (2 * quad[i]**2)\n",
    "\n",
    "                    # Calculate standard deviation of time_thr by error propagation\n",
    "                    time_thr_std = np.sqrt(\n",
    "                        (partial_intercept * intercept_std[i]) ** 2 +\n",
    "                        (partial_slope * slope_std[i]) ** 2 +\n",
    "                        (partial_quad * quad_std[i]) ** 2\n",
    "                    )\n",
    "                    times_thr_std.append(time_thr_std)\n",
    "                else:\n",
    "                    # If no real root, append NaN\n",
    "                    times_thr.append(np.nan)\n",
    "                    times_thr_std.append(np.nan)\n",
    "\n",
    "            elif model == 5:\n",
    "                # Linear model time threshold calculation\n",
    "                time_thr = - (thr / 100) * (intercept[i] / slope[i])\n",
    "                times_thr.append(time_thr)\n",
    "\n",
    "                partial_intercept = -(thr / 100) / slope[i]\n",
    "                partial_slope = ((thr / 100) * intercept[i]) / (slope[i] ** 2)\n",
    "\n",
    "                # Standard deviation calculation for linear model\n",
    "                time_thr_std = np.sqrt(\n",
    "                    (partial_intercept * intercept_std[i]) ** 2 +\n",
    "                    (partial_slope * slope_std[i]) ** 2\n",
    "                )\n",
    "                times_thr_std.append(time_thr_std)\n",
    "\n",
    "    times.append(times_thr)\n",
    "    times_std.append(times_thr_std)\n",
    "\n",
    "# Convert lists to numpy arrays and transpose\n",
    "times = np.array(times).T\n",
    "times_std = np.array(times_std).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baadbe06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12, 30))\n",
    "\n",
    "# AX1 configuration and plotting\n",
    "ax1.tick_params(axis='both', which='both', width=0, length=0, color='k', labelsize=30, pad=9)\n",
    "\n",
    "left_error = df_m3_re['estimate'] - df_m3_re['conf.low']\n",
    "right_error = df_m3_re['conf.high'] - df_m3_re['estimate']\n",
    "estimate = df[(df['model'] == 3) & (df['term'] == '(Intercept)')]['estimate'].reset_index(drop=True)\n",
    "ax1.errorbar(\n",
    "    df_m3_re['estimate'] + estimate.loc[0],\n",
    "    list(df_m3_re.index + 0.15),\n",
    "    xerr=[left_error, right_error],\n",
    "    fmt='o',\n",
    "    linewidth=6,\n",
    "    markersize=15,\n",
    "    color='lightsalmon'\n",
    ")\n",
    "ax1.plot(\n",
    "    [estimate, estimate],\n",
    "    [min(list(df_m3_re.index)) - 0.5, max(list(df_m3_re.index)) + 0.5],\n",
    "    linestyle=':',\n",
    "    dashes=(1, 0.5),\n",
    "    linewidth=6,\n",
    "    color='lightsalmon'\n",
    ")\n",
    "\n",
    "df_m5_re_intercept = df_m5_re[df_m5_re['facet'].str.contains('Intercept')].reset_index(drop=True)\n",
    "left_error = df_m5_re_intercept['estimate'] - df_m5_re_intercept['conf.low']\n",
    "right_error = df_m5_re_intercept['conf.high'] - df_m5_re_intercept['estimate']\n",
    "estimate = df[(df['model'] == 5) & (df['term'] == '(Intercept)')]['estimate'].reset_index(drop=True)\n",
    "ax1.errorbar(\n",
    "    df_m5_re_intercept['estimate'] + estimate.loc[0],\n",
    "    list(df_m5_re_intercept.index - 0.05),\n",
    "    xerr=[left_error, right_error],\n",
    "    fmt='o',\n",
    "    linewidth=6,\n",
    "    markersize=15,\n",
    "    color='crimson'\n",
    ")\n",
    "ax1.plot(\n",
    "    [estimate, estimate],\n",
    "    [min(list(df_m5_re_intercept.index)) - 0.5, max(list(df_m5_re_intercept.index)) + 0.5],\n",
    "    linestyle=':',\n",
    "    dashes=(1, 0.5),\n",
    "    linewidth=6,\n",
    "    color='crimson'\n",
    ")\n",
    "\n",
    "df_m6_re_intercept = df_m6_re[df_m6_re['facet'].str.contains('Intercept')].reset_index(drop=True)\n",
    "left_error = df_m6_re_intercept['estimate'] - df_m6_re_intercept['conf.low']\n",
    "right_error = df_m6_re_intercept['conf.high'] - df_m6_re_intercept['estimate']\n",
    "estimate = df[(df['model'] == 6) & (df['term'] == '(Intercept)')]['estimate'].reset_index(drop=True)\n",
    "ax1.errorbar(\n",
    "    df_m6_re_intercept['estimate'] + estimate.loc[0],\n",
    "    list(df_m6_re_intercept.index - 0.25),\n",
    "    xerr=[left_error, right_error],\n",
    "    fmt='o',\n",
    "    linewidth=6,\n",
    "    markersize=15,\n",
    "    color=(72 / 255, 13 / 255, 20 / 255)\n",
    ")\n",
    "ax1.plot(\n",
    "    [estimate, estimate],\n",
    "    [min(list(df_m6_re_intercept.index)) - 0.5, max(list(df_m6_re_intercept.index)) + 0.5],\n",
    "    linestyle=':',\n",
    "    dashes=(1, 0.5),\n",
    "    linewidth=6,\n",
    "    color=(72 / 255, 13 / 255, 20 / 255)\n",
    ")\n",
    "\n",
    "# Uncomment below for model 7 intercept plotting if needed\n",
    "# df_m7_re_intercept = df_m7_re[df_m7_re['facet'].str.contains('Intercept')].reset_index(drop=True)\n",
    "# left_error = df_m7_re_intercept['estimate'] - df_m7_re_intercept['conf.low']\n",
    "# right_error = df_m7_re_intercept['conf.high'] - df_m7_re_intercept['estimate']\n",
    "# estimate = df[(df['model'] == 7) & (df['term'] == '(Intercept)')]['estimate'].reset_index(drop=True)\n",
    "# ax1.errorbar(\n",
    "#     df_m7_re_intercept['estimate'] + estimate.loc[0],\n",
    "#     list(df_m7_re_intercept.index - 0.45),\n",
    "#     xerr=[left_error, right_error],\n",
    "#     fmt='o',\n",
    "#     linewidth=6,\n",
    "#     markersize=15,\n",
    "#     color=(72 / 255, 13 / 255, 20 / 255)\n",
    "# )\n",
    "# ax1.plot(\n",
    "#     [estimate, estimate],\n",
    "#     [min(list(df_m7_re_intercept.index)) - 0.5, max(list(df_m7_re_intercept.index)) + 0.5],\n",
    "#     linestyle=':',\n",
    "#     dashes=(1, 0.5),\n",
    "#     linewidth=6,\n",
    "#     color=(72 / 255, 13 / 255, 20 / 255)\n",
    "# )\n",
    "\n",
    "ax1.set_ylim(min(list(df_m5_re_intercept.index)) - 0.7, max(list(df_m5_re_intercept.index)) + 0.7)\n",
    "ax1.set_yticks(list(df_m5_re_intercept.index), list(df_m5_re_intercept.index))\n",
    "\n",
    "# AX2 configuration and plotting\n",
    "ax2.tick_params(axis='both', which='both', width=0, length=0, color='k', labelsize=30, pad=9)\n",
    "\n",
    "left_error = df_m4_re['estimate'] - df_m4_re['conf.low']\n",
    "right_error = df_m4_re['conf.high'] - df_m4_re['estimate']\n",
    "estimate = df[(df['model'] == 2) & (df['term'] == 'time')]['estimate'].reset_index(drop=True)\n",
    "ax2.errorbar(\n",
    "    df_m4_re['estimate'] + estimate.loc[0],\n",
    "    list(df_m4_re.index + 0.15),\n",
    "    xerr=[left_error, right_error],\n",
    "    fmt='o',\n",
    "    linewidth=6,\n",
    "    markersize=15,\n",
    "    color='lightblue'\n",
    ")\n",
    "ax2.plot(\n",
    "    [estimate, estimate],\n",
    "    [min(list(df_m4_re.index)) - 0.5, max(list(df_m4_re.index)) + 0.5],\n",
    "    linestyle=':',\n",
    "    dashes=(1, 0.5),\n",
    "    linewidth=6,\n",
    "    color='lightblue'\n",
    ")\n",
    "\n",
    "df_m5_re_slope = df_m5_re[df_m5_re['facet'] == 'time'].reset_index(drop=True)\n",
    "left_error = df_m5_re_slope['estimate'] - df_m5_re_slope['conf.low']\n",
    "right_error = df_m5_re_slope['conf.high'] - df_m5_re_slope['estimate']\n",
    "estimate = df[(df['model'] == 5) & (df['term'] == 'time')]['estimate'].reset_index(drop=True)\n",
    "ax2.errorbar(\n",
    "    df_m5_re_slope['estimate'] + estimate.loc[0],\n",
    "    list(df_m5_re_slope.index - 0.05),\n",
    "    xerr=[left_error, right_error],\n",
    "    fmt='o',\n",
    "    linewidth=6,\n",
    "    markersize=15,\n",
    "    color='crimson'\n",
    ")\n",
    "ax2.plot(\n",
    "    [estimate, estimate],\n",
    "    [min(list(df_m5_re_slope.index)) - 0.5, max(list(df_m5_re_slope.index)) + 0.5],\n",
    "    linestyle=':',\n",
    "    dashes=(1, 0.5),\n",
    "    linewidth=6,\n",
    "    color='crimson'\n",
    ")\n",
    "\n",
    "df_m6_re_slope = df_m6_re[df_m6_re['facet'] == 'time'].reset_index(drop=True)\n",
    "left_error = df_m6_re_slope['estimate'] - df_m6_re_slope['conf.low']\n",
    "right_error = df_m6_re_slope['conf.high'] - df_m6_re_slope['estimate']\n",
    "estimate = df[(df['model'] == 6) & (df['term'] == 'time')]['estimate'].reset_index(drop=True)\n",
    "ax2.errorbar(\n",
    "    df_m6_re_slope['estimate'] + estimate.loc[0],\n",
    "    list(df_m6_re_slope.index - 0.25),\n",
    "    xerr=[left_error, right_error],\n",
    "    fmt='o',\n",
    "    linewidth=6,\n",
    "    markersize=15,\n",
    "    color=(72 / 255, 13 / 255, 20 / 255)\n",
    ")\n",
    "ax2.plot(\n",
    "    [estimate, estimate],\n",
    "    [min(list(df_m6_re_slope.index)) - 0.5, max(list(df_m6_re_slope.index)) + 0.5],\n",
    "    linestyle=':',\n",
    "    dashes=(1, 0.5),\n",
    "    linewidth=6,\n",
    "    color=(72 / 255, 13 / 255, 20 / 255)\n",
    ")\n",
    "\n",
    "# Uncomment below for model 7 slope plotting if needed\n",
    "# df_m7_re_slope = df_m7_re[df_m7_re['facet']=='time'].reset_index(drop=True)\n",
    "# left_error = df_m7_re_slope['estimate'] - df_m7_re_slope['conf.low']\n",
    "# right_error = df_m7_re_slope['conf.high'] - df_m7_re_slope['estimate']\n",
    "# estimate = df[(df['model']==7) & (df['term']=='time')]['estimate'].reset_index(drop=True)\n",
    "# ax2.errorbar(\n",
    "#     df_m7_re_slope['estimate'] + estimate.loc[0],\n",
    "#     list(df_m7_re_slope.index-0.45),\n",
    "#     xerr=[left_error, right_error],\n",
    "#     fmt='o',\n",
    "#     linewidth=6,\n",
    "#     markersize=15,\n",
    "#     color=(72 / 255, 13 / 255, 20 / 255)\n",
    "# )\n",
    "# ax2.plot(\n",
    "#     [estimate, estimate],\n",
    "#     [min(list(df_m7_re_slope.index)) - 0.5, max(list(df_m7_re_slope.index)) + 0.5],\n",
    "#     linestyle=':',\n",
    "#     dashes=(1, 0.5),\n",
    "#     linewidth=6,\n",
    "#     color=(72 / 255, 13 / 255, 20 / 255)\n",
    "# )\n",
    "\n",
    "ax2.set_ylim(min(list(df_m5_re_intercept.index)) - 0.7, max(list(df_m5_re_intercept.index)) + 0.7)\n",
    "ax2.set_yticks(list(df_m5_re_slope.index), list(df_m5_re_slope.index))\n",
    "\n",
    "# AX3 configuration and plotting\n",
    "ax3.tick_params(axis='both', which='both', width=0, length=0, color='k', labelsize=30, pad=9)\n",
    "\n",
    "# Uncomment below for model 7 quadratic term plotting if needed\n",
    "# df_m7_re_quad = df_m7_re[df_m7_re['facet']=='time2'].reset_index(drop=True)\n",
    "# left_error = df_m7_re_quad['estimate'] - df_m7_re_quad['conf.low']\n",
    "# right_error = df_m7_re_quad['conf.high'] - df_m7_re_quad['estimate']\n",
    "# estimate = df[(df['model'] == 7) & (df['term'] == 'time2')]['estimate'].reset_index(drop=True)\n",
    "# ax3.errorbar(\n",
    "#     df_m7_re_quad['estimate'] + estimate.loc[0],\n",
    "#     list(df_m7_re_quad.index),\n",
    "#     xerr=[left_error, right_error],\n",
    "#     fmt='o',\n",
    "#     linewidth=6,\n",
    "#     markersize=15,\n",
    "#     color=(72 / 255, 13 / 255, 20 / 255)\n",
    "# )\n",
    "# ax3.plot(\n",
    "#     [estimate, estimate],\n",
    "#     [min(list(df_m7_re_quad.index)) - 0.5, max(list(df_m7_re_quad.index)) + 0.5],\n",
    "#     linestyle=':',\n",
    "#     dashes=(1, 0.5),\n",
    "#     linewidth=6,\n",
    "#     color=(72 / 255, 13 / 255, 20 / 255)\n",
    "# )\n",
    "# ax3.set_ylim(min(list(df_m7_re_quad.index)) - 0.7, max(list(df_m7_re_quad.index)) + 0.7)\n",
    "# ax3.set_yticks(list(df_m7_re_quad.index), list(df_m7_re_quad.index))\n",
    "# xticks = [round(tick * 10, 2) for tick in ax3.get_xticks()]\n",
    "# ax3.set_xticks(list([tick for tick in ax3.get_xticks()]), xticks)\n",
    "# ax3.text(0.9, -0.14, 'x 10e-1', fontsize=20, transform=ax3.transAxes)\n",
    "\n",
    "ax3.set_ylim([-10, 320])\n",
    "\n",
    "if category == 'density':\n",
    "    viridis = plt.cm.get_cmap('viridis')\n",
    "    n_class = len(np.unique(df_m6_re['term']))\n",
    "    norm = plt.Normalize(0, n_class - 1)\n",
    "    for i in range(n_class):\n",
    "        if np.sum(times[i]) > 0:\n",
    "            ax3.plot(thresholds, times[i], color=viridis(norm(i)), lw=5)\n",
    "            ax3.fill_between(thresholds, times[i] - times_std[i], times[i] + times_std[i], color=viridis(norm(i)), lw=0, alpha=0.25)\n",
    "elif category == 'rdi':\n",
    "    n_class = 3\n",
    "    cmap_base = matplotlib.colormaps.get_cmap('inferno')\n",
    "    if n_class == 3:\n",
    "        # mimic your [4, 13, 23] sampling\n",
    "        idx = [4, 13, 23]\n",
    "        colors_rdi = [cmap_base(i / 26) for i in idx]\n",
    "    else:\n",
    "        # general case: evenly spaced colors in the mid-range\n",
    "        colors_rdi = [cmap_base(x) for x in np.linspace(0.15, 0.85, n_class)]\n",
    "    for i in range(n_class):\n",
    "        if np.sum(times[i]) > 0:\n",
    "            ax3.plot(thresholds, times[i], color=colors_rdi[i], lw=5)\n",
    "            ax3.fill_between(thresholds, times[i] - times_std[i], times[i] + times_std[i], color=colors_rdi[i], lw=0, alpha=0.25)\n",
    "elif category == 'old':\n",
    "    n_class = 3\n",
    "    cmap_base = matplotlib.colormaps.get_cmap('cividis')\n",
    "    if n_class == 3:\n",
    "        # mimic your [4, 13, 23] sampling\n",
    "        idx = [2, 9, 24]\n",
    "        colors_old = [cmap_base(i / 26) for i in idx]\n",
    "    else:\n",
    "        # general case: evenly spaced colors in the mid-range\n",
    "        colors_old = [cmap_base(x) for x in np.linspace(0.15, 0.85, n_class)]\n",
    "    for i in range(n_class):\n",
    "        if np.sum(times[i]) > 0:\n",
    "            ax3.plot(thresholds, times[i], color=colors_old[i], lw=5)\n",
    "            ax3.fill_between(thresholds, times[i] - times_std[i], times[i] + times_std[i], color=colors_old[i], lw=0, alpha=0.25)\n",
    "\n",
    "            \n",
    "if stringency == True: \n",
    "    plt.savefig(\n",
    "        wd + '/plots/evolution/models/' + country_short + '_models_re_' + category + '_quad_stringency_no_m7_std-r1.pdf',\n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "else:\n",
    "        plt.savefig(\n",
    "        wd + '/plots/evolution/models/' + country_short + '_models_re_' + category + '_quad_no_m7_std-r1.pdf',\n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f7f284",
   "metadata": {},
   "source": [
    "# Compute recovery times at recovery thresholds: 25, 50, 75, 100\n",
    "Compute also the propagated uncertainties of these times, based on uncertainty of model estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63447248",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [25, 50, 75, 100]\n",
    "times = []\n",
    "times_std = []\n",
    "\n",
    "for thr in thresholds:\n",
    "    times_thr = []\n",
    "    times_thr_std = []\n",
    "    for i in range(len(intercept)):\n",
    "        if intercept[i] > 0 and slope[i] > 0:\n",
    "            times_thr.append(-1)\n",
    "            times_thr_std.append(-1)\n",
    "        else:\n",
    "            if model == 6:\n",
    "                discriminant = slope[i]**2 - 4 * quad[i] * (thr / 100) * intercept[i]\n",
    "                if discriminant >= 0:\n",
    "                    time_thr = (-slope[i] + np.sqrt(discriminant)) / (2 * quad[i])\n",
    "                    if time_thr > 0:\n",
    "                        times_thr.append(time_thr)\n",
    "                        partial_intercept = (-(thr / 100)) / np.sqrt(discriminant)\n",
    "                        partial_slope = (1 / quad[i]) * (-1 + (slope[i] / np.sqrt(discriminant)))\n",
    "                        partial_quad = (-(thr / 100) * intercept[i]) / (quad[i] * np.sqrt(discriminant)) + \\\n",
    "                                       (slope[i] - np.sqrt(discriminant)) / (2 * quad[i]**2)\n",
    "                    else:\n",
    "                        time_thr = (-slope[i] - np.sqrt(discriminant)) / (2 * quad[i])\n",
    "                        times_thr.append(time_thr)\n",
    "                        partial_intercept = (thr / 100) / np.sqrt(discriminant)\n",
    "                        partial_slope = (1 / quad[i]) * (-1 - (slope[i] / np.sqrt(discriminant)))\n",
    "                        partial_quad = ((thr / 100) * intercept[i]) / (quad[i] * np.sqrt(discriminant)) + \\\n",
    "                                       (slope[i] + np.sqrt(discriminant)) / (2 * quad[i]**2)\n",
    "\n",
    "                    time_thr_std = np.sqrt(\n",
    "                        (partial_intercept * intercept_std[i])**2 +\n",
    "                        (partial_slope * slope_std[i])**2 +\n",
    "                        (partial_quad * quad_std[i])**2\n",
    "                    )\n",
    "                    times_thr_std.append(time_thr_std)\n",
    "                else:\n",
    "                    times_thr.append(np.nan)\n",
    "                    times_thr_std.append(np.nan)\n",
    "\n",
    "            elif model == 5:\n",
    "                time_thr = - (thr / 100) * (intercept[i] / slope[i])\n",
    "                times_thr.append(time_thr)\n",
    "                partial_intercept = -(thr / 100) / slope[i]\n",
    "                partial_slope = ((thr / 100) * intercept[i]) / (slope[i]**2)\n",
    "                time_thr_std = np.sqrt(\n",
    "                    (partial_intercept * intercept_std[i])**2 +\n",
    "                    (partial_slope * slope_std[i])**2\n",
    "                )\n",
    "                times_thr_std.append(time_thr_std)\n",
    "\n",
    "    times.append(times_thr)\n",
    "    times_std.append(times_thr_std)\n",
    "\n",
    "print(times)\n",
    "print(times_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84067716",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
