{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c22a83ab",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e1d2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib import colors as mcolors\n",
    "from mycolorpy import colorlist as mcp\n",
    "import matplotlib\n",
    "import geopandas as gpd\n",
    "import jenkspy\n",
    "import random\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e5c08e",
   "metadata": {},
   "source": [
    "# Define country and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd9fe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select target country\n",
    "country = 'Colombia'\n",
    "\n",
    "# Set country-specific parameters: ISO codes and buffer size (in meters)\n",
    "if country == 'Argentina':\n",
    "    country_short = 'ARG'   # ISO 3-letter code\n",
    "    country_code = 'AR'     # ISO 2-letter code\n",
    "elif country == 'Chile':\n",
    "    country_short = 'CHL'\n",
    "    country_code = 'CL'\n",
    "elif country == 'Colombia':\n",
    "    country_short = 'COL'\n",
    "    country_code = 'CO'\n",
    "# Uncomment the following if Mexico is to be included in the analysis\n",
    "# elif country == 'Mexico':\n",
    "#     country_short = 'MEX'\n",
    "#     country_code = 'MX'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e96ea3",
   "metadata": {},
   "source": [
    "# Set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fd6865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define working directory path\n",
    "wd = (\n",
    "    '/your/path/to/working/directory/'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6115d6e0",
   "metadata": {},
   "source": [
    "# Load necessary data\n",
    "- Functional Urban Area boundaries\n",
    "- Grid for movement data\n",
    "- Baseline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfebe6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Functional Urban Areas (FUAs) shapefile and convert to WGS84 coordinate system\n",
    "gdf_fua = gpd.read_file(\n",
    "    wd + '/data/inputs/boundaries/GHS_FUA_UCDB2015_GLOBE_R2019A_54009_1K_V1_0/'\n",
    "         'GHS_FUA_UCDB2015_GLOBE_R2019A_54009_1K_V1_0.gpkg'\n",
    ").to_crs('EPSG:4326')\n",
    "\n",
    "# Load national grid shapefile and convert to WGS84 coordinate system\n",
    "grid = gpd.read_file(\n",
    "    wd + '/data/inputs/grids/Grid_' + country + '_FB_mov/Grid_' + country + '.shp'\n",
    ").to_crs('EPSG:4326')\n",
    "\n",
    "# Toggle for reading raw vs imputed baseline movement data\n",
    "raw = False\n",
    "\n",
    "if raw:\n",
    "    # Load raw baseline movement data\n",
    "    baseline_mov = pd.read_csv(\n",
    "        wd + '/data/outputs/' + country_short + '/baseline/baseline_mov.csv'\n",
    "        # .drop('Unnamed: 0', axis=1)  # Optional cleanup if needed\n",
    "    )\n",
    "else:\n",
    "    # Load imputed baseline movement data with exogenous variables\n",
    "    baseline_mov_imput = pd.read_csv(\n",
    "        wd + '/data/outputs/' + country_short +\n",
    "        '/baseline/movcell-baseline-imput-mov-dist-with-exo-var-flatten.csv'\n",
    "    ).drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# Load baseline population data with exogenous variables\n",
    "baseline_pop_imput = gpd.read_file(\n",
    "    wd + '/data/outputs/' + country_short +\n",
    "    '/grids-with-data/movcell-baseline-imput-pop-with-exo-var/'\n",
    "    'movcell-baseline-imput-pop-with-exo-var.gpkg'\n",
    ")\n",
    "\n",
    "# Load movement-distance baseline (non-imputed) with exogenous variables\n",
    "baseline_mov_dist = pd.read_csv(\n",
    "    wd + '/data/outputs/' + country_short +\n",
    "    '/baseline/movcell-baseline-mov-dist-with-exo-var.csv'\n",
    ").drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c66a1a7",
   "metadata": {},
   "source": [
    "# Analysis only for capital? All FUAs? or All FUAs but no capital?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ddb612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flags to control which Functional Urban Areas (FUAs) to include\n",
    "capital = False       # If True, analyse only the capital city\n",
    "no_capital = False    # If True, exclude the capital from the analysis\n",
    "\n",
    "# Set suffix to be used in file naming or result differentiation\n",
    "if capital:\n",
    "    capital_suffix = '_capital'\n",
    "elif no_capital:\n",
    "    capital_suffix = '_fuas_no_capital'\n",
    "else:\n",
    "    capital_suffix = '_fuas'\n",
    "\n",
    "# Filter FUAs to only those belonging to the target country\n",
    "gdf_fua = gdf_fua[gdf_fua['Cntry_ISO'] == country_short].reset_index(drop=True)\n",
    "\n",
    "# Further filter based on capital/no_capital flags\n",
    "if capital:\n",
    "    if country == 'Argentina':\n",
    "        gdf_fua = gdf_fua[gdf_fua['eFUA_name'] == 'Buenos Aires'].reset_index(drop=True)\n",
    "    elif country == 'Chile':\n",
    "        gdf_fua = gdf_fua[gdf_fua['eFUA_name'] == 'Santiago'].reset_index(drop=True)\n",
    "    elif country == 'Colombia':\n",
    "        gdf_fua = gdf_fua[gdf_fua['eFUA_name'] == 'Bogota'].reset_index(drop=True)\n",
    "\n",
    "elif no_capital:\n",
    "    if country == 'Argentina':\n",
    "        gdf_fua = gdf_fua[gdf_fua['eFUA_name'] != 'Buenos Aires'].reset_index(drop=True)\n",
    "    elif country == 'Chile':\n",
    "        gdf_fua = gdf_fua[gdf_fua['eFUA_name'] != 'Santiago'].reset_index(drop=True)\n",
    "    elif country == 'Colombia':\n",
    "        gdf_fua = gdf_fua[gdf_fua['eFUA_name'] != 'Bogota'].reset_index(drop=True)\n",
    "\n",
    "# Initialise a list to store index of the grid cell with max population density for each FUA\n",
    "index_fuas = []\n",
    "\n",
    "# Loop over each FUA to find the grid cell with the highest population density\n",
    "for i in range(len(gdf_fua)):\n",
    "    gdf_fua_join = gdf_fua.copy()\n",
    "    grid_join = grid.copy()\n",
    "\n",
    "    # Spatial join: match grid cells intersecting with the current FUA\n",
    "    grid_fua = gdf_fua_join.iloc[[i]].sjoin(grid_join, how=\"left\", predicate='intersects')\n",
    "\n",
    "    # Extract FID indexes of intersecting grid cells\n",
    "    indexes_fua = np.array(grid_fua['FID'])\n",
    "\n",
    "    # Subset the population baseline using those indexes\n",
    "    baseline_pop_fua = baseline_pop_imput.iloc[indexes_fua]\n",
    "\n",
    "    # Find the index of the grid cell with the maximum population density\n",
    "    max_density = max(baseline_pop_fua['density'])\n",
    "    index_fua = baseline_pop_fua[baseline_pop_fua['density'] == max_density].index[0]\n",
    "\n",
    "    # Store this index for later reference\n",
    "    index_fuas.append(index_fua)\n",
    "\n",
    "# Add the list of center grid cell indexes as a new column in gdf_fua\n",
    "gdf_fua['centre'] = index_fuas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b209285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_flows(df_mov_evo, flow_type):\n",
    "    \"\"\"\n",
    "    Compute either outflows or inflows aggregated by origin or destination.\n",
    "\n",
    "    Parameters:\n",
    "    - df_mov_evo: DataFrame containing movement data with columns 'O', 'D', and time series data.\n",
    "    - flow_type: str, either 'outflows' (sum by origin) or 'inflows' (sum by destination).\n",
    "\n",
    "    Returns:\n",
    "    - df_flows: DataFrame aggregated by 'O' or 'D'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialise df_flows with unique IDs depending on flow_type\n",
    "    if flow_type == 'outflows':\n",
    "        df_flows = pd.DataFrame({'O': np.unique(df_mov_evo['O'])})\n",
    "    elif flow_type == 'inflows':\n",
    "        df_flows = pd.DataFrame({'D': np.unique(df_mov_evo['D'])})\n",
    "    else:\n",
    "        raise ValueError(\"flow_type must be 'outflows' or 'inflows'\")\n",
    "\n",
    "    # Prepare empty columns for the time series data initialised with NaNs\n",
    "    time_columns = df_mov_evo.columns[2:]\n",
    "    df_flows_add = pd.DataFrame({col: [np.nan] * len(df_flows) for col in time_columns})\n",
    "\n",
    "    # Combine ID column with empty data columns\n",
    "    df_flows = pd.concat([df_flows, df_flows_add], axis=1)\n",
    "\n",
    "    # Iterate over each unique ID to compute aggregated flows\n",
    "    for i in range(len(df_flows)):\n",
    "        if flow_type == 'outflows':\n",
    "            ID = df_flows.loc[i, 'O']\n",
    "            df_subset = df_mov_evo[df_mov_evo['O'] == ID]\n",
    "        else:  # inflows\n",
    "            ID = df_flows.loc[i, 'D']\n",
    "            df_subset = df_mov_evo[df_mov_evo['D'] == ID]\n",
    "\n",
    "        # Sum values per column, ignoring NaNs\n",
    "        for column in time_columns:\n",
    "            values = df_subset[column].dropna()\n",
    "            if values.empty:\n",
    "                df_flows.loc[i, column] = np.nan\n",
    "            else:\n",
    "                df_flows.loc[i, column] = values.sum()\n",
    "\n",
    "    return df_flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70405d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_df_ts(df_flows, df_flows_baseline, initial_col):\n",
    "    \"\"\"\n",
    "    Compute time series of movement sums and baseline sums from flow DataFrames,\n",
    "    handle missing and zero values by interpolation using nearest observations,\n",
    "    and calculate rolling averages and percentage changes.\n",
    "\n",
    "    Parameters:\n",
    "    - df_flows: DataFrame with flow data over time columns starting at initial_col\n",
    "    - df_flows_baseline: Baseline DataFrame with same structure as df_flows\n",
    "    - initial_col: int, index of the first time column in the DataFrames\n",
    "\n",
    "    Returns:\n",
    "    - df_ts: DataFrame with dates, movements, baseline, filled values, rolling means,\n",
    "             and percentage change metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    evo_movs = []\n",
    "    evo_movs_baseline = []\n",
    "\n",
    "    # Aggregate sum of movements and baseline for each time column, ignoring NaNs\n",
    "    for column in df_flows.columns[initial_col:]:\n",
    "        sums_mov = []\n",
    "        sums_baseline = []\n",
    "        for i in range(len(df_flows)):\n",
    "            val_mov = df_flows.loc[i, column]\n",
    "            val_base = df_flows_baseline.loc[i, column]\n",
    "            if not pd.isna(val_mov) and not pd.isna(val_base):\n",
    "                sums_mov.append(val_mov)\n",
    "                sums_baseline.append(val_base)\n",
    "        if sums_mov:\n",
    "            evo_movs.append(np.sum(sums_mov))\n",
    "            evo_movs_baseline.append(np.sum(sums_baseline))\n",
    "        else:\n",
    "            evo_movs.append(np.nan)\n",
    "            evo_movs_baseline.append(np.nan)\n",
    "\n",
    "    # Create DataFrame with date and aggregated sums\n",
    "    df_ts = pd.DataFrame({\n",
    "        'date': df_flows.columns[initial_col:],\n",
    "        'movements': evo_movs,\n",
    "        'baseline': evo_movs_baseline\n",
    "    })\n",
    "\n",
    "    # Function to fill zeros and NaNs using mean of closest 15 observations in time series\n",
    "    def fill_zeros_and_nans(series, fill_column_name):\n",
    "        series.replace(0, np.nan, inplace=True)\n",
    "        series.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "        is_na = series.isna()\n",
    "        filled_series = series.copy()\n",
    "\n",
    "        # Extract rows where values are not NaN for reference\n",
    "        valid_idx = series.dropna().index\n",
    "        valid_vals = series.dropna()\n",
    "\n",
    "        # For each NaN, find 15 nearest valid observations by index distance and take their mean\n",
    "        for idx in series[is_na].index:\n",
    "            distances = abs(valid_idx - idx)\n",
    "            nearest_idx = distances.nsmallest(15).index\n",
    "            filled_series.loc[idx] = valid_vals.loc[nearest_idx].mean()\n",
    "\n",
    "        return filled_series\n",
    "\n",
    "    # Fill movements and baseline columns\n",
    "    df_ts['movements_fill'] = fill_zeros_and_nans(df_ts['movements'], 'movements_fill')\n",
    "    df_ts['rolling'] = df_ts['movements_fill'].rolling(window=15, min_periods=1).mean()\n",
    "\n",
    "    df_ts['baseline_fill'] = fill_zeros_and_nans(df_ts['baseline'], 'baseline_fill')\n",
    "    df_ts['rolling_baseline'] = df_ts['baseline_fill'].rolling(window=15, min_periods=1).mean()\n",
    "\n",
    "    # Calculate percentage change between movements and baseline\n",
    "    df_ts['perchange'] = (df_ts['movements_fill'] - df_ts['baseline_fill']) / df_ts['baseline_fill'] * 100\n",
    "    df_ts['rolling_perchange'] = df_ts['perchange'].rolling(window=30, min_periods=1).mean()\n",
    "\n",
    "    return df_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e469f4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_df_ts_weekly(df_ts):\n",
    "    \"\"\"\n",
    "    Aggregate daily time series data into weekly summaries.\n",
    "\n",
    "    Parameters:\n",
    "    - df_ts: DataFrame containing daily time series with at least the following columns:\n",
    "             'date', 'movements', 'baseline', 'movements_fill', 'baseline_fill'\n",
    "\n",
    "    Returns:\n",
    "    - df_ts_weekly: DataFrame aggregated by week with sums and percentage change.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate number of full weeks in the data (each week has 7 days)\n",
    "    num_weeks = len(df_ts) // 7\n",
    "\n",
    "    # Initialise DataFrame for weekly aggregation\n",
    "    df_ts_weekly = pd.DataFrame({'week_no': range(num_weeks)})\n",
    "\n",
    "    # Aggregate by week:\n",
    "    # - 'week_start' is the date of the first day of the week\n",
    "    # - sum the columns over each week block of 7 days\n",
    "    df_ts_weekly['week_start'] = [df_ts.loc[i * 7, 'date'] for i in range(num_weeks)]\n",
    "    df_ts_weekly['movements'] = [np.sum(df_ts.loc[i * 7:(i + 1) * 7 - 1, 'movements']) for i in range(num_weeks)]\n",
    "    df_ts_weekly['baseline'] = [np.sum(df_ts.loc[i * 7:(i + 1) * 7 - 1, 'baseline']) for i in range(num_weeks)]\n",
    "    df_ts_weekly['movements_fill'] = [np.sum(df_ts.loc[i * 7:(i + 1) * 7 - 1, 'movements_fill']) for i in range(num_weeks)]\n",
    "    df_ts_weekly['baseline_fill'] = [np.sum(df_ts.loc[i * 7:(i + 1) * 7 - 1, 'baseline_fill']) for i in range(num_weeks)]\n",
    "\n",
    "    # Compute weekly percentage change between filled movements and baseline\n",
    "    df_ts_weekly['perchange'] = [\n",
    "        (df_ts_weekly.loc[i, 'movements_fill'] - df_ts_weekly.loc[i, 'baseline_fill']) / df_ts_weekly.loc[i, 'baseline_fill'] * 100\n",
    "        for i in range(num_weeks)\n",
    "    ]\n",
    "\n",
    "    return df_ts_weekly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ccf7b8",
   "metadata": {},
   "source": [
    "# Read some additional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e7010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load COVID-19 stringency data from CSV file\n",
    "df_stringency = pd.read_csv(wd + '/data/inputs/covid-stringency/owid-covid-data.csv')\n",
    "\n",
    "# Filter the data for the specified country (case-insensitive, capitalizes first letter)\n",
    "df_stringency = df_stringency[df_stringency['location'] == str(country).capitalize()].reset_index(drop=True)                             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7126219",
   "metadata": {},
   "source": [
    "# Set filename suffixes based on processing options:\n",
    "- `dist`: whether to include movements with distance >=0 (adds '_dist' if True) <br>\n",
    "- `raw`: whether using raw data (adds '_raw' if True) <br>\n",
    "- `adjust`: whether data is adjusted (adds '_adjust' if True) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcbce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flags to control data type and processing options\n",
    "dist = True     # If True, use distance-based data\n",
    "raw = False     # If True, use raw (non-imputed) data\n",
    "adjust = True   # If True, use adjusted data (e.g., adjusted for exogenous variables)\n",
    "\n",
    "# Set suffix based on distance flag\n",
    "if dist is True:\n",
    "    dist_suffix = '_dist'\n",
    "else:\n",
    "    dist_suffix = ''\n",
    "\n",
    "# Set suffix based on raw flag\n",
    "if raw is True:\n",
    "    raw_suffix = '_raw'\n",
    "else:\n",
    "    raw_suffix = ''\n",
    "    \n",
    "    # Only consider adjustment suffix if raw is False (i.e., imputed data is used)\n",
    "    if adjust is True:\n",
    "        adjust_suffix = '_adjust'\n",
    "    else:\n",
    "        adjust_suffix = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fc52d2",
   "metadata": {},
   "source": [
    "# Read movement data as time series for each tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ab5a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mobility evolution data based on configured suffixes\n",
    "# File includes options for distance-based, raw, or adjusted versions\n",
    "df_mov_evo = pd.read_csv(\n",
    "    wd + '/data/outputs/' + country_short + '/evo/mov_evo' + dist_suffix + raw_suffix + adjust_suffix + '.csv'\n",
    ").drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# Load corresponding baseline mobility evolution data\n",
    "# Note: No adjusted version for baseline file\n",
    "df_mov_evo_baseline = pd.read_csv(\n",
    "    wd + '/data/outputs/' + country_short + '/evo/mov_evo_baseline' + dist_suffix + raw_suffix + '.csv'\n",
    ").drop('Unnamed: 0', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4222ee",
   "metadata": {},
   "source": [
    "# Read movement data as time series for inflows or outflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d3cfff",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Set the type of flow to analyze ('movs', 'inflows', or 'outflows')\n",
    "flows = 'outflows'  # change to 'movs', 'inflows', or 'outflows' as needed\n",
    "\n",
    "# Load appropriate flow data depending on the selected flow type\n",
    "if flows in ['inflows', 'outflows']:\n",
    "    # Load computed flow data and baseline from CSV, dropping the index column\n",
    "    df_flows = pd.read_csv(\n",
    "        wd + '/data/outputs/' + country_short + '/mov-analysis/' +\n",
    "        flows + dist + raw + adjust + '.csv'\n",
    "    ).drop('Unnamed: 0', axis=1)\n",
    "\n",
    "    df_flows_baseline = pd.read_csv(\n",
    "        wd + '/data/outputs/' + country_short + '/mov-analysis/' +\n",
    "        flows + '_baseline' + dist + raw + '.csv'\n",
    "    ).drop('Unnamed: 0', axis=1)\n",
    "\n",
    "    # Set the initial column index for further processing\n",
    "    initial_col = 1\n",
    "\n",
    "else:\n",
    "    # Use raw mobility evolution data directly if 'movs' is selected\n",
    "    df_flows = df_mov_evo\n",
    "    df_flows_baseline = df_mov_evo_baseline\n",
    "    initial_col = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682e3cac",
   "metadata": {},
   "source": [
    "# Set distance within a radius of 100 of FUAs centres? True for YES, False for NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a53b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable radius filtering\n",
    "radius = True\n",
    "\n",
    "# Define suffix based on radius flag\n",
    "radius_suffix = '_radius' if radius else ''\n",
    "\n",
    "# Mask flows to include only those connected to FUA centres (either origin or destination)\n",
    "mask = df_flows['O'].isin(gdf_fua['centre']) | df_flows['D'].isin(gdf_fua['centre'])\n",
    "df_flows_fua = df_flows[mask].reset_index(drop=True)\n",
    "df_flows_fua_baseline = df_flows_baseline[mask].reset_index(drop=True)\n",
    "\n",
    "# Prepare to drop flows that exceed a specified distance (100 km)\n",
    "index_to_drop = []\n",
    "\n",
    "if radius:\n",
    "    for i in range(len(df_flows_fua)):\n",
    "        O = df_flows_fua.loc[i, 'O']\n",
    "        D = df_flows_fua.loc[i, 'D']\n",
    "        \n",
    "        # Get distance for weekday 0 (e.g., Monday) between origin and destination\n",
    "        dist = baseline_mov_dist[\n",
    "            (baseline_mov_dist['O'] == O) &\n",
    "            (baseline_mov_dist['D'] == D) &\n",
    "            (baseline_mov_dist['wday'] == 0)\n",
    "        ].reset_index(drop=True).loc[0, 'dist']\n",
    "        \n",
    "        # Drop if distance is greater than or equal to 100 km\n",
    "        if dist >= 100000:\n",
    "            index_to_drop.append(i)\n",
    "\n",
    "# Apply distance filter\n",
    "df_flows_fua = df_flows_fua.drop(index_to_drop).reset_index(drop=True)\n",
    "df_flows_fua_baseline = df_flows_fua_baseline.drop(index_to_drop).reset_index(drop=True)\n",
    "\n",
    "# Starting index for movement data columns (skip ID columns)\n",
    "initial_col = 4\n",
    "\n",
    "# Add new columns: \n",
    "# 'classify' identifies the grid cell to be classified (not the FUA center)\n",
    "# 'anchor' identifies the direction (O or D) that contains the FUA center\n",
    "\n",
    "classify = []\n",
    "anchor = []\n",
    "\n",
    "for i in range(len(df_flows_fua)):\n",
    "    origin = df_flows_fua.loc[i, 'O']\n",
    "    destination = df_flows_fua.loc[i, 'D']\n",
    "    \n",
    "    if origin in list(gdf_fua['centre']):\n",
    "        if destination in list(gdf_fua['centre']):\n",
    "            # Both O and D are centres → randomly select one to classify\n",
    "            random_choice = random.choice([0, 1])\n",
    "            classify.append(df_flows_fua.loc[i, df_flows_fua.columns[random_choice]])\n",
    "            anchor.append(df_flows_fua.columns[random_choice])\n",
    "        else:\n",
    "            # Origin is centre, classify destination\n",
    "            classify.append(destination)\n",
    "            anchor.append('O')\n",
    "    else:\n",
    "        # Destination is centre, classify origin\n",
    "        classify.append(origin)\n",
    "        anchor.append('D')\n",
    "\n",
    "# Insert new columns into the dataframes\n",
    "df_flows_fua.insert(2, 'classify', classify)\n",
    "df_flows_fua.insert(3, 'anchor', anchor)\n",
    "df_flows_fua_baseline.insert(2, 'classify', classify)\n",
    "df_flows_fua_baseline.insert(3, 'anchor', anchor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f696e14b",
   "metadata": {},
   "source": [
    "# By density class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fc266c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of density classes\n",
    "n_class_density = 5\n",
    "\n",
    "# Compute class breaks using Jenks natural breaks optimization\n",
    "breaks_density = jenkspy.jenks_breaks(\n",
    "    baseline_pop_imput.dropna(subset=['density'])['density'], \n",
    "    n_classes=n_class_density\n",
    ")\n",
    "\n",
    "# Slightly adjust first break to ensure inclusion of minimum density value\n",
    "breaks_density[0] -= 1e-10\n",
    "\n",
    "# Bin the 'density' column into discrete classes using the computed breaks\n",
    "baseline_pop_imput['class_density'] = pd.cut(\n",
    "    baseline_pop_imput['density'], \n",
    "    bins=breaks_density, \n",
    "    labels=[i for i in range(n_class_density)]\n",
    ")\n",
    "\n",
    "# Ensure class labels are numeric\n",
    "baseline_pop_imput['class_density'] = pd.to_numeric(baseline_pop_imput['class_density'])\n",
    "\n",
    "# Get unique class labels and number of valid (non-NaN) classes\n",
    "class_density = np.unique(baseline_pop_imput['class_density'])\n",
    "n_class_density = len(class_density[~np.isnan(class_density)])\n",
    "\n",
    "# Initialize matrices to store time series data for each class\n",
    "n_weeks = int((len(df_flows_fua.columns) - 4) / 7)  # Weekly bins inferred from column structure\n",
    "\n",
    "df_ts_weekly_inflows_class_density = np.zeros((n_class_density, n_weeks))\n",
    "df_ts_weekly_inflows_baseline_class_density = np.zeros((n_class_density, n_weeks))\n",
    "df_ts_weekly_outflows_class_density = np.zeros((n_class_density, n_weeks))\n",
    "df_ts_weekly_outflows_baseline_class_density = np.zeros((n_class_density, n_weeks))\n",
    "\n",
    "# Loop through each density class\n",
    "for i in range(n_class_density):\n",
    "    # Get indexes of grid cells in this density class\n",
    "    indexes = set(baseline_pop_imput[baseline_pop_imput['class_density'] == i].index)\n",
    "    \n",
    "    # -------------------------\n",
    "    # INFLOWS\n",
    "    # -------------------------\n",
    "    # Mask rows where 'classify' cell is in the current class and it's a destination (D)\n",
    "    mask_inflows = (df_flows_fua['classify'].isin(indexes)) & (df_flows_fua['anchor'] == 'D')\n",
    "    \n",
    "    # Filter flows and corresponding baselines\n",
    "    df_inflows_class_density = df_flows_fua[mask_inflows].reset_index(drop=True)\n",
    "    df_inflows_class_density_baseline = df_flows_fua_baseline[mask_inflows].reset_index(drop=True)\n",
    "    \n",
    "    # Compute time series and weekly aggregates\n",
    "    df_ts_class_density = compute_df_ts(df_inflows_class_density, df_inflows_class_density_baseline, initial_col)\n",
    "    df_ts_weekly_inflows = compute_df_ts_weekly(df_ts_class_density)\n",
    "    \n",
    "    # Store results\n",
    "    df_ts_weekly_inflows_class_density[i, :] = df_ts_weekly_inflows['movements']\n",
    "    df_ts_weekly_inflows_baseline_class_density[i, :] = df_ts_weekly_inflows['baseline']\n",
    "    \n",
    "    # -------------------------\n",
    "    # OUTFLOWS\n",
    "    # -------------------------\n",
    "    # Mask rows where 'classify' cell is in the current class and it's an origin (O)\n",
    "    mask_outflows = (df_flows_fua['classify'].isin(indexes)) & (df_flows_fua['anchor'] == 'O')\n",
    "    \n",
    "    # Filter flows and corresponding baselines\n",
    "    df_outflows_class_density = df_flows_fua[mask_outflows].reset_index(drop=True)\n",
    "    df_outflows_class_density_baseline = df_flows_fua_baseline[mask_outflows].reset_index(drop=True)\n",
    "    \n",
    "    # Compute time series and weekly aggregates\n",
    "    df_ts_class_density = compute_df_ts(df_outflows_class_density, df_outflows_class_density_baseline, initial_col)\n",
    "    df_ts_weekly_outflows = compute_df_ts_weekly(df_ts_class_density)\n",
    "    \n",
    "    # Store results\n",
    "    df_ts_weekly_outflows_class_density[i, :] = df_ts_weekly_outflows['movements']\n",
    "    df_ts_weekly_outflows_baseline_class_density[i, :] = df_ts_weekly_outflows['baseline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd17e9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.tick_params(\n",
    "    axis='both', which='both', width=0, length=0, color='k',\n",
    "    labelsize=20, pad=9\n",
    ")\n",
    "\n",
    "viridis = plt.cm.get_cmap('viridis')\n",
    "norm = plt.Normalize(0, n_class_density - 1)\n",
    "\n",
    "maxima = []\n",
    "minima = []\n",
    "\n",
    "for i in range(n_class_density):\n",
    "\n",
    "    color = viridis(norm(i))\n",
    "    inflows_class_density = df_ts_weekly_inflows_class_density[i, :]\n",
    "    inflows_baseline_class_density = df_ts_weekly_inflows_baseline_class_density[i, :]\n",
    "    inflows_perchange = [\n",
    "        (inflows_class_density[i] - inflows_baseline_class_density[i]) /\n",
    "        inflows_baseline_class_density[i] * 100\n",
    "        for i in range(len(inflows_baseline_class_density))\n",
    "    ]\n",
    "    df_ts_weekly_class_density_plot = pd.DataFrame(\n",
    "        {'perchange_class': inflows_perchange}\n",
    "    )\n",
    "\n",
    "#     df_ts_weekly_class_density_plot.loc[:,'rolling_perchange'] = df_ts_weekly_class_density_plot['perchange_class'].rolling(window=6).mean()\n",
    "#     ax.plot(np.arange(len(df_ts_weekly_class_density_plot['rolling_perchange']))*7, df_ts_weekly_class_density_plot['rolling_perchange'], color=color, lw=2, zorder=3)\n",
    "\n",
    "    df_ts_weekly_class_density_plot['rolling_perchange'] = (\n",
    "        df_ts_weekly_class_density_plot['perchange_class']\n",
    "        .ewm(span=10).mean()\n",
    "    )\n",
    "    df_ts_weekly_class_density_plot['rolling_perchange'] = scipy.signal.savgol_filter(\n",
    "        df_ts_weekly_class_density_plot['rolling_perchange'],\n",
    "        window_length=10,\n",
    "        polyorder=3\n",
    "    )\n",
    "    ax.plot(\n",
    "        np.arange(len(df_ts_weekly_class_density_plot['rolling_perchange'])) * 7,\n",
    "        df_ts_weekly_class_density_plot['rolling_perchange'],\n",
    "        color=color, lw=5, zorder=3\n",
    "    )\n",
    "\n",
    "    maxima.append(max(df_ts_weekly_class_density_plot['rolling_perchange']))\n",
    "    minima.append(min(df_ts_weekly_class_density_plot['rolling_perchange']))\n",
    "\n",
    "ax.plot(\n",
    "    np.arange(len(df_ts_weekly_class_density_plot['rolling_perchange']) * 7),\n",
    "    np.zeros(len(df_ts_weekly_class_density_plot['rolling_perchange']) * 7),\n",
    "    linestyle=':', color='k'\n",
    ")\n",
    "\n",
    "stringencies = []\n",
    "for date in df_ts_class_density['date']:\n",
    "    stringencies.append(\n",
    "        df_stringency[df_stringency['date'] == date]\n",
    "        .reset_index(drop=True).loc[0, 'stringency_index']\n",
    "    )\n",
    "\n",
    "ymin = -105\n",
    "ymax = 30\n",
    "\n",
    "for k in range(len(df_ts_class_density)):\n",
    "    try:\n",
    "        rgba = matplotlib.cm.gist_heat(\n",
    "            1 - (stringencies[k] - min(stringencies)) / max(stringencies)\n",
    "        )\n",
    "    except:\n",
    "        rgba = matplotlib.cm.gist_heat(\n",
    "            1 - (stringencies[k - 1] - min(stringencies)) / max(stringencies)\n",
    "        )\n",
    "    x = [k - 0.50, k + 0.50]\n",
    "    ax.fill_between(\n",
    "        x, ymin, ymax, color=rgba, alpha=0.6,\n",
    "        edgecolor='None', linewidth=0, zorder=0\n",
    "    )\n",
    "\n",
    "xticks = []\n",
    "xticks_labels = ['Apr 2020', 'Oct 2020', 'Apr 2021', 'Oct 2021', 'Apr 2022']\n",
    "for i in range(0, len(df_ts_class_density['rolling_perchange'])):\n",
    "    if i % 183 == 0:\n",
    "        xticks.append(i)\n",
    "ax.set_xticks(xticks, xticks_labels)\n",
    "ax.tick_params(axis='x', bottom=True, labelsize=23, pad=6, rotation=90)\n",
    "\n",
    "yticks = []\n",
    "for i in range(ymin, ymax):\n",
    "    if i % 25 == 0:\n",
    "        yticks.append(i)\n",
    "ax.set_yticks(yticks, yticks)\n",
    "for y in yticks:\n",
    "    ax.plot(\n",
    "        [0, len(df_ts_class_density['rolling_perchange'])],\n",
    "        [y, y], color='gray', lw=0.7, zorder=0\n",
    "    )\n",
    "ax.tick_params(axis='y', labelsize=23, pad=6, rotation=0)\n",
    "\n",
    "# plt.savefig(wd + '/plots/evolution/' + flows + '/by-density/' + country_short + '/evo_inflows' + capital_suffix + dist_suffix + raw_suffix + adjust_suffix + radius_suffix + '.pdf', bbox_inches = 'tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3829ac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.tick_params(\n",
    "    axis='both', which='both', width=0, length=0,\n",
    "    color='k', labelsize=20, pad=9\n",
    ")\n",
    "\n",
    "viridis = plt.cm.get_cmap('viridis')\n",
    "norm = plt.Normalize(0, n_class_density - 1)\n",
    "\n",
    "maxima = []\n",
    "minima = []\n",
    "\n",
    "for i in range(n_class_density):\n",
    "\n",
    "    color = viridis(norm(i))\n",
    "    outflows_class_density = df_ts_weekly_outflows_class_density[i, :]\n",
    "    outflows_baseline_class_density = df_ts_weekly_outflows_baseline_class_density[i, :]\n",
    "    outflows_perchange = [\n",
    "        (outflows_class_density[i] - outflows_baseline_class_density[i]) /\n",
    "        outflows_baseline_class_density[i] * 100\n",
    "        for i in range(len(outflows_baseline_class_density))\n",
    "    ]\n",
    "    df_ts_weekly_class_density_plot = pd.DataFrame(\n",
    "        {'perchange_class': outflows_perchange}\n",
    "    )\n",
    "\n",
    "#     df_ts_weekly_class_density_plot.loc[:,'rolling_perchange'] = df_ts_weekly_class_density_plot['perchange_class'].rolling(window=6).mean()\n",
    "#     ax.plot(np.arange(len(df_ts_weekly_class_density_plot['rolling_perchange']))*7, df_ts_weekly_class_density_plot['rolling_perchange'], color=color, lw=2, zorder=3)\n",
    "\n",
    "    df_ts_weekly_class_density_plot['rolling_perchange'] = (\n",
    "        df_ts_weekly_class_density_plot['perchange_class']\n",
    "        .ewm(span=10).mean()\n",
    "    )\n",
    "    df_ts_weekly_class_density_plot['rolling_perchange'] = scipy.signal.savgol_filter(\n",
    "        df_ts_weekly_class_density_plot['rolling_perchange'],\n",
    "        window_length=10, polyorder=3\n",
    "    )\n",
    "    ax.plot(\n",
    "        np.arange(len(df_ts_weekly_class_density_plot['rolling_perchange'])) * 7,\n",
    "        df_ts_weekly_class_density_plot['rolling_perchange'],\n",
    "        color=color, lw=5, zorder=3\n",
    "    )\n",
    "\n",
    "    maxima.append(max(df_ts_weekly_class_density_plot['rolling_perchange']))\n",
    "    minima.append(min(df_ts_weekly_class_density_plot['rolling_perchange']))\n",
    "\n",
    "ax.plot(\n",
    "    np.arange(len(df_ts_weekly_class_density_plot['rolling_perchange']) * 7),\n",
    "    np.zeros(len(df_ts_weekly_class_density_plot['rolling_perchange']) * 7),\n",
    "    linestyle=':', color='k'\n",
    ")\n",
    "\n",
    "stringencies = []\n",
    "for date in df_ts_class_density['date']:\n",
    "    stringencies.append(\n",
    "        df_stringency[df_stringency['date'] == date]\n",
    "        .reset_index(drop=True).loc[0, 'stringency_index']\n",
    "    )\n",
    "\n",
    "ymin = -105\n",
    "ymax = 30\n",
    "\n",
    "for k in range(len(df_ts_class_density)):\n",
    "    try:\n",
    "        rgba = matplotlib.cm.gist_heat(\n",
    "            1 - (stringencies[k] - min(stringencies)) / max(stringencies)\n",
    "        )\n",
    "    except:\n",
    "        rgba = matplotlib.cm.gist_heat(\n",
    "            1 - (stringencies[k - 1] - min(stringencies)) / max(stringencies)\n",
    "        )\n",
    "    x = [k - 0.50, k + 0.50]\n",
    "    ax.fill_between(\n",
    "        x, ymin, ymax, color=rgba, alpha=0.6,\n",
    "        edgecolor='None', linewidth=0, zorder=0\n",
    "    )\n",
    "\n",
    "xticks = []\n",
    "xticks_labels = ['Apr 2020', 'Oct 2020', 'Apr 2021', 'Oct 2021', 'Apr 2022']\n",
    "for i in range(0, len(df_ts_class_density['rolling_perchange'])):\n",
    "    if i % 183 == 0:\n",
    "        xticks.append(i)\n",
    "ax.set_xticks(xticks, xticks_labels)\n",
    "ax.tick_params(axis='x', bottom=True, labelsize=23, pad=6, rotation=90)\n",
    "\n",
    "yticks = []\n",
    "for i in range(ymin, ymax):\n",
    "    if i % 25 == 0:\n",
    "        yticks.append(i)\n",
    "ax.set_yticks(yticks, yticks)\n",
    "for y in yticks:\n",
    "    ax.plot(\n",
    "        [0, len(df_ts_class_density['rolling_perchange'])],\n",
    "        [y, y], color='gray', lw=0.7, zorder=0\n",
    "    )\n",
    "ax.tick_params(axis='y', labelsize=23, pad=6, rotation=0)\n",
    "\n",
    "# plt.savefig(wd + '/plots/evolution/' + flows + '/by-density/' + country_short + '/evo_outflows' + capital_suffix + dist_suffix + raw_suffix + adjust_suffix + radius_suffix + '.pdf', bbox_inches = 'tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403010b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.tick_params(\n",
    "    axis='both', which='both', width=0, length=0,\n",
    "    color='k', labelsize=20, pad=9\n",
    ")\n",
    "\n",
    "viridis = plt.cm.get_cmap('viridis')\n",
    "norm = plt.Normalize(0, n_class_density - 1)\n",
    "\n",
    "maxima = []\n",
    "minima = []\n",
    "\n",
    "for i in range(n_class_density):\n",
    "\n",
    "    color = viridis(norm(i))\n",
    "    netflows_class_density = (\n",
    "        df_ts_weekly_inflows_class_density[i, :] -\n",
    "        df_ts_weekly_outflows_class_density[i, :]\n",
    "    )\n",
    "    netflows_baseline_class_density = (\n",
    "        df_ts_weekly_inflows_baseline_class_density[i, :] -\n",
    "        df_ts_weekly_outflows_baseline_class_density[i, :]\n",
    "    )\n",
    "    netflows_perchange = [\n",
    "        (netflows_class_density[i] - netflows_baseline_class_density[i]) /\n",
    "        netflows_baseline_class_density[i] * 100\n",
    "        for i in range(len(netflows_baseline_class_density))\n",
    "    ]\n",
    "    df_ts_weekly_class_density_plot = pd.DataFrame(\n",
    "        {'perchange_class': netflows_perchange}\n",
    "    )\n",
    "\n",
    "#     df_ts_weekly_class_density_plot.loc[:,'rolling_perchange'] = df_ts_weekly_class_density_plot['perchange_class'].rolling(window=6).mean()\n",
    "#     ax.plot(np.arange(len(df_ts_weekly_class_density_plot['rolling_perchange']))*7, df_ts_weekly_class_density_plot['rolling_perchange'], color=color, lw=2, zorder=3)\n",
    "\n",
    "    df_ts_weekly_class_density_plot['rolling_perchange'] = (\n",
    "        df_ts_weekly_class_density_plot['perchange_class']\n",
    "        .ewm(span=10).mean()\n",
    "    )\n",
    "    df_ts_weekly_class_density_plot['rolling_perchange'] = scipy.signal.savgol_filter(\n",
    "        df_ts_weekly_class_density_plot['rolling_perchange'],\n",
    "        window_length=10, polyorder=3\n",
    "    )\n",
    "    ax.plot(\n",
    "        np.arange(len(df_ts_weekly_class_density_plot['rolling_perchange'])) * 7,\n",
    "        df_ts_weekly_class_density_plot['rolling_perchange'],\n",
    "        color=color, lw=5, zorder=3\n",
    "    )\n",
    "\n",
    "    maxima.append(max(df_ts_weekly_class_density_plot['rolling_perchange']))\n",
    "    minima.append(min(df_ts_weekly_class_density_plot['rolling_perchange']))\n",
    "\n",
    "ax.plot(\n",
    "    np.arange(len(df_ts_weekly_class_density_plot['rolling_perchange']) * 7),\n",
    "    np.zeros(len(df_ts_weekly_class_density_plot['rolling_perchange']) * 7),\n",
    "    linestyle=':', color='k'\n",
    ")\n",
    "\n",
    "stringencies = []\n",
    "for date in df_ts_class_density['date']:\n",
    "    stringencies.append(\n",
    "        df_stringency[df_stringency['date'] == date]\n",
    "        .reset_index(drop=True).loc[0, 'stringency_index']\n",
    "    )\n",
    "\n",
    "ymin = -105\n",
    "ymax = 30\n",
    "\n",
    "for k in range(len(df_ts_class_density)):\n",
    "    try:\n",
    "        rgba = matplotlib.cm.gray(\n",
    "            1 - (stringencies[k] - min(stringencies)) / max(stringencies)\n",
    "        )\n",
    "    except:\n",
    "        rgba = matplotlib.cm.gray(\n",
    "            1 - (stringencies[k - 1] - min(stringencies)) / max(stringencies)\n",
    "        )\n",
    "    x = [k - 0.50, k + 0.50]\n",
    "    ax.fill_between(\n",
    "        x, ymin, ymax, color=rgba, alpha=0.4,\n",
    "        edgecolor='None', linewidth=0, zorder=0\n",
    "    )\n",
    "\n",
    "xticks = []\n",
    "xticks_labels = ['Apr 2020', 'Oct 2020', 'Apr 2021', 'Oct 2021', 'Apr 2022']\n",
    "for i in range(0, len(df_ts_class_density['rolling_perchange'])):\n",
    "    if i % 183 == 0:\n",
    "        xticks.append(i)\n",
    "ax.set_xticks(xticks, xticks_labels)\n",
    "ax.tick_params(axis='x', bottom=True, labelsize=23, pad=6, rotation=90)\n",
    "\n",
    "yticks = []\n",
    "for i in range(ymin, ymax):\n",
    "    if i % 25 == 0:\n",
    "        yticks.append(i)\n",
    "ax.set_yticks(yticks, yticks)\n",
    "for y in yticks:\n",
    "    ax.plot(\n",
    "        [0, len(df_ts_class_density['rolling_perchange'])],\n",
    "        [y, y], color='gray', lw=0.7, zorder=0\n",
    "    )\n",
    "ax.tick_params(axis='y', labelsize=23, pad=6, rotation=0)\n",
    "\n",
    "# plt.savefig(wd + '/plots/evolution/' + flows + '/by-density/' + country_short + '/evo_netflows' + capital_suffix + dist_suffix + raw_suffix + adjust_suffix + radius_suffix + '.pdf', bbox_inches = 'tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437a2795",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.tick_params(axis='both', which='both', width=0, length=0, color='k', labelsize=20, pad=9)\n",
    "\n",
    "viridis = plt.cm.get_cmap('viridis')\n",
    "norm = plt.Normalize(0, n_class_density - 1)\n",
    "\n",
    "maxima = []\n",
    "minima = []\n",
    "\n",
    "for i in range(n_class_density):\n",
    "    color = viridis(norm(i))\n",
    "\n",
    "    netflows_class_density = (\n",
    "        df_ts_weekly_inflows_class_density[i, :] -\n",
    "        df_ts_weekly_outflows_class_density[i, :]\n",
    "    )\n",
    "    netflows_baseline_class_density = (\n",
    "        df_ts_weekly_inflows_baseline_class_density[i, :] -\n",
    "        df_ts_weekly_outflows_baseline_class_density[i, :]\n",
    "    )\n",
    "\n",
    "    netflows_perchange = [\n",
    "        (netflows_class_density[j] - netflows_baseline_class_density[j]) /\n",
    "        netflows_baseline_class_density[j] * 100\n",
    "        for j in range(len(netflows_baseline_class_density))\n",
    "    ]\n",
    "\n",
    "    df_ts_weekly_class_density_plot = pd.DataFrame({\n",
    "        'perchange_class': netflows_perchange\n",
    "    })\n",
    "\n",
    "    # Smoothing with EWM + Savitzky-Golay filter\n",
    "    df_ts_weekly_class_density_plot['rolling_perchange'] = (\n",
    "        df_ts_weekly_class_density_plot['perchange_class']\n",
    "        .ewm(span=10)\n",
    "        .mean()\n",
    "    )\n",
    "    df_ts_weekly_class_density_plot['rolling_perchange'] = scipy.signal.savgol_filter(\n",
    "        df_ts_weekly_class_density_plot['rolling_perchange'],\n",
    "        window_length=10,\n",
    "        polyorder=3\n",
    "    )\n",
    "\n",
    "    ax.plot(\n",
    "        np.arange(len(df_ts_weekly_class_density_plot['rolling_perchange'])) * 7,\n",
    "        df_ts_weekly_class_density_plot['rolling_perchange'],\n",
    "        color=color,\n",
    "        lw=5,\n",
    "        zorder=3\n",
    "    )\n",
    "\n",
    "    maxima.append(max(df_ts_weekly_class_density_plot['rolling_perchange']))\n",
    "    minima.append(min(df_ts_weekly_class_density_plot['rolling_perchange']))\n",
    "\n",
    "# Axis limits\n",
    "xmin = -len(df_ts_class_density) * 0.4\n",
    "xmax = len(df_ts_class_density) * 1.05\n",
    "ax.set_xlim([xmin, xmax])\n",
    "\n",
    "# Horizontal zero line\n",
    "ax.plot(\n",
    "    np.arange(len(df_ts_weekly_class_density_plot['rolling_perchange']) * 7),\n",
    "    np.zeros(len(df_ts_weekly_class_density_plot['rolling_perchange']) * 7),\n",
    "    linestyle=':',\n",
    "    color='k'\n",
    ")\n",
    "\n",
    "# Background shading from stringency index\n",
    "stringencies = []\n",
    "for date in df_ts_class_density['date']:\n",
    "    stringencies.append(\n",
    "        df_stringency[df_stringency['date'] == date]\n",
    "        .reset_index(drop=True)\n",
    "        .loc[0, 'stringency_index']\n",
    "    )\n",
    "\n",
    "ymin = -105\n",
    "ymax = 30\n",
    "\n",
    "for k in range(len(df_ts_class_density)):\n",
    "    try:\n",
    "        rgba = matplotlib.cm.gray(\n",
    "            1 - (stringencies[k] - min(stringencies)) / max(stringencies)\n",
    "        )\n",
    "    except:\n",
    "        rgba = matplotlib.cm.gray(\n",
    "            1 - (stringencies[k - 1] - min(stringencies)) / max(stringencies)\n",
    "        )\n",
    "    x = [k - 0.5, k + 0.5]\n",
    "    ax.fill_between(x, ymin, ymax, color=rgba, alpha=0.4, edgecolor='None', linewidth=0, zorder=0)\n",
    "\n",
    "# Custom x-ticks\n",
    "xticks = []\n",
    "xticks_labels = ['Apr 2020', 'Oct 2020', 'Apr 2021', 'Oct 2021', 'Apr 2022']\n",
    "for i in range(0, len(df_ts_class_density['rolling_perchange'])):\n",
    "    if i % 183 == 0:\n",
    "        xticks.append(i + 40)\n",
    "ax.set_xticks(xticks, xticks_labels)\n",
    "ax.tick_params(axis='x', bottom=True, labelsize=17, pad=6, rotation=90)\n",
    "\n",
    "# Custom y-ticks\n",
    "yticks = []\n",
    "for i in range(ymin, ymax):\n",
    "    if i % 25 == 0:\n",
    "        yticks.append(i)\n",
    "ax.set_yticks(yticks, yticks)\n",
    "for y in yticks:\n",
    "    ax.plot(\n",
    "        [0, len(df_ts_class_density['rolling_perchange'])],\n",
    "        [y, y],\n",
    "        color='gray',\n",
    "        lw=0.7,\n",
    "        zorder=0\n",
    "    )\n",
    "ax.tick_params(axis='y', labelsize=17, pad=4, rotation=0)\n",
    "\n",
    "# Secondary y-axis with baseline averages\n",
    "ax1 = ax.twinx()\n",
    "ax1.yaxis.tick_left()\n",
    "netflows_averages = []\n",
    "\n",
    "for i in range(n_class_density):\n",
    "    color = viridis(norm(i))\n",
    "    netflows_baseline_class_density_average = np.mean(\n",
    "        df_ts_weekly_inflows_baseline_class_density[i, :] -\n",
    "        df_ts_weekly_outflows_baseline_class_density[i, :]\n",
    "    )\n",
    "    ax1.plot(\n",
    "        [xmin + (0 - xmin) * 0.1, 0 - (0 - xmin) * 0.1],\n",
    "        [netflows_baseline_class_density_average] * 2,\n",
    "        color=color,\n",
    "        lw=5,\n",
    "        zorder=3\n",
    "    )\n",
    "    netflows_averages.append(netflows_baseline_class_density_average)\n",
    "\n",
    "ymin_ax1 = int(min(netflows_averages) - (max(netflows_averages) - min(netflows_averages)) * 0.2)\n",
    "ymax_ax1 = int(max(netflows_averages) + (max(netflows_averages) - min(netflows_averages)) * 0.2)\n",
    "ax1.set_ylim([ymin_ax1, ymax_ax1])\n",
    "\n",
    "# Custom y-ticks for ax1\n",
    "yticks_ax1 = []\n",
    "for i in range(ymin_ax1, ymax_ax1):\n",
    "    if i % 30000 == 0:\n",
    "        yticks_ax1.append(i)\n",
    "ax1.set_yticks(yticks_ax1, [int(y / 1000) for y in yticks_ax1])\n",
    "ax1.tick_params(axis='both', which='both', width=0, length=0, color='k', pad=9)\n",
    "ax1.tick_params(axis='y', labelsize=17, pad=6, rotation=0)\n",
    "\n",
    "# Label for baseline axis\n",
    "ax1.text(\n",
    "    xmin + (0 - xmin) * 0.45,\n",
    "    ymin_ax1 - (ymax_ax1 - ymin_ax1) * 0.15,\n",
    "    'Pre-pandemic\\nbaseline',\n",
    "    ha='center',\n",
    "    fontsize=14\n",
    ")\n",
    "\n",
    "# Vertical reference line at time zero\n",
    "ax.yaxis.tick_right()\n",
    "ax.plot(\n",
    "    [0.01, 0.01],\n",
    "    [ymin - (ymax - ymin) * 0.05, ymax + (ymax - ymin) * 0.05],\n",
    "    linestyle='-',\n",
    "    color='k',\n",
    "    lw=2,\n",
    "    zorder=20\n",
    ")\n",
    "\n",
    "# Uncomment to save:\n",
    "# plt.savefig(\n",
    "#     wd + '/plots/evolution/' + flows + '/by-density/' + country_short +\n",
    "#     '/evo_netflows' + capital_suffix + dist_suffix + raw_suffix + adjust_suffix +\n",
    "#     radius_suffix + '_including_baseline.pdf',\n",
    "#     bbox_inches='tight'\n",
    "# )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbc23f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "netflows_averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa083c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.tick_params(axis='both', which='both', width=0, length=0, color='k', labelsize=20, pad=9)\n",
    "\n",
    "viridis = plt.cm.get_cmap('viridis')\n",
    "norm = plt.Normalize(0, n_class_density - 1)\n",
    "\n",
    "maxima = []\n",
    "minima = []\n",
    "\n",
    "for i in range(n_class_density):\n",
    "    color = viridis(norm(i))\n",
    "\n",
    "    netflows_class_density = (\n",
    "        df_ts_weekly_inflows_class_density[i, :] -\n",
    "        df_ts_weekly_outflows_class_density[i, :]\n",
    "    )\n",
    "    netflows_baseline_class_density = (\n",
    "        df_ts_weekly_inflows_baseline_class_density[i, :] -\n",
    "        df_ts_weekly_outflows_baseline_class_density[i, :]\n",
    "    )\n",
    "\n",
    "    netflows_perchange = [\n",
    "        (netflows_class_density[j] - netflows_baseline_class_density[j]) /\n",
    "        netflows_baseline_class_density[j] * 100\n",
    "        for j in range(len(netflows_baseline_class_density))\n",
    "    ]\n",
    "\n",
    "    df_ts_weekly_class_density_plot = pd.DataFrame({\n",
    "        'perchange_class': netflows_perchange\n",
    "    })\n",
    "\n",
    "    df_ts_weekly_class_density_plot['rolling_perchange'] = (\n",
    "        df_ts_weekly_class_density_plot['perchange_class']\n",
    "        .ewm(span=10)\n",
    "        .mean()\n",
    "    )\n",
    "    df_ts_weekly_class_density_plot['rolling_perchange'] = scipy.signal.savgol_filter(\n",
    "        df_ts_weekly_class_density_plot['rolling_perchange'],\n",
    "        window_length=10,\n",
    "        polyorder=3\n",
    "    )\n",
    "\n",
    "    if netflows_averages[i] > 0:\n",
    "        ax.plot(\n",
    "            np.arange(len(df_ts_weekly_class_density_plot['rolling_perchange'])) * 7,\n",
    "            df_ts_weekly_class_density_plot['rolling_perchange'],\n",
    "            color=color,\n",
    "            lw=5,\n",
    "            linestyle=':',\n",
    "            dashes=[1, 0.5],\n",
    "            zorder=3\n",
    "        )\n",
    "    elif netflows_averages[i] < 0:\n",
    "        ax.plot(\n",
    "            np.arange(len(df_ts_weekly_class_density_plot['rolling_perchange'])) * 7,\n",
    "            df_ts_weekly_class_density_plot['rolling_perchange'],\n",
    "            color=color,\n",
    "            lw=5,\n",
    "            zorder=3\n",
    "        )\n",
    "\n",
    "    maxima.append(max(df_ts_weekly_class_density_plot['rolling_perchange']))\n",
    "    minima.append(min(df_ts_weekly_class_density_plot['rolling_perchange']))\n",
    "\n",
    "# Zero reference line\n",
    "ax.plot(\n",
    "    np.arange(len(df_ts_weekly_class_density_plot['rolling_perchange']) * 7),\n",
    "    np.zeros(len(df_ts_weekly_class_density_plot['rolling_perchange']) * 7),\n",
    "    linestyle=':',\n",
    "    color='k'\n",
    ")\n",
    "\n",
    "# Background shading from stringency index\n",
    "stringencies = []\n",
    "for date in df_ts_class_density['date']:\n",
    "    stringencies.append(\n",
    "        df_stringency[df_stringency['date'] == date]\n",
    "        .reset_index(drop=True)\n",
    "        .loc[0, 'stringency_index']\n",
    "    )\n",
    "\n",
    "ymin = -105\n",
    "ymax = 30\n",
    "\n",
    "for k in range(len(df_ts_class_density)):\n",
    "    try:\n",
    "        rgba = matplotlib.cm.gray(\n",
    "            1 - (stringencies[k] - min(stringencies)) / max(stringencies)\n",
    "        )\n",
    "    except:\n",
    "        rgba = matplotlib.cm.gray(\n",
    "            1 - (stringencies[k - 1] - min(stringencies)) / max(stringencies)\n",
    "        )\n",
    "    x = [k - 0.5, k + 0.5]\n",
    "    ax.fill_between(x, ymin, ymax, color=rgba, alpha=0.4, edgecolor='None', linewidth=0, zorder=0)\n",
    "\n",
    "# Custom x-ticks\n",
    "xticks = []\n",
    "xticks_labels = ['Apr 2020', 'Oct 2020', 'Apr 2021', 'Oct 2021', 'Apr 2022']\n",
    "for i in range(0, len(df_ts_class_density['rolling_perchange'])):\n",
    "    if i % 183 == 0:\n",
    "        xticks.append(i)\n",
    "ax.set_xticks(xticks, xticks_labels)\n",
    "ax.tick_params(axis='x', bottom=True, labelsize=23, pad=6, rotation=90)\n",
    "\n",
    "# Custom y-ticks\n",
    "yticks = []\n",
    "for i in range(ymin, ymax):\n",
    "    if i % 25 == 0:\n",
    "        yticks.append(i)\n",
    "ax.set_yticks(yticks, yticks)\n",
    "for y in yticks:\n",
    "    ax.plot(\n",
    "        [0, len(df_ts_class_density['rolling_perchange'])],\n",
    "        [y, y],\n",
    "        color='gray',\n",
    "        lw=0.7,\n",
    "        zorder=0\n",
    "    )\n",
    "ax.tick_params(axis='y', labelsize=23, pad=6, rotation=0)\n",
    "\n",
    "# Save and show\n",
    "plt.savefig(\n",
    "    wd + '/plots/evolution/' + flows + '/by-density/' + country_short +\n",
    "    '/evo_netflows' + capital_suffix + dist_suffix + raw_suffix +\n",
    "    adjust_suffix + radius_suffix + '_no_baseline.pdf',\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12010346",
   "metadata": {},
   "source": [
    "# Transforming the trend DataFrame to long format and saving it as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682175ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise trend DataFrame with weeks as columns\n",
    "df_trend = pd.DataFrame(\n",
    "    columns=[df_ts_weekly_inflows.loc[i, 'week_start'] for i in range(len(df_ts_weekly_inflows))]\n",
    ")\n",
    "\n",
    "# Compute trend component for each class density\n",
    "for i in range(n_class_density):\n",
    "    netflows_class_density = (\n",
    "        df_ts_weekly_inflows_class_density[i, :] - df_ts_weekly_outflows_class_density[i, :]\n",
    "    )\n",
    "    netflows_baseline_class_density = (\n",
    "        df_ts_weekly_inflows_baseline_class_density[i, :] - df_ts_weekly_outflows_baseline_class_density[i, :]\n",
    "    )\n",
    "\n",
    "    netflows_perchange = [\n",
    "        (netflows_class_density[j] - netflows_baseline_class_density[j]) /\n",
    "        netflows_baseline_class_density[j] * 100\n",
    "        for j in range(len(netflows_baseline_class_density))\n",
    "    ]\n",
    "\n",
    "    series = pd.DataFrame({\n",
    "        'index': pd.to_datetime(df_ts_weekly_inflows['week_start']),\n",
    "        'value': netflows_perchange\n",
    "    })\n",
    "    series.set_index('index', inplace=True)\n",
    "\n",
    "    try:\n",
    "        result = seasonal_decompose(series, model='additive', extrapolate_trend='freq')\n",
    "        df_trend.loc[i] = result.trend.values\n",
    "    except Exception as e:\n",
    "        print(f'Not possible for class {i}: {e}')\n",
    "\n",
    "# Convert to long format\n",
    "time = []\n",
    "cat = []\n",
    "y = []\n",
    "\n",
    "for i in range(len(df_trend)):\n",
    "    for j, col in enumerate(df_trend.columns):\n",
    "        time.append(j)\n",
    "        cat.append(i)\n",
    "        y.append(df_trend.loc[i, col])\n",
    "\n",
    "df_trend_long = pd.DataFrame({\n",
    "    'time': time,\n",
    "    'cat': cat,\n",
    "    'y': y\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "df_trend_long.to_csv(\n",
    "    wd + '/data/outputs/' + country_short + '/mov-analysis/by-density/trend' + capital_suffix + '.csv',\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8296b3",
   "metadata": {},
   "source": [
    "# Transforming the time series to long format and saving it as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da84a639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame to hold time series data (rows: density classes, columns: week_start dates)\n",
    "df_ts = pd.DataFrame(\n",
    "    columns=[df_ts_weekly_inflows.loc[i, 'week_start'] for i in range(len(df_ts_weekly_inflows))]\n",
    ")\n",
    "\n",
    "# Calculate netflow % changes for each density class and store in df_ts\n",
    "for i in range(n_class_density):\n",
    "    netflows_class_density = (\n",
    "        df_ts_weekly_inflows_class_density[i, :] - df_ts_weekly_outflows_class_density[i, :]\n",
    "    )\n",
    "    netflows_baseline_class_density = (\n",
    "        df_ts_weekly_inflows_baseline_class_density[i, :] - df_ts_weekly_outflows_baseline_class_density[i, :]\n",
    "    )\n",
    "\n",
    "    netflows_perchange = [\n",
    "        (netflows_class_density[j] - netflows_baseline_class_density[j]) /\n",
    "        netflows_baseline_class_density[j] * 100\n",
    "        for j in range(len(netflows_baseline_class_density))\n",
    "    ]\n",
    "\n",
    "    series = pd.DataFrame({\n",
    "        'index': pd.to_datetime(df_ts_weekly_inflows['week_start']),\n",
    "        'value': netflows_perchange\n",
    "    })\n",
    "    series.set_index('index', inplace=True)\n",
    "\n",
    "    try:\n",
    "        seasonal_decompose(series, model='additive', extrapolate_trend='freq')\n",
    "        df_ts.loc[i] = series['value']\n",
    "    except Exception as e:\n",
    "        print(f'Not possible for class {i}: {e}')\n",
    "\n",
    "# Reshape from wide to long format\n",
    "time = []\n",
    "cat = []\n",
    "y = []\n",
    "\n",
    "for i in range(len(df_ts)):\n",
    "    for j, col in enumerate(df_ts.columns):\n",
    "        time.append(j)\n",
    "        cat.append(i)\n",
    "        y.append(df_ts.loc[i, col])\n",
    "\n",
    "df_ts_long = pd.DataFrame({\n",
    "    'time': time,\n",
    "    'cat': cat,\n",
    "    'y': y\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "df_ts_long.to_csv(\n",
    "    wd + '/data/outputs/' + country_short + '/mov-analysis/by-density/time_series' + capital_suffix + '.csv',\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f10588a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(len(netflows_perchange)), netflows_perchange)\n",
    "ax.plot(np.arange(len(netflows_perchange)), result.trend)\n",
    "ax.plot(np.arange(len(netflows_perchange)), result.seasonal)\n",
    "ax.plot(np.arange(len(netflows_perchange)), df_trend.loc[0])\n",
    "ax.plot(np.arange(len(netflows_perchange)), df_trend.loc[1])\n",
    "ax.plot(np.arange(len(netflows_perchange)), df_trend.loc[2])\n",
    "ax.plot(np.arange(len(netflows_perchange)), df_trend.loc[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804f8187",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Axis style\n",
    "ax.tick_params(axis='both', which='both', width=0, length=0, color='k', labelsize=20, pad=9)\n",
    "\n",
    "# Colormap setup\n",
    "viridis = plt.cm.get_cmap('viridis')\n",
    "norm = plt.Normalize(0, n_class_density - 1)\n",
    "\n",
    "maxima = []\n",
    "minima = []\n",
    "\n",
    "for i in range(n_class_density):\n",
    "    color = viridis(norm(i)) \n",
    "    \n",
    "    # Compute absolute netflows\n",
    "    netflows_class_density = df_ts_weekly_inflows_class_density[i, :] - df_ts_weekly_outflows_class_density[i, :]\n",
    "    netflows_baseline_class_density = df_ts_weekly_inflows_baseline_class_density[i, :] - df_ts_weekly_outflows_baseline_class_density[i, :]\n",
    "\n",
    "    df_plot = pd.DataFrame({'perchange_class': netflows_class_density})\n",
    "    df_baseline_plot = pd.DataFrame({'perchange_class': netflows_baseline_class_density})\n",
    "    \n",
    "    # Smooth data using EWM and Savitzky-Golay filter\n",
    "    df_plot['rolling_perchange'] = df_plot['perchange_class'].ewm(span=10).mean()\n",
    "    df_plot['rolling_perchange'] = scipy.signal.savgol_filter(df_plot['rolling_perchange'], window_length=10, polyorder=3)\n",
    "    \n",
    "    df_baseline_plot['rolling_perchange'] = df_baseline_plot['perchange_class'].ewm(span=10).mean()\n",
    "    df_baseline_plot['rolling_perchange'] = scipy.signal.savgol_filter(df_baseline_plot['rolling_perchange'], window_length=10, polyorder=3)\n",
    "    \n",
    "    # Plot density class curve\n",
    "    ax.plot(np.arange(len(df_plot['rolling_perchange'])) * 7, df_plot['rolling_perchange'], color=color, lw=5, zorder=3)\n",
    "    # Optional: Baseline dashed line\n",
    "    # ax.plot(np.arange(len(df_baseline_plot['rolling_perchange'])) * 7, df_baseline_plot['rolling_perchange'], color=color, lw=2, linestyle=':', zorder=3)\n",
    "\n",
    "    maxima.append(max(df_plot['rolling_perchange']))\n",
    "    minima.append(min(df_plot['rolling_perchange']))\n",
    "\n",
    "# Optional zero line\n",
    "# ax.plot(np.arange(len(df_plot['rolling_perchange']) * 7), np.zeros(len(df_plot['rolling_perchange']) * 7), linestyle=':', color='k')\n",
    "\n",
    "# Background shading: stringency index\n",
    "stringencies = []\n",
    "for date in df_ts_class_density['date']:\n",
    "    try:\n",
    "        stringency = df_stringency[df_stringency['date'] == date].reset_index(drop=True).loc[0, 'stringency_index']\n",
    "    except:\n",
    "        stringency = df_stringency[df_stringency['date'] == date].reset_index(drop=True).loc[0, 'stringency_index']\n",
    "    stringencies.append(stringency)\n",
    "\n",
    "ymin = int(min(minima)) - 2500\n",
    "ymax = int(max(maxima)) + 2500\n",
    "\n",
    "for k in range(len(df_ts_class_density)):\n",
    "    try:\n",
    "        rgba = matplotlib.cm.gist_heat(1 - (stringencies[k] - min(stringencies)) / max(stringencies))\n",
    "    except:\n",
    "        rgba = matplotlib.cm.gist_heat(1 - (stringencies[k - 1] - min(stringencies)) / max(stringencies))\n",
    "    \n",
    "    ax.fill_between([k - 0.5, k + 0.5], ymin, ymax, color=rgba, alpha=0.6, edgecolor='None', linewidth=0, zorder=0)\n",
    "\n",
    "# X-axis ticks: every ~6 months\n",
    "xticks = []\n",
    "xticks_labels = ['Apr 2020', 'Oct 2020', 'Apr 2021', 'Oct 2021', 'Apr 2022']\n",
    "for i in range(0, len(df_ts_class_density['rolling_perchange'])):\n",
    "    if i % 183 == 0:\n",
    "        xticks.append(i)\n",
    "ax.set_xticks(xticks, xticks_labels)\n",
    "ax.tick_params(axis='x', bottom=True, labelsize=23, pad=6, rotation=90)\n",
    "\n",
    "# Y-axis ticks\n",
    "yticks = [i for i in range(ymin, ymax) if i % 10000 == 0]\n",
    "ax.set_yticks(yticks, yticks)\n",
    "for y in yticks:\n",
    "    ax.plot([0, len(df_ts_class_density['rolling_perchange'])], [y, y], color='gray', lw=0.7, zorder=0)\n",
    "ax.tick_params(axis='y', labelsize=23, pad=6)\n",
    "\n",
    "# plt.savefig(wd + '/plots/evolution/' + flows + '/by-density/' + country_short + '/evo_netflows_absolute' + capital_suffix + dist_suffix + raw_suffix + adjust_suffix + radius_suffix + '.pdf', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
