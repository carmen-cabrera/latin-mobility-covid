{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124b809a",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2c1d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "from matplotlib import colors as mcolors\n",
    "from mycolorpy import colorlist as mcp\n",
    "import matplotlib\n",
    "import geopandas as gpd\n",
    "from datetime import datetime, timedelta\n",
    "import jenkspy\n",
    "import warnings\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0776c3ab",
   "metadata": {},
   "source": [
    "# Define country and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7056f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select target country\n",
    "country = 'Colombia'\n",
    "\n",
    "# Set country-specific parameters: ISO codes and buffer size (in meters)\n",
    "if country == 'Argentina':\n",
    "    country_short = 'ARG'   # ISO 3-letter code\n",
    "    country_code = 'AR'     # ISO 2-letter code\n",
    "elif country == 'Chile':\n",
    "    country_short = 'CHL'\n",
    "    country_code = 'CL'\n",
    "elif country == 'Colombia':\n",
    "    country_short = 'COL'\n",
    "    country_code = 'CO'\n",
    "# Uncomment the following if Mexico is to be included in the analysis\n",
    "# elif country == 'Mexico':\n",
    "#     country_short = 'MEX'\n",
    "#     country_code = 'MX'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a95263a",
   "metadata": {},
   "source": [
    "# Set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c8807e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define working directory path\n",
    "wd = (\n",
    "    '/your/path/to/working/directory/'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f94f70b",
   "metadata": {},
   "source": [
    "# Set parameters: place of interest? and stringency as predictor? \n",
    "And import necessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed52b73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "place = 'fuas' # or 'capital'\n",
    "stringency = True # or False\n",
    "\n",
    "if stringency == True:\n",
    "    df = pd.read_csv(wd + '/data/outputs/' + country_short + '/mov-analysis/by-' + category + '/data_trend_netflows_' + place + '_param_tidy_results_cat.csv')\n",
    "    df_m3_re = pd.read_csv(wd + '/data/outputs/' + country_short + '/mov-analysis/by-' + category + '/data_trend_param_' + place + '_m3cat_re.csv')\n",
    "    df_m4_re = pd.read_csv(wd + '/data/outputs/' + country_short + '/mov-analysis/by-' + category + '/data_trend_param_' + place + '_m4cat_re.csv')\n",
    "    df_m5_re = pd.read_csv(wd + '/data/outputs/' + country_short + '/mov-analysis/by-' + category + '/data_trend_param_' + place + '_m5cat_re.csv')\n",
    "    df_m6_re = pd.read_csv(wd + '/data/outputs/' + country_short + '/mov-analysis/by-' + category + '/data_trend_param_' + place + '_m6cat_re.csv')\n",
    "    df_m7_re = pd.read_csv(wd + '/data/outputs/' + country_short + '/mov-analysis/by-' + category + '/data_trend_param_' + place + '_m7cat_re.csv')\n",
    "else:\n",
    "    df = pd.read_csv(wd + '/data/outputs/' + country_short + '/mov-analysis/by-' + category + '/data_trend_netflows_' + place + '_param_tidy_results_cats.csv')\n",
    "    df_m3_re = pd.read_csv(wd + '/data/outputs/' + country_short + '/mov-analysis/by-' + category + '/data_trend_param_' + place + '_m3cats_re.csv')\n",
    "    df_m4_re = pd.read_csv(wd + '/data/outputs/' + country_short + '/mov-analysis/by-' + category + '/data_trend_param_' + place + '_m4cats_re.csv')\n",
    "    df_m5_re = pd.read_csv(wd + '/data/outputs/' + country_short + '/mov-analysis/by-' + category + '/data_trend_param_' + place + '_m5cats_re.csv')\n",
    "    df_m6_re = pd.read_csv(wd + '/data/outputs/' + country_short + '/mov-analysis/by-' + category + '/data_trend_param_' + place + '_m6cats_re.csv')\n",
    "    df_m7_re = pd.read_csv(wd + '/data/outputs/' + country_short + '/mov-analysis/by-' + category + '/data_trend_param_' + place + '_m7cats_re.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd3f754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select model\n",
    "model = 6\n",
    "\n",
    "# Filter fixed effects by selected model\n",
    "df_model = df[df['model'] == model].reset_index(drop=True)\n",
    "\n",
    "# Extract fixed effect intercept\n",
    "fe_intercept = df_model[df_model['term'].str.contains('Intercept')]['estimate'].reset_index(drop=True).loc[0]\n",
    "\n",
    "# Compute total intercepts: fixed + random effects\n",
    "if model == 6:\n",
    "    re_intercept = df_m6_re[df_m6_re['facet'].str.contains('Intercept')].reset_index(drop=True)\n",
    "    intercept = [fe_intercept + re_intercept['estimate'].loc[i] for i in range(len(np.unique(df_m6_re['term'])))]\n",
    "elif model == 5:\n",
    "    re_intercept = df_m5_re[df_m5_re['facet'].str.contains('Intercept')].reset_index(drop=True)\n",
    "    intercept = [fe_intercept + re_intercept['estimate'].loc[i] for i in range(len(np.unique(df_m5_re['term'])))]\n",
    "\n",
    "# Extract fixed effect slope\n",
    "fe_slope = df_model[df_model['term'] == 'time']['estimate'].reset_index(drop=True).loc[0]\n",
    "\n",
    "# Compute total slopes: fixed + random effects\n",
    "if model == 6:\n",
    "    re_slope = df_m6_re[df_m6_re['facet'] == 'time'].reset_index(drop=True)\n",
    "    slope = [fe_slope + re_slope['estimate'].loc[i] for i in range(len(np.unique(df_m6_re['term'])))]\n",
    "elif model == 5:\n",
    "    re_slope = df_m5_re[df_m5_re['facet'] == 'time'].reset_index(drop=True)\n",
    "    slope = [fe_slope + re_slope['estimate'].loc[i] for i in range(len(np.unique(df_m5_re['term'])))]\n",
    "\n",
    "# Handle stringency interaction term if present\n",
    "try:\n",
    "    stringency = [\n",
    "        df_model[df_model['term'] == 'stringency_index']['estimate'].reset_index(drop=True).loc[0]\n",
    "        for i in range(len(intercept))\n",
    "    ]\n",
    "except:\n",
    "    stringency = [0 for i in range(len(intercept))]\n",
    "\n",
    "# Add stringency effect to slopes\n",
    "slope = [slope[i] + stringency[i] for i in range(len(slope))]\n",
    "\n",
    "# Extract quadratic term for time if model == 6\n",
    "if model == 6:\n",
    "    quad = [\n",
    "        df_model[df_model['term'] == 'time2']['estimate'].reset_index(drop=True).loc[0]\n",
    "        for i in range(len(intercept))\n",
    "    ]\n",
    "\n",
    "# --- Standard errors ---\n",
    "\n",
    "# Intercept standard error\n",
    "fe_intercept_std = df_model[df_model['term'].str.contains('Intercept')]['std.error'].reset_index(drop=True).loc[0]\n",
    "\n",
    "# Random intercept confidence intervals\n",
    "if model == 6:\n",
    "    re_intercept = df_m6_re[df_m6_re['facet'].str.contains('Intercept')].reset_index(drop=True)\n",
    "elif model == 5:\n",
    "    re_intercept = df_m5_re[df_m5_re['facet'].str.contains('Intercept')].reset_index(drop=True)\n",
    "\n",
    "re_intercept_ci = [\n",
    "    re_intercept.loc[i, 'conf.high'] - re_intercept.loc[i, 'conf.low']\n",
    "    for i in range(len(re_intercept))\n",
    "]\n",
    "\n",
    "# Convert CI to standard deviation assuming normal distribution\n",
    "re_intercept_std = [ci / (2 * 1.96) for ci in re_intercept_ci]\n",
    "\n",
    "# Combine fixed + random intercept std if desired (currently only fixed used)\n",
    "# intercept_std = [np.sqrt(fe_intercept_std**2 + std**2) for std in re_intercept_std]\n",
    "intercept_std = [np.sqrt(fe_intercept_std**2) for std in re_intercept_std]\n",
    "\n",
    "# Time slope standard error\n",
    "fe_time_std = df_model[df_model['term'] == 'time']['std.error'].reset_index(drop=True).loc[0]\n",
    "\n",
    "# Stringency std error (if present)\n",
    "try:\n",
    "    fe_stringency_std = df_model[df_model['term'] == 'stringency_index']['std.error'].reset_index(drop=True).loc[0]\n",
    "except:\n",
    "    fe_stringency_std = 0\n",
    "\n",
    "# Random slope confidence intervals\n",
    "if model == 6:\n",
    "    re_time = df_m6_re[df_m6_re['facet'].str.contains('time')].reset_index(drop=True)\n",
    "elif model == 5:\n",
    "    re_time = df_m5_re[df_m5_re['facet'].str.contains('time')].reset_index(drop=True)\n",
    "\n",
    "re_time_ci = [\n",
    "    re_time.loc[i, 'conf.high'] - re_time.loc[i, 'conf.low']\n",
    "    for i in range(len(re_time))\n",
    "]\n",
    "\n",
    "# Convert CI to standard deviation assuming normal distribution\n",
    "re_time_std = [ci / (2 * 1.96) for ci in re_time_ci]\n",
    "\n",
    "# Combine fixed stds only (random component excluded in current calc)\n",
    "# slope_std = [np.sqrt(fe_time_std**2 + fe_stringency_std**2 + std**2) for std in re_time_std]\n",
    "slope_std = [np.sqrt(fe_time_std**2 + fe_stringency_std**2) for std in re_time_std]\n",
    "\n",
    "# Quadratic term std error\n",
    "if model == 6:\n",
    "    fe_quad_std = df_model[df_model['term'] == 'time2']['std.error'].reset_index(drop=True).loc[0]\n",
    "if model == 5:\n",
    "    fe_quad_std = 0\n",
    "\n",
    "quad_std = [fe_quad_std for i in range(len(slope_std))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66451b97",
   "metadata": {},
   "source": [
    "# Compute recovery time for recovery thresholds 25, 50, 75, 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63447248",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [25, 50, 75, 100]  # Percentage thresholds to evaluate\n",
    "times = []       # Store calculated times for each threshold\n",
    "times_std = []   # Store standard deviations of times for each threshold\n",
    "\n",
    "for thr in thresholds:\n",
    "    times_thr = []      # Times for the current threshold across groups\n",
    "    times_thr_std = []  # Std devs for the current threshold across groups\n",
    "    \n",
    "    for i in range(len(intercept)):\n",
    "        # If both intercept and slope are positive, time threshold undefined (set -1)\n",
    "        if intercept[i] > 0 and slope[i] > 0:\n",
    "            times_thr.append(-1)\n",
    "            times_thr_std.append(-1)\n",
    "        \n",
    "        else:  \n",
    "            # Model 6: quadratic form: solve quadratic equation for time_thr\n",
    "            if model == 6:\n",
    "                discriminant = slope[i]**2 - 4 * quad[i] * (thr / 100) * intercept[i]\n",
    "                \n",
    "                # Calculate roots only if discriminant is non-negative\n",
    "                if discriminant >= 0:\n",
    "                    # Calculate first root\n",
    "                    time_thr = (-slope[i] + np.sqrt(discriminant)) / (2 * quad[i])\n",
    "                    \n",
    "                    if time_thr > 0:\n",
    "                        times_thr.append(time_thr)\n",
    "                        # Partial derivatives for error propagation\n",
    "                        partial_intercept = (-(thr / 100)) / np.sqrt(discriminant)\n",
    "                        partial_slope = (1 / quad[i]) * (-1 + slope[i] / np.sqrt(discriminant))\n",
    "                        partial_quad = (-(thr / 100) * intercept[i]) / (quad[i] * np.sqrt(discriminant)) + \\\n",
    "                                       (slope[i] - np.sqrt(discriminant)) / (2 * quad[i]**2)\n",
    "                    \n",
    "                    else:\n",
    "                        # Calculate second root if first root is negative\n",
    "                        time_thr = (-slope[i] - np.sqrt(discriminant)) / (2 * quad[i])\n",
    "                        times_thr.append(time_thr)\n",
    "                        # Partial derivatives for error propagation (alternate root)\n",
    "                        partial_intercept = (thr / 100) / np.sqrt(discriminant)\n",
    "                        partial_slope = (1 / quad[i]) * (-1 - slope[i] / np.sqrt(discriminant))\n",
    "                        partial_quad = ((thr / 100) * intercept[i]) / (quad[i] * np.sqrt(discriminant)) + \\\n",
    "                                       (slope[i] + np.sqrt(discriminant)) / (2 * quad[i]**2)\n",
    "                    \n",
    "                    # Calculate standard deviation for time_thr via error propagation\n",
    "                    time_thr_std = np.sqrt(\n",
    "                        (partial_intercept * intercept_std[i])**2 +\n",
    "                        (partial_slope * slope_std[i])**2 +\n",
    "                        (partial_quad * quad_std[i])**2\n",
    "                    )\n",
    "                    times_thr_std.append(time_thr_std)\n",
    "                \n",
    "                else:\n",
    "                    # If discriminant is negative, solution is complex -> NaN\n",
    "                    times_thr.append(np.nan)\n",
    "                    times_thr_std.append(np.nan)\n",
    "            \n",
    "            # Model 5: linear form, direct calculation of time_thr\n",
    "            elif model == 5:\n",
    "                time_thr = - (thr / 100) * (intercept[i] / slope[i])\n",
    "                times_thr.append(time_thr) \n",
    "                \n",
    "                # Partial derivatives for error propagation in linear model\n",
    "                partial_intercept = -(thr / 100) / slope[i]\n",
    "                partial_slope = ((thr / 100) * intercept[i]) / (slope[i]**2)\n",
    "                \n",
    "                # Calculate std deviation for time_thr\n",
    "                time_thr_std = np.sqrt(\n",
    "                    (partial_intercept * intercept_std[i])**2 +\n",
    "                    (partial_slope * slope_std[i])**2\n",
    "                )\n",
    "                times_thr_std.append(time_thr_std)\n",
    "    \n",
    "    # Append results for the current threshold\n",
    "    times.append(times_thr)\n",
    "    times_std.append(times_thr_std)\n",
    "\n",
    "print(times)\n",
    "print(times_std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
