{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9de9cc6c",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730e4fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd50c5c",
   "metadata": {},
   "source": [
    "# Set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35062d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the working directory where project files are stored\n",
    "wd = (\n",
    "    \"/Users/carmen/Library/CloudStorage/OneDrive-TheUniversityofLiverpool/\"\n",
    "    \"Research/RECAST/latin-mobility-covid-local-files\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8772e29",
   "metadata": {},
   "source": [
    "# Define country and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589b83b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the target country for analysis\n",
    "country = \"Colombia\"\n",
    "\n",
    "# Set country-specific parameters based on the selected country\n",
    "if country == \"Argentina\":\n",
    "    country_short = \"ARG\"  # ISO 3-letter country code\n",
    "    country_code = \"AR\"    # ISO 2-letter country code\n",
    "    buffer = 4000          # Buffer size in meters for spatial processing (chosen empirically)\n",
    "elif country == \"Chile\":\n",
    "    country_short = \"CHL\"\n",
    "    country_code = \"CL\"\n",
    "    buffer = 4000\n",
    "elif country == \"Colombia\":\n",
    "    country_short = \"COL\"\n",
    "    country_code = \"CO\"\n",
    "    buffer = 2000\n",
    "# Uncomment the following if Mexico is to be included in the analysis\n",
    "# elif country == \"Mexico\":\n",
    "#     country_short = \"MEX\"\n",
    "#     country_code = \"MX\"\n",
    "#     buffer = 4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419034e1",
   "metadata": {},
   "source": [
    "# Test: load population grid and plot buffers for sample population data\n",
    "\n",
    "**Note:** Do the buffers around the population data fall within the grid cells? If that's the case, grid works and is in the right resolution for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa02d0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory path for Facebook population data for the selected country\n",
    "directory = f\"/Volumes/RECAST/data/populations/facebook/{country}\"\n",
    "\n",
    "# List all files in the directory\n",
    "files = os.listdir(directory)\n",
    "\n",
    "# Filter to include only files that contain '_0800.csv' (likely representing 08:00 time data)\n",
    "files = [file for file in files if '_0800.csv' in file]\n",
    "\n",
    "# Load the Facebook population grid shapefile for the country and convert it to EPSG:4326 (WGS 84) coordinate system\n",
    "grid_path = f\"{wd}/data/inputs/grids/Grid_{country}_FB_pop/Grid_{country}.shp\"\n",
    "grid_pop = gpd.read_file(grid_path).to_crs(\"EPSG:4326\")\n",
    "\n",
    "# Load a specific CSV file for testing (e.g., the 701st file matching '_0800.csv') into a DataFrame\n",
    "df_pops = pd.read_csv(f\"{directory}/{files[700]}\")\n",
    "\n",
    "# Filter the DataFrame to include only rows matching the selected country code,\n",
    "# then reset the index\n",
    "df_pops = df_pops[df_pops[\"country\"] == country_code].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Convert the population DataFrame into a GeoDataFrame by creating Point geometries\n",
    "# from the 'lon' (longitude) and 'lat' (latitude) columns\n",
    "gdf_pops = gpd.GeoDataFrame(\n",
    "    df_pops,\n",
    "    geometry=gpd.points_from_xy(df_pops[\"lon\"], df_pops[\"lat\"]),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# Create a figure and axes object with a 15x15 inch size\n",
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "# Plot the population grid polygons with thin white edges\n",
    "grid_pop.plot(ax=ax, linewidth=0.1, edgecolor=\"white\", zorder=1)\n",
    "\n",
    "# Create buffer zones (in meters) around each point after projecting to EPSG:3857,\n",
    "# then reproject the result back to EPSG:4326\n",
    "gdf_buff = (\n",
    "    gdf_pops.to_crs(\"EPSG:3857\")\n",
    "    .buffer(buffer)\n",
    "    .to_crs(\"EPSG:4326\")\n",
    ")\n",
    "\n",
    "# Plot the buffer zones in red\n",
    "gdf_buff.plot(ax=ax, color=\"red\", zorder=2)\n",
    "\n",
    "# Set the visible map extent (longitude and latitude bounds)\n",
    "ax.set_xlim(-75, -74)\n",
    "ax.set_ylim(4, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dff053",
   "metadata": {},
   "source": [
    "# Computation of population grid cell size \n",
    "... to chose the size of buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47251b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the side (in km) of a typical cell (geometry at index 1000)\n",
    "# Convert geometry to EPSG:3857 (meters), get area in mÂ², take square root, and convert to kilometers\n",
    "\n",
    "area_sqrt_km = np.sqrt(grid_pop.to_crs('epsg:3857').loc[1000, 'geometry'].area) / 1000\n",
    "print(area_sqrt_km)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bf5deb",
   "metadata": {},
   "source": [
    "# Add Feature IDs (FID) to population data and save processed files\n",
    "\n",
    "**Note:** This process can be optimised by using the `quadkey2` package. Update in the future!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afe985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory path for Facebook population data based on the selected country\n",
    "directory = f\"/Volumes/RECAST/data/populations/facebook/{country}\"\n",
    "\n",
    "# List and sort all files in the directory to have a consistent order\n",
    "files = sorted(os.listdir(directory))\n",
    "\n",
    "# Filter the sorted list to include only files containing '_0800.csv'\n",
    "files = [file for file in files if '_0800.csv' in file]\n",
    "\n",
    "# Loop through each file for processing\n",
    "for i in range(len(files)):\n",
    "\n",
    "    # Print progress every 50 files as a percentage completed\n",
    "    if i % 50 == 0:\n",
    "        print(f\"{(i / len(files)) * 100:.2f}% processed\")\n",
    "\n",
    "    try:\n",
    "        file = files[i]\n",
    "\n",
    "        # Load population data from CSV for the current file\n",
    "        df_pops = pd.read_csv(f\"{directory}/{file}\")\n",
    "\n",
    "        # Filter rows by country code and reset index\n",
    "        df_pops = df_pops[df_pops[\"country\"] == country_code].reset_index(drop=True)\n",
    "\n",
    "        index_to_drop = []\n",
    "        # Initialize 'FID' column with -1\n",
    "        df_pops[\"FID\"] = -1\n",
    "\n",
    "        # Loop through each row to find the grid cell intersecting the buffered point\n",
    "        for j in range(len(df_pops)):\n",
    "            try:\n",
    "                # Create a GeoDataFrame with a point geometry at (lon, lat)\n",
    "                point = gpd.GeoDataFrame(\n",
    "                    {\"geometry\": [Point(df_pops.loc[j, \"lon\"], df_pops.loc[j, \"lat\"])]},\n",
    "                    crs=\"EPSG:4326\",\n",
    "                )\n",
    "\n",
    "                # Buffer the point in meters (via EPSG:3857), then back to EPSG:4326\n",
    "                buffered_point = (\n",
    "                    point.to_crs(\"EPSG:3857\").buffer(buffer).to_crs(\"EPSG:4326\")\n",
    "                )\n",
    "\n",
    "                # Check which grid geometries intersect with the buffered point\n",
    "                overlap_point = buffered_point[0].intersects(grid_pop[\"geometry\"])\n",
    "\n",
    "                # Find the first matching grid polygon and assign its Feature ID (FID) to the row\n",
    "                matched_indices = np.where(overlap_point)[0]\n",
    "                if len(matched_indices) > 0:\n",
    "                    df_pops.loc[j, \"FID\"] = grid_pop.loc[matched_indices[0], \"FID\"]\n",
    "                else:\n",
    "                    # If no overlap, mark for dropping\n",
    "                    index_to_drop.append(j)\n",
    "\n",
    "            except Exception as e:\n",
    "                # If error processing this row, mark it for dropping\n",
    "                index_to_drop.append(j)\n",
    "\n",
    "        # Drop rows where no grid polygon matched or error occurred\n",
    "        df_pops = df_pops.drop(index_to_drop).reset_index(drop=True)\n",
    "\n",
    "        # Save the processed DataFrame to output directory\n",
    "        output_path = f\"{wd}/data/outputs/{country_short}/pop/{file}\"\n",
    "        df_pops.to_csv(output_path, index=False)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Log the index of the file that caused an error\n",
    "        print(f\"Error processing file index {i}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
