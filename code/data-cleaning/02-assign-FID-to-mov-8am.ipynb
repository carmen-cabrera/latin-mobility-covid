{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a347bcda",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022a129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8626c8b",
   "metadata": {},
   "source": [
    "# Set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32260d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define working directory path\n",
    "wd = (\n",
    "    '/Users/carmen/Library/CloudStorage/OneDrive-TheUniversityofLiverpool/'\n",
    "    'Research/RECAST/latin-mobility-covid-local-files'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dc8581",
   "metadata": {},
   "source": [
    "# Define country and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7df3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select target country\n",
    "country = 'Colombia'\n",
    "\n",
    "# Set country-specific parameters: ISO codes and buffer size (in meters)\n",
    "if country == 'Argentina':\n",
    "    country_short = 'ARG'   # ISO 3-letter code\n",
    "    country_code = 'AR'     # ISO 2-letter code\n",
    "    buffer = 8000           # Buffer size in meters for spatial processing (chosen empirically)\n",
    "elif country == 'Chile':\n",
    "    country_short = 'CHL'\n",
    "    country_code = 'CL'\n",
    "    buffer = 8000\n",
    "elif country == 'Colombia':\n",
    "    country_short = 'COL'\n",
    "    country_code = 'CO'\n",
    "    buffer = 2000\n",
    "# Uncomment the following if Mexico is to be included in the analysis\n",
    "# elif country == 'Mexico':\n",
    "#     country_short = 'MEX'\n",
    "#     country_code = 'MX'\n",
    "#     buffer = 8000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f3c164",
   "metadata": {},
   "source": [
    "# Test: load movement grid and plot buffers for sample movement data\n",
    "\n",
    "**Note:** Do the buffers around the movmeent data fall within the grid cells? If that's the case, grid works and is in the right resolution for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282dcbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory path for Facebook movement data for the selected country\n",
    "directory = f\"/Volumes/RECAST/data/movements/{country}\"\n",
    "\n",
    "# List and sort all files in the directory\n",
    "files = sorted(os.listdir(directory))\n",
    "\n",
    "# Filter to include only files that contain '_0800.csv' (likely representing 08:00 time data)\n",
    "files = [file for file in files if '_0800.csv' in file]\n",
    "\n",
    "# Load the Facebook movement grid shapefile for the country and convert it to EPSG:4326 (WGS 84) coordinate system\n",
    "grid_path = f\"{wd}/data/inputs/grids/Grid_{country}_FB_mov/Grid_{country}.shp\"\n",
    "grid_mov = gpd.read_file(grid_path).to_crs(\"EPSG:4326\")\n",
    "\n",
    "# Load a specific CSV file for testing (e.g., the 101st file matching '_0800.csv') into a DataFrame\n",
    "df_movs = pd.read_csv(f\"{directory}/{files[100]}\")\n",
    "\n",
    "# Filter the DataFrame to include only rows matching the selected country code,\n",
    "# then reset the index\n",
    "df_movs = df_movs[df_movs['country']==country_code].reset_index(drop=True)\n",
    "\n",
    "# Initialise lists to store extracted coordinates\n",
    "start_lstr_lons = []\n",
    "start_lstr_lats = []\n",
    "end_lstr_lons = []\n",
    "end_lstr_lats = []\n",
    "\n",
    "# Iterate over each row in the DataFrame `df_movs`\n",
    "for j in range(len(df_movs)):\n",
    "    try:\n",
    "        # Try extracting coordinates from the 'geometry' column string\n",
    "        geom_str = df_movs.loc[j, 'geometry']\n",
    "    except KeyError:\n",
    "        # Fallback to 'GEOMETRY' column if 'geometry' doesn't exist\n",
    "        geom_str = df_movs.loc[j, 'GEOMETRY']\n",
    "\n",
    "    # Example geometry format: \"LINESTRING (lon1 lat1, lon2 lat2)\"\n",
    "    # Parse start and end coordinates from the string\n",
    "    try:\n",
    "        coords_str = geom_str.split(\"(\")[1].split(\")\")[0].strip()\n",
    "        start_str, end_str = coords_str.split(\", \")\n",
    "        \n",
    "        # Split lon and lat for start point\n",
    "        start_lon, start_lat = start_str.split(\" \")\n",
    "        start_lstr_lons.append(float(start_lon))\n",
    "        start_lstr_lats.append(float(start_lat))\n",
    "        \n",
    "        # Split lon and lat for end point\n",
    "        end_lon, end_lat = end_str.split(\" \")\n",
    "        end_lstr_lons.append(float(end_lon))\n",
    "        end_lstr_lats.append(float(end_lat))\n",
    "        \n",
    "    except Exception as e:\n",
    "        # Handle any parsing error by appending NaNs or skipping\n",
    "        start_lstr_lons.append(float('nan'))\n",
    "        start_lstr_lats.append(float('nan'))\n",
    "        end_lstr_lons.append(float('nan'))\n",
    "        end_lstr_lats.append(float('nan'))\n",
    "        print(f\"Parsing error at row {j}: {e}\")\n",
    "\n",
    "# Add extracted coordinates as new columns to the DataFrame\n",
    "df_movs['start_lstr_lon'] = start_lstr_lons\n",
    "df_movs['start_lstr_lat'] = start_lstr_lats\n",
    "df_movs['end_lstr_lon'] = end_lstr_lons\n",
    "df_movs['end_lstr_lat'] = end_lstr_lats\n",
    "\n",
    "# Convert the DataFrame to a GeoDataFrame using start coordinates as geometry points\n",
    "gdf_movs = gpd.GeoDataFrame(\n",
    "    df_movs,\n",
    "    geometry=gpd.points_from_xy(df_movs['start_lstr_lon'], df_movs['start_lstr_lat']),\n",
    "    crs=\"EPSG:4326\"\n",
    ")                          \n",
    "\n",
    "# Create a figure and axis with specified size\n",
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "# Plot the movement grid polygons with thin white edges, base layer (zorder=1)\n",
    "grid_mov.plot(ax=ax, linewidth=0.1, edgecolor='white', zorder=1)\n",
    "\n",
    "# Buffer the points (movements) in meters (projected CRS EPSG:3857),\n",
    "# then reproject back to geographic coordinates (EPSG:4326)\n",
    "gdf_buff = gdf_movs.to_crs('EPSG:3857').buffer(buffer).to_crs('EPSG:4326')\n",
    "\n",
    "# Plot the buffered points as red patches on top (zorder=2)\n",
    "gdf_buff.plot(ax=ax, color='red', zorder=2)\n",
    "\n",
    "# Optionally, you can set map bounds for zoom - change according to country\n",
    "ax.set_xlim(-75, -74)\n",
    "ax.set_ylim(4, 5)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefccc0f",
   "metadata": {},
   "source": [
    "# Computation of movement grid cell size \n",
    "... to chose the size of buffers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b169df68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the side (in km) of a typical cell (geometry at index 1000)\n",
    "# Convert geometry to EPSG:3857 (meters), get area in mÂ², take square root, and convert to kilometers\n",
    "\n",
    "area_sqrt_km = np.sqrt(grid_mov.to_crs('epsg:3857').loc[1000, 'geometry'].area) / 1000\n",
    "print(area_sqrt_km)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036b9cd8",
   "metadata": {},
   "source": [
    "# Add Feature IDs (FID) to movement data and save processed files\n",
    "\n",
    "**Note:** This process can be optimised by using the `quadkey2` package. Update in the future!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45f23c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing movement CSV files for the selected country\n",
    "directory = f'/Volumes/RECAST/data/movements/{country}'\n",
    "\n",
    "# List all files in the directory and sort them alphabetically for consistent ordering\n",
    "files = sorted(os.listdir(directory))\n",
    "\n",
    "# Filter the list to include only files with '_0800.csv' in their filename (likely representing data for 08:00)\n",
    "files = [file for file in files if '_0800.csv' in file]\n",
    "\n",
    "# Loop through each file for processing\n",
    "for i in range(len(files)):\n",
    "    \n",
    "    # Print progress every 20 files as a percentage\n",
    "    if i % 20 == 0:\n",
    "        print(f'Progress: {(i / len(files)) * 100:.2f}%')\n",
    "    \n",
    "    try:\n",
    "        file = files[i]\n",
    "\n",
    "        # Load movement data for the current file\n",
    "        df_movs = pd.read_csv(f\"{directory}/{file}\")\n",
    "        \n",
    "        # Filter rows for the target country and reset index\n",
    "        df_movs = df_movs[df_movs['country'] == country_code].reset_index(drop=True)\n",
    "        \n",
    "        # Initialize lists to hold extracted longitude and latitude for start and end points\n",
    "        start_lstr_lons = []\n",
    "        start_lstr_lats = []\n",
    "        end_lstr_lons = []\n",
    "        end_lstr_lats = []\n",
    "\n",
    "        # Extract coordinates from 'geometry' or 'GEOMETRY' column strings\n",
    "        for j in range(len(df_movs)):\n",
    "            try:\n",
    "                # Attempt to parse from 'geometry' column\n",
    "                start_lstr_lons.append(float(df_movs.loc[j, 'geometry'].split(\"(\")[1].split(\",\")[0].split(\" \")[0]))\n",
    "                start_lstr_lats.append(float(df_movs.loc[j, 'geometry'].split(\"(\")[1].split(\",\")[0].split(\" \")[1]))\n",
    "                end_lstr_lons.append(float(df_movs.loc[j, 'geometry'].split(\", \")[1].split(\")\")[0].split(\" \")[0]))\n",
    "                end_lstr_lats.append(float(df_movs.loc[j, 'geometry'].split(\", \")[1].split(\")\")[0].split(\" \")[1]))\n",
    "            except:\n",
    "                # Fallback: parse from 'GEOMETRY' column if 'geometry' parsing fails\n",
    "                start_lstr_lons.append(float(df_movs.loc[j, 'GEOMETRY'].split(\"(\")[1].split(\",\")[0].split(\" \")[0]))\n",
    "                start_lstr_lats.append(float(df_movs.loc[j, 'GEOMETRY'].split(\"(\")[1].split(\",\")[0].split(\" \")[1]))\n",
    "                end_lstr_lons.append(float(df_movs.loc[j, 'GEOMETRY'].split(\", \")[1].split(\")\")[0].split(\" \")[0]))\n",
    "                end_lstr_lats.append(float(df_movs.loc[j, 'GEOMETRY'].split(\", \")[1].split(\")\")[0].split(\" \")[1]))\n",
    "\n",
    "        # Add extracted coordinate columns to the DataFrame\n",
    "        df_movs['start_lstr_lat'] = start_lstr_lats\n",
    "        df_movs['start_lstr_lon'] = start_lstr_lons\n",
    "        df_movs['end_lstr_lat'] = end_lstr_lats\n",
    "        df_movs['end_lstr_lon'] = end_lstr_lons\n",
    "        \n",
    "        # Initialize start and end Feature ID (FID) columns with -1 as default\n",
    "        df_movs['start_FID'] = -1\n",
    "        df_movs['end_FID'] = -1\n",
    "        \n",
    "        # Keep track of rows to drop if processing fails\n",
    "        index_to_drop = []\n",
    "        \n",
    "        # Assign FID for start and end locations by checking intersection with grid polygons\n",
    "        for j in range(len(df_movs)):\n",
    "            try:\n",
    "                # Create buffered start point geometry for intersection\n",
    "                start = (\n",
    "                    gpd.GeoDataFrame({'geometry': [Point(df_movs.loc[j, 'start_lstr_lon'], df_movs.loc[j, 'start_lstr_lat'])]})\n",
    "                    .set_crs('EPSG:4326')\n",
    "                    .to_crs('EPSG:3857')\n",
    "                    .buffer(buffer)\n",
    "                    .to_crs('EPSG:4326')\n",
    "                )\n",
    "                overlap_start = start[0].intersects(grid_mov['geometry'])\n",
    "                df_movs.loc[j, 'start_FID'] = grid_mov.loc[np.where(overlap_start == True)[0][0]]['FID']\n",
    "\n",
    "                # Create buffered end point geometry for intersection\n",
    "                end = (\n",
    "                    gpd.GeoDataFrame({'geometry': [Point(df_movs.loc[j, 'end_lstr_lon'], df_movs.loc[j, 'end_lstr_lat'])]})\n",
    "                    .set_crs('EPSG:4326')\n",
    "                    .to_crs('EPSG:3857')\n",
    "                    .buffer(buffer)\n",
    "                    .to_crs('EPSG:4326')\n",
    "                )\n",
    "                overlap_end = end[0].intersects(grid_mov['geometry'])\n",
    "                df_movs.loc[j, 'end_FID'] = grid_mov.loc[np.where(overlap_end == True)[0][0]]['FID']\n",
    "\n",
    "            except:\n",
    "                # Log problematic file and row indices, and mark row for dropping\n",
    "                print(f\"Error processing file index {i}, row {j}\")\n",
    "                index_to_drop.append(j)\n",
    "        \n",
    "        # Drop rows where either start or end FID assignment failed\n",
    "        df_movs = df_movs.drop(index_to_drop).reset_index(drop=True)\n",
    "        \n",
    "        # Save processed DataFrame to output directory\n",
    "        output_path = f\"{wd}/data/outputs/{country_short}/mov/{file}\"\n",
    "        df_movs.to_csv(output_path, index=False)\n",
    "    \n",
    "    except:\n",
    "        print(f\"Failed to process file index {i}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
