{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8dad7db",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f08ea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rioxarray as rx\n",
    "import jenkspy\n",
    "from pysal.lib import weights\n",
    "from matplotlib.lines import Line2D\n",
    "from mycolorpy import colorlist as mcp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3270b8c",
   "metadata": {},
   "source": [
    "# Define country and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17826f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select target country\n",
    "country = 'Colombia'\n",
    "\n",
    "# Set country-specific parameters: ISO codes and buffer size (in meters)\n",
    "if country == 'Argentina':\n",
    "    country_short = 'ARG'   # ISO 3-letter code\n",
    "    country_code = 'AR'     # ISO 2-letter code\n",
    "elif country == 'Chile':\n",
    "    country_short = 'CHL'\n",
    "    country_code = 'CL'\n",
    "elif country == 'Colombia':\n",
    "    country_short = 'COL'\n",
    "    country_code = 'CO'\n",
    "# Uncomment the following if Mexico is to be included in the analysis\n",
    "# elif country == 'Mexico':\n",
    "#     country_short = 'MEX'\n",
    "#     country_code = 'MX'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef129427",
   "metadata": {},
   "source": [
    "# Set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1feb7427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define working directory path\n",
    "\n",
    "wd = (\n",
    "    '/Users/carmen/Library/CloudStorage/OneDrive-TheUniversityofLiverpool/'\n",
    "    'Research/RECAST/latin-mobility-covid-local-files'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9f8866",
   "metadata": {},
   "source": [
    "# Load FB population baseline data at the resolution of FB mobility data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8091353d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mobility cell baseline imputed population data from GeoPackage file\n",
    "movcell_baseline_imput_pop = gpd.read_file(\n",
    "    f\"{wd}/data/outputs/{country_short}/grids-with-data/movcell-baseline-imput-pop/movcell-baseline-imput-pop.gpkg\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810649f1",
   "metadata": {},
   "source": [
    "# Merge movcell baseline input pop with WP population via spatial join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b196abd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell:\n",
    "# - Loads WorldPop raster and converts it to a GeoDataFrame of points \n",
    "# - Performs a spatial join to assign population points to mobility grid cells and aggregates population within each cell\n",
    "# - For Mexico, identifies a potential outlier in population values and smooths it by replacing with the spatial lag of its neighbours\n",
    "\n",
    "# Import WorldPop raster and convert it to a GeoDataFrame of points at pixel centroids\n",
    "rds = rx.open_rasterio(\n",
    "    wd + f'/data/inputs/population/worldpop/{country_short.lower()}_ppp_2020_1km_Aggregated.tif'\n",
    ")\n",
    "rds.name = \"population\"\n",
    "\n",
    "# Convert raster to DataFrame and create geometry from pixel centroids\n",
    "df = rds.squeeze().to_dataframe().reset_index()\n",
    "geometry = gpd.points_from_xy(df.x, df.y)\n",
    "gdf_worldpop = gpd.GeoDataFrame(df, crs=rds.rio.crs, geometry=geometry)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "gdf_worldpop = gdf_worldpop.drop(['y', 'x', 'band', 'spatial_ref'], axis=1)\n",
    "\n",
    "# Filter out invalid population values and reproject to WGS84\n",
    "gdf_worldpop = gdf_worldpop[gdf_worldpop['population'] != -99999].reset_index(drop=True)\n",
    "gdf_worldpop = gdf_worldpop.to_crs('EPSG:4326')\n",
    "\n",
    "# Spatial join: assign WorldPop points to mobility cells with population data\n",
    "grid_wp = gpd.sjoin(movcell_baseline_imput_pop, gdf_worldpop)\n",
    "\n",
    "# Aggregate population within each mobility cell\n",
    "grid_wp_group = grid_wp[['population']].groupby(grid_wp.index).sum()\n",
    "\n",
    "# Merge aggregated WorldPop population data back into mobility cell GeoDataFrame\n",
    "movcell_baseline_imput_pop = pd.merge(\n",
    "    movcell_baseline_imput_pop,\n",
    "    grid_wp_group,\n",
    "    how='left',\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    ")\n",
    "\n",
    "if country == 'Mexico':\n",
    "    # Identify the second highest population cell (potentially an outlier)\n",
    "    id_problem = movcell_baseline_imput_pop.sort_values(by='population', ascending=False).iloc[1].name\n",
    "\n",
    "    # Create spatial weights matrix (Queen contiguity) for all mobility cells\n",
    "    w = weights.Queen.from_dataframe(movcell_baseline_imput_pop)\n",
    "\n",
    "    # Remove isolated cells (islands) from the dataset\n",
    "    movcell_baseline_imput_pop_w = movcell_baseline_imput_pop.drop(w.islands)\n",
    "\n",
    "    # Recalculate spatial weights matrix without islands\n",
    "    w = weights.Queen.from_dataframe(movcell_baseline_imput_pop_w)\n",
    "    w.transform = 'R'  # Row-standardize weights\n",
    "\n",
    "    # Calculate spatial lag of population variable (weighted average of neighbors)\n",
    "    movcell_baseline_imput_pop_w['population_lag'] = weights.lag_spatial(\n",
    "        w, movcell_baseline_imput_pop_w['population']\n",
    "    )\n",
    "\n",
    "    # Replace the problematic population value with its spatial lag value\n",
    "    movcell_baseline_imput_pop.loc[id_problem, 'population'] = (\n",
    "        movcell_baseline_imput_pop_w.loc[id_problem, 'population_lag']\n",
    "    )\n",
    "\n",
    "# Quick check of results\n",
    "# Plot scatter of WorldPop population vs. imputed population on weekday 5\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(movcell_baseline_imput_pop['population'], movcell_baseline_imput_pop['5'], alpha=0.6)\n",
    "ax.set_xlabel('WorldPop Population')\n",
    "ax.set_ylabel('Imputed Population (Weekday 5)')\n",
    "ax.set_title('Scatter plot: WorldPop vs Imputed Population (Weekday 5)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c51003",
   "metadata": {},
   "source": [
    "# Classify mobility cells into population density categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcc7881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of density classes\n",
    "n_class_density = 5\n",
    "\n",
    "# Calculate population density (population per sq km) using area in EPSG:3857 projection\n",
    "area_sqm = movcell_baseline_imput_pop['geometry'].to_crs('EPSG:3857').area\n",
    "movcell_baseline_imput_pop['density'] = movcell_baseline_imput_pop['population'] / (area_sqm / 1e6)\n",
    "\n",
    "# Compute Jenks natural breaks for density classification\n",
    "breaks_density = jenkspy.jenks_breaks(\n",
    "    movcell_baseline_imput_pop.dropna(subset=['density'])['density'],\n",
    "    n_classes=n_class_density\n",
    ")\n",
    "\n",
    "# Slightly adjust lower bound to include minimum values\n",
    "breaks_density[0] -= 1e-10\n",
    "\n",
    "# Classify densities using Jenks breaks\n",
    "movcell_baseline_imput_pop['class_density'] = pd.cut(\n",
    "    movcell_baseline_imput_pop['density'],\n",
    "    bins=breaks_density,\n",
    "    labels=range(n_class_density),\n",
    "    include_lowest=True\n",
    ").astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ff03f2",
   "metadata": {},
   "source": [
    "# Map population density categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a03c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "if country != 'Mexico':\n",
    "    background = gpd.read_file(\n",
    "        wd + '/data/inputs/boundaries/south-america/vc965bq8111.shp'\n",
    "    ).to_crs('EPSG:4326')\n",
    "else:\n",
    "    background = gpd.read_file(\n",
    "        wd + '/data/inputs/boundaries/central-america/bound_p.shp'\n",
    "    ).to_crs('EPSG:4326')\n",
    "\n",
    "background.plot(ax=ax, facecolor='dimgray', alpha=0.5, zorder=1)\n",
    "\n",
    "if country != 'Mexico':\n",
    "    background[background['name'] == country.upper()].plot(ax=ax, color='None', zorder=2)\n",
    "else:\n",
    "    shape = gpd.read_file(\n",
    "        wd + '/data/inputs/boundaries/gadm41_MEX_2.json'\n",
    "    ).to_crs('EPSG:4326')\n",
    "    shape.plot(ax=ax, color='None', zorder=2)\n",
    "\n",
    "ax.set_facecolor('lightskyblue')\n",
    "\n",
    "movcell_baseline_imput_pop.plot(\n",
    "    column='density',\n",
    "    cmap='viridis',\n",
    "    scheme='natural_breaks',\n",
    "    k=5,\n",
    "    legend=False,\n",
    "    zorder=2,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "if country == 'Argentina' or country == 'Chile':\n",
    "    ax.set_xlim(-77, -49)\n",
    "    ax.set_ylim(-57, -16)\n",
    "elif country == 'Colombia':\n",
    "    ax.set_xlim(-80, -64)\n",
    "    ax.set_ylim(-5.5, 13.5)\n",
    "elif country == 'Mexico':\n",
    "    ax.set_xlim(-119, -85)\n",
    "    ax.set_ylim(10, 38)\n",
    "\n",
    "ax.tick_params(\n",
    "    axis='both',\n",
    "    which='both',\n",
    "    width=0,\n",
    "    length=0,\n",
    "    color='k',\n",
    "    labelleft=False,\n",
    "    labelbottom=False\n",
    ")\n",
    "\n",
    "labels_density = breaks_density    \n",
    "custom_labels = []\n",
    "for i in range(n_class_density - 1):\n",
    "    custom_labels.append(f'[{int(labels_density[i])}, {int(labels_density[i+1])})')\n",
    "custom_labels.append(f'[{int(labels_density[-2])}, {int(labels_density[-1])}]')\n",
    "\n",
    "colors = mcp.gen_color(cmap='viridis', n=n_class_density)\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], lw=0, color=colors[i], marker='o', markersize=10, label=custom_labels[i])\n",
    "    for i in range(len(colors))\n",
    "]\n",
    "\n",
    "if country in ['Argentina', 'Chile', 'Colombia']:\n",
    "    loc = 'lower right'\n",
    "elif country == 'Mexico':\n",
    "    loc = 'lower left'\n",
    "\n",
    "# Uncomment to add legend and scalebar as needed\n",
    "# legend = ax.legend(handles=legend_elements, handlelength=0, fontsize=14, shadow=False,\n",
    "#                    fancybox=False, loc=loc, ncol=1, columnspacing=1.2,\n",
    "#                    borderpad=1, title='Population density from \\nWorldPop (persons/sqkm)')\n",
    "# for t in legend.get_texts():\n",
    "#     t.set_ha('right')\n",
    "# legend.get_frame().set_edgecolor('black')\n",
    "# legend.get_frame().set_linewidth(1)\n",
    "# legend.get_frame().set_alpha(None)\n",
    "# legend.get_frame().set_facecolor((1, 1, 1, 0.7))\n",
    "# legend.get_title().set_fontsize('14')\n",
    "# ax.add_artist(ScaleBar(dx=1, units=\"km\", dimension=\"si-length\", length_fraction=.1,\n",
    "#                        scale_formatter=lambda value, unit: f' {value * 100} km ',\n",
    "#                        pad=0.7, sep=5, border_pad=1, scale_loc='top',\n",
    "#                        box_color='w', box_alpha=0, font_properties={'size':20}, location='upper left'))\n",
    "\n",
    "# Uncomment to add north arrow image as needed\n",
    "# im = plt.imread(wd + '/data/inputs/boundaries/north-arrow.png')\n",
    "# if country == 'Argentina':\n",
    "#     loc_arr1 = [0.655, 0.82, 0.04, 0.04]\n",
    "# elif country == 'Chile':\n",
    "#     loc_arr1 = [0.655, 0.82, 0.04, 0.04]\n",
    "# elif country == 'Colombia':\n",
    "#     loc_arr1 = [0.755, 0.82, 0.04, 0.04]\n",
    "# elif country == 'Mexico':\n",
    "#     loc_arr1 = [0.83, 0.78, 0.04, 0.04]\n",
    "# newax = fig.add_axes(loc_arr1, zorder=1)\n",
    "# newax.tick_params(axis='both', which='both', labelbottom=False, labelleft=False, width=0, length=0)\n",
    "# newax.set_facecolor('None')\n",
    "# plt.setp(newax.spines.values(), linewidth=0)\n",
    "# newax.imshow(im)\n",
    "\n",
    "# plt.savefig(wd + '/plots/map-classes/map-classes-density-' + country_short + '-nolegend.pdf', bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668d6eed",
   "metadata": {},
   "source": [
    "# Merge movcell baseline input pop with level of Relative Deprivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1b609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only uncomment if you want to reread the RDI raster and generate a GeoPackage with point geometries\n",
    "# Import RDI raster and convert it to a GeoDataFrame of points at pixel centroids\n",
    "\n",
    "file_raster = wd + '/data/inputs/rdi/povmap-grdi-v1-grdiv1-geotiff/povmap-grdi-v1.tif'\n",
    "\n",
    "# Open the raster file using rioxarray\n",
    "rds = rx.open_rasterio(file_raster)\n",
    "rds.name = \"rdi\"\n",
    "\n",
    "# Convert raster to DataFrame, squeezing to remove single-dimensional entries and resetting the index\n",
    "df_rdi = rds.squeeze().to_dataframe().reset_index()\n",
    "\n",
    "# Filter out invalid RDI values (keep only rdi >= 0)\n",
    "df_rdi = df_rdi[df_rdi['rdi'] >= 0].reset_index(drop=True)\n",
    "\n",
    "# Create point geometries from raster pixel centroids using x and y coordinates\n",
    "geometry = gpd.points_from_xy(df_rdi.x, df_rdi.y)\n",
    "\n",
    "# Create GeoDataFrame with the same CRS as the raster\n",
    "gdf_rdi = gpd.GeoDataFrame(df_rdi, crs=rds.rio.crs, geometry=geometry)\n",
    "\n",
    "# Drop unnecessary columns related to raster metadata\n",
    "gdf_rdi = gdf_rdi.drop(['y', 'x', 'band', 'spatial_ref'], axis=1)\n",
    "\n",
    "# Reproject GeoDataFrame to WGS84 (EPSG:4326)\n",
    "gdf_rdi = gdf_rdi.to_crs('epsg:4326')\n",
    "\n",
    "# Spatially join RDI points to mobility cells to assign RDI values to each cell\n",
    "grid_rdi_join = gpd.sjoin(movcell_baseline_imput_pop, gdf_rdi)\n",
    "\n",
    "# Drop rows where RDI values are missing (NaN)\n",
    "grid_rdi_join = grid_rdi_join.dropna(subset=['rdi'])\n",
    "\n",
    "# Calculate mean RDI value per mobility cell (grouped by cell index)\n",
    "grid_rdi_group = grid_rdi_join[['rdi']].groupby(grid_rdi_join.index).mean()\n",
    "\n",
    "# Merge the aggregated mean RDI values back into the mobility cells GeoDataFrame\n",
    "movcell_baseline_imput_pop = pd.merge(\n",
    "    movcell_baseline_imput_pop, \n",
    "    grid_rdi_group, \n",
    "    how='left', \n",
    "    left_index=True, \n",
    "    right_index=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce9d28e",
   "metadata": {},
   "source": [
    "# Classify mobility cells into RDI categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab65ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class_rdi = 3\n",
    "\n",
    "# Calculate Jenks natural breaks for RDI values, ignoring NaNs\n",
    "breaks_rdi = jenkspy.jenks_breaks(\n",
    "    movcell_baseline_imput_pop.dropna(subset=['rdi'])['rdi'], \n",
    "    n_classes=n_class_rdi\n",
    ")\n",
    "\n",
    "# Slightly lower the first break to include minimum value\n",
    "breaks_rdi[0] = breaks_rdi[0] - 10**(-10)\n",
    "\n",
    "# Classify RDI values into bins based on Jenks breaks with labels 0, 1, 2\n",
    "movcell_baseline_imput_pop['class_rdi'] = pd.cut(\n",
    "    movcell_baseline_imput_pop['rdi'], \n",
    "    bins=breaks_rdi, \n",
    "    labels=[i for i in range(n_class_rdi)]\n",
    ")\n",
    "\n",
    "# Convert class labels from categorical to numeric type\n",
    "movcell_baseline_imput_pop['class_rdi'] = pd.to_numeric(movcell_baseline_imput_pop['class_rdi'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe8e74e",
   "metadata": {},
   "source": [
    "# Map RDI categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dd1823",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "if country != 'Mexico':\n",
    "    background = gpd.read_file(wd + '/data/inputs/boundaries/south-america/vc965bq8111.shp').to_crs('EPSG:4326')\n",
    "else:\n",
    "    background = gpd.read_file(wd + '/data/inputs/boundaries/central-america/bound_p.shp').to_crs('EPSG:4326')\n",
    "\n",
    "background.plot(ax=ax, facecolor='dimgray', alpha=0.5, zorder=1)\n",
    "if country != 'Mexico':\n",
    "    background[background['name'] == country.upper()].plot(ax=ax, color='None', zorder=2)\n",
    "else:\n",
    "    shape = gpd.read_file(wd + '/data/inputs/boundaries/gadm41_MEX_2.json').to_crs('EPSG:4326')\n",
    "    shape.plot(ax=ax, color='None', zorder=2)\n",
    "\n",
    "ax.set_facecolor('lightskyblue')\n",
    "\n",
    "movcell_baseline_imput_pop['class_rdi_plot'] = movcell_baseline_imput_pop['class_rdi']\n",
    "for i in range(len(movcell_baseline_imput_pop)):\n",
    "    if pd.isna(movcell_baseline_imput_pop.loc[i, 'class_rdi_plot']):\n",
    "        movcell_baseline_imput_pop.loc[i, 'class_rdi_plot'] = 2\n",
    "\n",
    "movcell_baseline_imput_pop.plot(\n",
    "    column='class_rdi_plot', cmap='viridis', k=3, legend=False, zorder=2, ax=ax\n",
    ")\n",
    "movcell_baseline_imput_pop.drop(['class_rdi_plot'], axis=1)\n",
    "\n",
    "movcell_baseline_imput_pop.plot(column='class_rdi', cmap='viridis', ax=ax, legend=False)\n",
    "\n",
    "if country == 'Argentina':\n",
    "    ax.set_xlim(-77, -49)\n",
    "    ax.set_ylim(-57, -16)\n",
    "elif country == 'Chile':\n",
    "    ax.set_xlim(-77, -49)\n",
    "    ax.set_ylim(-57, -16)\n",
    "elif country == 'Colombia':\n",
    "    ax.set_xlim(-80, -64)\n",
    "    ax.set_ylim(-5.5, 13.5)\n",
    "elif country == 'Mexico':\n",
    "    ax.set_xlim(-119, -85)\n",
    "    ax.set_ylim(10, 38)\n",
    "\n",
    "ax.tick_params(axis='both', which='both', width=0, length=0, color='k', labelleft=False, labelbottom=False)\n",
    "\n",
    "im = plt.imread(wd + '/data/inputs/boundaries/north-arrow.png')\n",
    "\n",
    "if country == 'Argentina':\n",
    "    loc_arr1 = [0.655, 0.82, 0.04, 0.04]\n",
    "elif country == 'Chile':\n",
    "    loc_arr1 = [0.655, 0.82, 0.04, 0.04]\n",
    "elif country == 'Colombia':\n",
    "    loc_arr1 = [0.755, 0.82, 0.04, 0.04]\n",
    "elif country == 'Mexico':\n",
    "    loc_arr1 = [0.83, 0.78, 0.04, 0.04]\n",
    "\n",
    "newax = fig.add_axes(loc_arr1, zorder=1)\n",
    "newax.tick_params(axis='both', which='both', labelbottom=False, labelleft=False, width=0, length=0)\n",
    "newax.set_facecolor('None')\n",
    "plt.setp(newax.spines.values(), linewidth=0)\n",
    "# newax.imshow(im)\n",
    "\n",
    "plt.savefig(\n",
    "    wd + '/plots/map-classes/map-classes-rdi-' + country_short + '-nolegend-invert.pdf',\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe31d93",
   "metadata": {},
   "source": [
    "# Percentage population in each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf418b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average weekly value for each row across the first 7 columns (index 0 to 6)\n",
    "average_week = []\n",
    "for i in range(len(movcell_baseline_imput_pop)):\n",
    "    average_week.append(np.mean(movcell_baseline_imput_pop.iloc[i, [0, 1, 2, 3, 4, 5, 6]]))\n",
    "\n",
    "# Add the average weekly values as a new column\n",
    "movcell_baseline_imput_pop['average_week'] = average_week\n",
    "\n",
    "# Initialise lists to store total Facebook and WorldPop populations per density class\n",
    "fb_pop_class_density = []\n",
    "wp_pop_class_density = []\n",
    "\n",
    "# Sum the 'average_week' and 'population' values for each density class\n",
    "for i in range(n_class_density):\n",
    "    fb_pop_class_density.append(\n",
    "        np.sum(movcell_baseline_imput_pop[movcell_baseline_imput_pop['class_density'] == i]['average_week'])\n",
    "    )\n",
    "    wp_pop_class_density.append(\n",
    "        np.sum(movcell_baseline_imput_pop[movcell_baseline_imput_pop['class_density'] == i]['population'])\n",
    "    )\n",
    "\n",
    "# Calculate the percentage distribution of Facebook and WorldPop populations by density class\n",
    "fb_pop_class_density_per = fb_pop_class_density / np.sum(fb_pop_class_density) * 100\n",
    "wp_pop_class_density_per = wp_pop_class_density / np.sum(wp_pop_class_density) * 100\n",
    "\n",
    "# Initialise lists to store total Facebook and WorldPop populations per RDI class\n",
    "fb_pop_class_rdi = []\n",
    "wp_pop_class_rdi = []\n",
    "\n",
    "# Sum the 'average_week' and 'population' values for each RDI class\n",
    "for i in range(n_class_rdi):\n",
    "    fb_pop_class_rdi.append(\n",
    "        np.sum(movcell_baseline_imput_pop[movcell_baseline_imput_pop['class_density'] == i]['average_week'])\n",
    "    )\n",
    "    wp_pop_class_rdi.append(\n",
    "        np.sum(movcell_baseline_imput_pop[movcell_baseline_imput_pop['class_density'] == i]['population'])\n",
    "    )\n",
    "\n",
    "# Calculate the percentage distribution of Facebook and WorldPop populations by RDI class\n",
    "fb_pop_class_rdi_per = fb_pop_class_rdi / np.sum(fb_pop_class_rdi) * 100\n",
    "wp_pop_class_rdi_per = wp_pop_class_rdi / np.sum(wp_pop_class_rdi) * 100\n",
    "\n",
    "# Plot to see distribution of population in each category\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "fb_pop_class_density_lim = [np.sum(fb_pop_class_density_per[0:i]) for i in range(len(fb_pop_class_density_per))]\n",
    "ax.barh(3, width=fb_pop_class_density_per, left=fb_pop_class_density_lim, color=mcp.gen_color(cmap='viridis', n=n_class_density))\n",
    "\n",
    "wp_pop_class_density_lim = [np.sum(wp_pop_class_density_per[0:i]) for i in range(len(wp_pop_class_density_per))]\n",
    "ax.barh(4, width=wp_pop_class_density_per, left=wp_pop_class_density_lim, color=mcp.gen_color(cmap='viridis', n=n_class_density))\n",
    "\n",
    "fb_pop_class_rdi_lim = [np.sum(fb_pop_class_rdi_per[0:i]) for i in range(len(fb_pop_class_rdi_per))]\n",
    "ax.barh(1, width=fb_pop_class_rdi_per, left=fb_pop_class_rdi_lim, color=mcp.gen_color(cmap='viridis', n=n_class_rdi))\n",
    "\n",
    "wp_pop_class_rdi_lim = [np.sum(wp_pop_class_rdi_per[0:i]) for i in range(len(wp_pop_class_rdi_per))]\n",
    "ax.barh(2, width=wp_pop_class_rdi_per, left=wp_pop_class_rdi_lim, color=mcp.gen_color(cmap='viridis', n=n_class_rdi))\n",
    "\n",
    "ax.spines['bottom'].set_linewidth(0)\n",
    "ax.spines['top'].set_linewidth(0)\n",
    "ax.spines['left'].set_linewidth(0)\n",
    "ax.spines['right'].set_linewidth(0)\n",
    "\n",
    "ax.tick_params(axis='both', rotation=0, length=0, labelsize=20, labelleft=False, labelbottom=True)\n",
    "\n",
    "plt.savefig(wd + '/plots/percentage-classes/percentage-classes-' + country_short + '.pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed40d7a",
   "metadata": {},
   "source": [
    "# Assign Combined Class Labels Based on Density and RDI Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36537a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise counter for total number of combined classes\n",
    "n_class = 0\n",
    "# Dictionary to store combined class labels as keys with [density_class, rdi_class] pairs as values\n",
    "n_class_labels = {}\n",
    "\n",
    "# Loop over all density classes and RDI classes to create combined class label pairs\n",
    "for i in range(n_class_density):\n",
    "    for j in range(n_class_rdi):\n",
    "        n_class += 1\n",
    "        n_class_labels[n_class - 1] = [i, j]\n",
    "\n",
    "# Print all combined class labels with their corresponding pairs\n",
    "print(n_class_labels)\n",
    "\n",
    "# Initialise a new column in the DataFrame to hold combined class labels (default to 0)\n",
    "movcell_baseline_imput_pop['n_class_label'] = np.zeros(len(movcell_baseline_imput_pop))\n",
    "\n",
    "# Assign combined class label for each row based on matching density and RDI classes\n",
    "for i in range(len(movcell_baseline_imput_pop)):\n",
    "    # Extract the density and RDI class for the current row\n",
    "    pair = [\n",
    "        movcell_baseline_imput_pop.loc[i, 'class_density'],\n",
    "        movcell_baseline_imput_pop.loc[i, 'class_rdi']\n",
    "    ]\n",
    "    # Find the combined class key that matches the current [density, rdi] pair\n",
    "    matching_keys = [key for key, value in n_class_labels.items() if value == pair]\n",
    "\n",
    "    # If no matching combined class found, assign NaN\n",
    "    if len(matching_keys) == 0:\n",
    "        movcell_baseline_imput_pop.loc[i, 'n_class_label'] = np.nan\n",
    "    else:\n",
    "        # Otherwise, assign the combined class label\n",
    "        movcell_baseline_imput_pop.loc[i, 'n_class_label'] = matching_keys[0]\n",
    "\n",
    "        \n",
    "movcell_baseline_imput_pop.to_file(\n",
    "    wd + '/data/outputs/' + country_short + '/grids-with-data/movcell-baseline-imput-pop-with-exo-var/movcell-baseline-imput-pop-with-exo-var.gpkg'\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
