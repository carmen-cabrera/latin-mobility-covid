{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f57b45d8",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e1d2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1037cfda",
   "metadata": {},
   "source": [
    "# Define country and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3df0eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select target country\n",
    "country = 'Colombia'\n",
    "\n",
    "# Set country-specific parameters: ISO codes and buffer size (in meters)\n",
    "if country == 'Argentina':\n",
    "    country_short = 'ARG'   # ISO 3-letter code\n",
    "    country_code = 'AR'     # ISO 2-letter code\n",
    "elif country == 'Chile':\n",
    "    country_short = 'CHL'\n",
    "    country_code = 'CL'\n",
    "elif country == 'Colombia':\n",
    "    country_short = 'COL'\n",
    "    country_code = 'CO'\n",
    "# Uncomment the following if Mexico is to be included in the analysis\n",
    "# elif country == 'Mexico':\n",
    "#     country_short = 'MEX'\n",
    "#     country_code = 'MX'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d296e05",
   "metadata": {},
   "source": [
    "# Set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd9d406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define working directory path\n",
    "wd = (\n",
    "    '/Users/carmen/Library/CloudStorage/OneDrive-TheUniversityofLiverpool/'\n",
    "    'research/recast/latin-mobility-covid-local-files'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137eedc5",
   "metadata": {},
   "source": [
    "# Load baseline data\n",
    "Two options:<br>\n",
    "    - with raw data (reported) only<br>\n",
    "    - with both raw and estimated data from imputed baseline when raw data is missing <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fee47fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to True or False according to desired option (see description above)\n",
    "raw = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c46990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load baseline movement data depending on the flag\n",
    "if raw == True:\n",
    "    baseline_mov = pd.read_csv(\n",
    "        os.path.join(wd, 'data', 'outputs', country_short, 'baseline', 'baseline_mov.csv')\n",
    "    )\n",
    "else:\n",
    "    baseline_mov_imput = pd.read_csv(\n",
    "        os.path.join(\n",
    "            wd, 'data', 'outputs', country_short,\n",
    "            'baseline', 'movcell-baseline-imput-mov-dist-with-exo-var-flatten-sample.csv'\n",
    "        )\n",
    "    ).drop(columns='Unnamed: 0')\n",
    "\n",
    "# Load imputed baseline population data with exogenous variables\n",
    "baseline_pop_imput = gpd.read_file(\n",
    "    os.path.join(\n",
    "        wd, 'data', 'outputs', country_short,\n",
    "        'grids-with-data', 'movcell-baseline-imput-pop-with-exo-var',\n",
    "        'movcell-baseline-imput-pop-with-exo-var.gpkg'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dcc1f5",
   "metadata": {},
   "source": [
    "# Evolution by day distance > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b47b831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing daily movement data\n",
    "directory = os.path.join(wd, 'data', 'outputs', country_short, 'mov')\n",
    "\n",
    "# Get a sorted list of non-hidden files in the movement data directory\n",
    "files = sorted([file for file in os.listdir(directory) if not file.startswith('.')])\n",
    "\n",
    "# Extract start and end dates from filenames (assuming format includes YYYY-MM-DD near the end)\n",
    "start_date = datetime.strptime(files[0][-19:-9], '%Y-%m-%d')\n",
    "end_date = datetime.strptime(files[-1][-19:-9], '%Y-%m-%d')\n",
    "\n",
    "# Compute the number of days in the movement data time span\n",
    "delta = end_date - start_date\n",
    "\n",
    "# Generate list of column names as date strings for each day in the time range\n",
    "columns = [str(start_date + timedelta(days=i))[:10] for i in range(delta.days + 1)]\n",
    "\n",
    "# Initialise empty DataFrame for movement data evolution based on `raw` flag\n",
    "if raw == True:\n",
    "    # Create DataFrame with NaNs and same number of rows as baseline raw data\n",
    "    df_mov_evo_dist = pd.DataFrame({\n",
    "        column: [np.nan] * len(baseline_mov) for column in columns\n",
    "    })\n",
    "\n",
    "    # Insert origin and destination columns from raw baseline data\n",
    "    df_mov_evo_dist.insert(0, 'D', baseline_mov['D'])\n",
    "    df_mov_evo_dist.insert(0, 'O', baseline_mov['O'])\n",
    "\n",
    "    # Create a copy to represent baseline movement for comparison or extension\n",
    "    df_mov_evo_dist_baseline_from_mov = df_mov_evo_dist.copy()\n",
    "\n",
    "else:\n",
    "    # Create DataFrame with NaNs and same number of rows as imputed baseline data\n",
    "    df_mov_evo_dist = pd.DataFrame({\n",
    "        column: [np.nan] * len(baseline_mov_imput) for column in columns\n",
    "    })\n",
    "\n",
    "    # Insert origin and destination columns from imputed baseline data\n",
    "    df_mov_evo_dist.insert(0, 'D', baseline_mov_imput['D'])\n",
    "    df_mov_evo_dist.insert(0, 'O', baseline_mov_imput['O'])\n",
    "\n",
    "    # Create a copy for later reference or baseline comparison\n",
    "    df_mov_evo_dist_baseline_from_baseline = df_mov_evo_dist.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897558c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This block is slow to run. Only run if you want to regenerate movement evolution files.\n",
    "\n",
    "for i in range(len(files)):\n",
    "    # Print progress every 50 files\n",
    "    if i % 50 == 0:\n",
    "        print(f\"Processing {i / len(files) * 100:.2f}%\")\n",
    "\n",
    "    file = files[i]\n",
    "    file_path = os.path.join(directory, file)\n",
    "\n",
    "    # Load movement file and drop unnecessary column\n",
    "    df_movs = pd.read_csv(file_path).drop('Unnamed: 0', axis=1)\n",
    "\n",
    "    # Extract date and weekday from filename\n",
    "    date_str = file[-19:-9]\n",
    "    wday = datetime.strptime(date_str, \"%Y-%m-%d\").weekday()\n",
    "\n",
    "    for j in range(len(df_movs)):\n",
    "        if df_movs.loc[j, 'length_km'] > 0:\n",
    "            start_FID = df_movs.loc[j, 'start_FID']\n",
    "            end_FID = df_movs.loc[j, 'end_FID']\n",
    "\n",
    "            try:\n",
    "                # Filter for matching Origin-Destination pair\n",
    "                df_od = df_mov_evo_dist[\n",
    "                    (df_mov_evo_dist['O'] == start_FID) &\n",
    "                    (df_mov_evo_dist['D'] == end_FID)\n",
    "                ]\n",
    "\n",
    "                index = df_od.index[0]\n",
    "\n",
    "                # Get crisis and baseline values\n",
    "                n_crisis = df_movs.loc[j, 'n_crisis']\n",
    "                n_baseline = baseline_mov_imput.loc[index, str(wday)]\n",
    "\n",
    "                if pd.notna(n_crisis) and pd.notna(n_baseline):\n",
    "                    df_mov_evo_dist.loc[index, date_str] = n_crisis\n",
    "\n",
    "                    if raw:\n",
    "                        df_mov_evo_dist_baseline_from_mov.loc[index, date_str] = n_baseline\n",
    "                else:\n",
    "                    # If raw is False and we have percent change instead of absolute values\n",
    "                    if not raw:\n",
    "                        percent_change = df_movs.loc[j, 'percent_change']\n",
    "                        df_mov_evo_dist.loc[index, date_str] = (\n",
    "                            n_baseline * percent_change / 100 + n_baseline\n",
    "                        )\n",
    "\n",
    "                if not raw:\n",
    "                    df_mov_evo_dist_baseline_from_baseline.loc[index, date_str] = n_baseline\n",
    "\n",
    "            except Exception:\n",
    "                print('OD pair not found')\n",
    "\n",
    "# Save results to appropriate files based on raw flag\n",
    "output_dir = os.path.join(wd, 'data', 'outputs', country_short, 'evo')\n",
    "\n",
    "if raw == True:\n",
    "    df_mov_evo_dist.to_csv(os.path.join(output_dir, 'mov_evo_dist_raw.csv'), index=False)\n",
    "    df_mov_evo_dist_baseline_from_mov.to_csv(os.path.join(output_dir, 'mov_evo_baseline_dist_raw.csv'), index=False)\n",
    "else:\n",
    "    df_mov_evo_dist.to_csv(os.path.join(output_dir, 'mov_evo_dist_sample.csv'), index=False)\n",
    "    df_mov_evo_dist_baseline_from_baseline.to_csv(os.path.join(output_dir, 'mov_evo_baseline_dist_sample.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b90f4ab",
   "metadata": {},
   "source": [
    "# Load crisis data generated above for further adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3e9645",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop_evo = pd.read_csv(\n",
    "    f\"{wd}/data/outputs/{country_short}/evo/pop_evo_movcell.csv\"\n",
    ").drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "if raw == True:\n",
    "    df_mov_evo = pd.read_csv(\n",
    "        f\"{wd}/data/outputs/{country_short}/evo/mov_evo_dist_raw.csv\"\n",
    "    ).drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "    df_mov_evo_baseline = pd.read_csv(\n",
    "        f\"{wd}/data/outputs/{country_short}/evo/mov_evo_baseline_dist_raw.csv\"\n",
    "    ).drop(\"Unnamed: 0\", axis=1)\n",
    "else:\n",
    "    df_mov_evo = pd.read_csv(\n",
    "        f\"{wd}/data/outputs/{country_short}/evo/mov_evo_dist_sample.csv\"\n",
    "    ).drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "    df_mov_evo_baseline = pd.read_csv(\n",
    "        f\"{wd}/data/outputs/{country_short}/evo/mov_evo_baseline_dist_sample.csv\"\n",
    "    ).drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "column_to_drop = [\n",
    "    column for column in df_pop_evo.columns[1:]\n",
    "    if column not in df_mov_evo.columns[2:]\n",
    "]\n",
    "df_pop_evo = df_pop_evo.drop(column_to_drop, axis=1)\n",
    "\n",
    "column_to_drop = [\n",
    "    column for column in df_mov_evo.columns[2:]\n",
    "    if column not in df_pop_evo.columns[1:]\n",
    "]\n",
    "df_mov_evo = df_mov_evo.drop(column_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4cc6ad",
   "metadata": {},
   "source": [
    "# Example of evolution of movements and movements/FBuser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cce80ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = 1750\n",
    "origin = df_mov_evo.loc[row, \"O\"]\n",
    "\n",
    "evo_movs = df_mov_evo.loc[row, df_mov_evo.columns[2:]]\n",
    "plt.plot(np.arange(len(evo_movs)), evo_movs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3664d0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "evo_pops = df_pop_evo[df_pop_evo[\"FID\"] == origin].reset_index(drop=True)\n",
    "evo_pops = evo_pops.loc[0, evo_pops.columns[1:]]\n",
    "plt.plot(np.arange(len(evo_pops)), evo_pops)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a392541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evo_movs_per_pop = [\n",
    "    evo_movs[i] / evo_pops[i] if pd.notna(evo_pops[i]) else np.nan\n",
    "    for i in range(len(evo_pops))\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(len(evo_movs_per_pop)), evo_movs_per_pop)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18098da5",
   "metadata": {},
   "source": [
    "# Adjust FB movs with quotient of median (baseline) and daily pop in tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec95ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mov_evo_adjust = df_mov_evo.copy()\n",
    "\n",
    "# Drop movement columns not found in population evolution\n",
    "for column in df_mov_evo_adjust.columns[2:]:\n",
    "    if column not in df_pop_evo.columns:\n",
    "        df_mov_evo_adjust = df_mov_evo_adjust.drop(column, axis=1)\n",
    "\n",
    "index_to_drop = []\n",
    "\n",
    "# Compute median total population across all time points\n",
    "median = np.median([\n",
    "    np.sum(df_pop_evo[column])\n",
    "    for column in df_pop_evo.columns[1:]\n",
    "])\n",
    "\n",
    "for i in range(len(df_mov_evo_adjust)):\n",
    "    if i % 1000 == 0:\n",
    "        print(i / len(df_mov_evo_adjust) * 100)\n",
    "\n",
    "    origin = df_mov_evo_adjust.loc[i, \"O\"]\n",
    "\n",
    "    if origin in baseline_pop_imput.index:\n",
    "        for column in df_mov_evo_adjust.columns[2:]:\n",
    "            if pd.notna(df_mov_evo_adjust.loc[i, column]):\n",
    "                if pd.notna(median) and pd.notna(df_pop_evo.loc[origin, column]):\n",
    "                    df_mov_evo_adjust.loc[i, column] = (\n",
    "                        df_mov_evo_adjust.loc[i, column] * median / np.sum(df_pop_evo[column])\n",
    "                    )\n",
    "                else:\n",
    "                    df_mov_evo_adjust.loc[i, column] = np.nan\n",
    "    else:\n",
    "        index_to_drop.append(i)\n",
    "\n",
    "df_mov_evo_adjust = df_mov_evo_adjust.drop(index_to_drop).reset_index(drop=True)\n",
    "\n",
    "df_mov_evo_adjust.to_csv(\n",
    "    f\"{wd}/data/outputs/{country_short}/evo/mov_evo_dist_adjust_sample.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a689a475",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mov_evo_adjust = df_mov_evo.copy()\n",
    "\n",
    "# Drop movement columns that are not present in population evolution\n",
    "for column in df_mov_evo_adjust.columns[2:]:\n",
    "    if column not in df_pop_evo.columns:\n",
    "        df_mov_evo_adjust.drop(column, axis=1, inplace=True)\n",
    "\n",
    "index_to_drop = []\n",
    "\n",
    "# Compute median total population over all dates\n",
    "median = np.median([\n",
    "    df_pop_evo[column].sum()\n",
    "    for column in df_pop_evo.columns[1:]\n",
    "])\n",
    "\n",
    "for i in range(len(df_mov_evo_adjust)):\n",
    "    if i % 1000 == 0:\n",
    "        print(i / len(df_mov_evo_adjust) * 100)\n",
    "\n",
    "    origin = df_mov_evo_adjust.loc[i, \"O\"]\n",
    "\n",
    "    if origin in baseline_pop_imput.index:\n",
    "        for column in df_mov_evo_adjust.columns[2:]:\n",
    "            value = df_mov_evo_adjust.loc[i, column]\n",
    "            pop_value = df_pop_evo.loc[origin, column] if column in df_pop_evo.columns else np.nan\n",
    "\n",
    "            if pd.notna(value) and pd.notna(median) and pd.notna(pop_value):\n",
    "                adjusted_value = value * median / df_pop_evo[column].sum()\n",
    "                df_mov_evo_adjust.loc[i, column] = adjusted_value\n",
    "            else:\n",
    "                df_mov_evo_adjust.loc[i, column] = np.nan\n",
    "    else:\n",
    "        index_to_drop.append(i)\n",
    "\n",
    "df_mov_evo_adjust.drop(index_to_drop, inplace=True)\n",
    "df_mov_evo_adjust.reset_index(drop=True, inplace=True)\n",
    "\n",
    "output_path = f\"{wd}/data/outputs/{country_short}/evo/mov_evo_dist_adjust_sample.csv\"\n",
    "df_mov_evo_adjust.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b752fa",
   "metadata": {},
   "source": [
    "# Adjust FB movs evo baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e3bd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mov_evo_adjust = df_mov_evo.copy()\n",
    "\n",
    "# Drop movement columns that are not present in population evolution\n",
    "for column in df_mov_evo_adjust.columns[2:]:\n",
    "    if column not in df_pop_evo.columns:\n",
    "        df_mov_evo_adjust.drop(column, axis=1, inplace=True)\n",
    "\n",
    "index_to_drop = []\n",
    "\n",
    "# Compute median total population over all dates\n",
    "median = np.median([\n",
    "    df_pop_evo[column].sum()\n",
    "    for column in df_pop_evo.columns[1:]\n",
    "])\n",
    "\n",
    "for i in range(len(df_mov_evo_adjust)):\n",
    "    if i % 1000 == 0:\n",
    "        print(i / len(df_mov_evo_adjust) * 100)\n",
    "\n",
    "    origin = df_mov_evo_adjust.loc[i, \"O\"]\n",
    "\n",
    "    if origin in baseline_pop_imput.index:\n",
    "        for column in df_mov_evo_adjust.columns[2:]:\n",
    "            value = df_mov_evo_adjust.loc[i, column]\n",
    "            pop_value = df_pop_evo.loc[origin, column] if column in df_pop_evo.columns else np.nan\n",
    "\n",
    "            if pd.notna(value) and pd.notna(median) and pd.notna(pop_value):\n",
    "                adjusted_value = value * median / df_pop_evo[column].sum()\n",
    "                df_mov_evo_adjust.loc[i, column] = adjusted_value\n",
    "            else:\n",
    "                df_mov_evo_adjust.loc[i, column] = np.nan\n",
    "    else:\n",
    "        index_to_drop.append(i)\n",
    "\n",
    "df_mov_evo_adjust.drop(index_to_drop, inplace=True)\n",
    "df_mov_evo_adjust.reset_index(drop=True, inplace=True)\n",
    "\n",
    "output_path = f\"{wd}/data/outputs/{country_short}/evo/mov_evo_dist_adjust_sample.csv\"\n",
    "df_mov_evo_adjust.to_csv(output_path)\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
