---
title: "lme-r"
format: html
editor: visual
---

```{r}
# data wrangling
library(tidyverse)
# data utilities
library(timetk)
# estimating mixed effects models
library(lme4)
library(merTools)
library(glmmTMB)
library(nlme)
# correlograms
library(ggcorrplot)
library(corrplot)
# data visualisation
library(viridis)
library(ggthemes)
library(ggpubr)
library(zoo)
library(showtext)
library(patchwork)
library(ggrepel)
# display regression equation
library(equatiomatic)
# standardise input variables
  #library(arm)
  # reporting regression results
library(broom.mixed)
library(gtsummary)
library(sjPlot)
library(mgcv)
library(car)    # For VIF (optional, if you want to check multicollinearity)
library(lmtest) # For Durbin-Watson test
library(MASS)   # For stepwise AIC
```

```{r}
# Set working directory
wd <- '/Users/carmen/Library/CloudStorage/OneDrive-TheUniversityofLiverpool/research/RECAST/latin-mobility-covid-local-files'

# Set the country
country <- 'Chile'

# Initialize variables for country_short and country_code
country_short <- ""
country_code <- ""

# Assign country_short and country_code based on the country
if (country == 'Argentina') {
    country_short <- 'ARG'
    country_code <- 'AR'
} else if (country == 'Chile') {
    country_short <- 'CHL'
    country_code <- 'CL'
} else if (country == 'Colombia') {
    country_short <- 'COL'
    country_code <- 'CO'
} 
```

```{r}
category <- "density"
```

```{r}
# Read the CSV file
file_path <- paste0(wd, '/data/outputs/', country_short, '/mov-analysis/by-', category, '/time_series_capital.csv')
df <- read.csv(file_path)
df <- df[, !(names(df) == "X")]

df$time2 <- df$time^2

```

```{r}
dates <- read.csv(paste0(wd, '/data/outputs/', country_short, '/mov-analysis/dates.csv'))

df_stringency <- read.csv(paste0(wd, '/data/inputs/covid-stringency/owid-covid-data.csv')) %>%
  filter(location == "Argentina") %>% 
  filter(date %in% dates$date) %>% 
  slice(seq(1, n(), by = 7)) %>% 
  mutate(time = seq(0, n() - 1)) %>%
  select(time, stringency_index)

df <- df %>% left_join(df_stringency, by = "time")
```

```{r}
# Fit a base model (simple linear with random intercept for cat)
model_1 <- gamm(y ~ time , 
                random = list(cat = ~ 1), 
                data = df)

# Durbin-Watson test to check for autocorrelation in residuals
dw_test <- dwtest(model_1$gam)
print(dw_test)  # p-value < 0.05 indicates autocorrelation

# Check residuals for autocorrelation (ACF plot)
acf(model_1$gam$residuals)  # Look for any spikes at lag 1 (positive autocorrelation)

# Model with nonlinear effect of time (still no autocorrelation)
model_2 <- gamm(y ~ s(time) , 
                random = list(cat = ~ 1), 
                data = df)


# Model with random slopes for time (still no autocorrelation)
model_3 <- gamm(y ~ s(time), 
                random = list(cat = ~ time), 
                data = df)


# Model with AR(1) autocorrelation structure (to address autocorrelation)
model_4 <- gamm(y ~ s(time) , 
                random = list(cat = ~ time), 
                correlation = corAR1(form = ~ time | cat),
                data = df)


# Model with AR(2) autocorrelation structure (to address autocorrelation)
model_5 <- gamm(y ~ s(time) , 
                random = list(cat = ~ time), 
                correlation = corARMA(p = 2, form = ~ time | cat),
                data = df)

# Model with AR(2) autocorrelation structure (to address autocorrelation)
model_6 <- gamm(y ~ s(time) , 
                random = list(cat = ~ time), 
                correlation = corARMA(p = 4, form = ~ time | cat),
                data = df)

```

```{r}
summary(model_1$lme)
```

```{r}
print(summary(model_1$lme)$AIC)
print(summary(model_2$lme)$AIC)
print(summary(model_3$lme)$AIC)
print(summary(model_4$lme)$AIC)
print(summary(model_5$lme)$AIC)
print(summary(model_6$lme)$AIC)
```

```{r}
df_new <- data.frame(
  time = rep(0:199, times = 5),
  cat = rep(0:4, each = 200)
)
```

```{r}
# Predict on the original data (or new data if you have it)
predictions <- predict(model_6$gam, 
                       newdata = df_new, 
                       re.form=NULL,
                       type = "response")

df_new$y_pred <- predictions
```

```{r}

# Extract random effects for each level of 'cat' from the original model
random_effects <- ranef(model_3$lme)$cat

# Make predictions for the fixed effects (smooth function of time)
predictions_fixed <- predict(model_3$gam, 
                             newdata = df_new, 
                             type = "response")

# Add random effects for the corresponding 'cat' levels in new_data
df_new$predicted_y_with_random <- predictions_fixed + 
  random_effects[match(df_new$cat, names(random_effects))]

# View the updated data with predictions
print(df_new)
```
