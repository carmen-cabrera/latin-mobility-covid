{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6059ed66",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2c1d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import geopandas as gpd\n",
    "import jenkspy\n",
    "from datetime import datetime, timedelta\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81c5d4b",
   "metadata": {},
   "source": [
    "# Define country and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659eed25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select target country\n",
    "country = 'Colombia'\n",
    "\n",
    "# Set country-specific parameters: ISO codes and buffer size (in meters)\n",
    "if country == 'Argentina':\n",
    "    country_short = 'ARG'   # ISO 3-letter code\n",
    "    country_code = 'AR'     # ISO 2-letter code\n",
    "elif country == 'Chile':\n",
    "    country_short = 'CHL'\n",
    "    country_code = 'CL'\n",
    "elif country == 'Colombia':\n",
    "    country_short = 'COL'\n",
    "    country_code = 'CO'\n",
    "# Uncomment the following if Mexico is to be included in the analysis\n",
    "# elif country == 'Mexico':\n",
    "#     country_short = 'MEX'\n",
    "#     country_code = 'MX'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb27fb3",
   "metadata": {},
   "source": [
    "# Set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334a21a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define working directory path\n",
    "wd = (\n",
    "    '/Users/carmen/Library/CloudStorage/OneDrive-TheUniversityofLiverpool/'\n",
    "    'research/recast/latin-mobility-covid-local-files'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e747e1c",
   "metadata": {},
   "source": [
    "# Define some functions to generate time series of inflows, outflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953c62c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_flows(df_mov_evo, flow_type):\n",
    "    \"\"\"\n",
    "    Compute either outflows or inflows aggregated by origin or destination.\n",
    "\n",
    "    Parameters:\n",
    "    - df_mov_evo: DataFrame containing movement data with columns 'O', 'D', and time series data.\n",
    "    - flow_type: str, either 'outflows' (sum by origin) or 'inflows' (sum by destination).\n",
    "\n",
    "    Returns:\n",
    "    - df_flows: DataFrame aggregated by 'O' or 'D'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize df_flows with unique IDs depending on flow_type\n",
    "    if flow_type == 'outflows':\n",
    "        df_flows = pd.DataFrame({'O': np.unique(df_mov_evo['O'])})\n",
    "    elif flow_type == 'inflows':\n",
    "        df_flows = pd.DataFrame({'D': np.unique(df_mov_evo['D'])})\n",
    "    else:\n",
    "        raise ValueError(\"flow_type must be 'outflows' or 'inflows'\")\n",
    "\n",
    "    # Prepare empty columns for the time series data initialised with NaNs\n",
    "    time_columns = df_mov_evo.columns[2:]\n",
    "    df_flows_add = pd.DataFrame({col: [np.nan] * len(df_flows) for col in time_columns})\n",
    "\n",
    "    # Combine ID column with empty data columns\n",
    "    df_flows = pd.concat([df_flows, df_flows_add], axis=1)\n",
    "\n",
    "    # Iterate over each unique ID to compute aggregated flows\n",
    "    for i in range(len(df_flows)):\n",
    "        if flow_type == 'outflows':\n",
    "            ID = df_flows.loc[i, 'O']\n",
    "            df_subset = df_mov_evo[df_mov_evo['O'] == ID]\n",
    "        else:  # inflows\n",
    "            ID = df_flows.loc[i, 'D']\n",
    "            df_subset = df_mov_evo[df_mov_evo['D'] == ID]\n",
    "\n",
    "        # Sum values per column, ignoring NaNs\n",
    "        for column in time_columns:\n",
    "            values = df_subset[column].dropna()\n",
    "            if values.empty:\n",
    "                df_flows.loc[i, column] = np.nan\n",
    "            else:\n",
    "                df_flows.loc[i, column] = values.sum()\n",
    "\n",
    "    return df_flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311a1442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_df_ts(df_flows, df_flows_baseline, initial_col):\n",
    "    \"\"\"\n",
    "    Compute time series of movement sums and baseline sums from flow DataFrames,\n",
    "    handle missing and zero values by interpolation using nearest observations,\n",
    "    and calculate rolling averages and percentage changes.\n",
    "\n",
    "    Parameters:\n",
    "    - df_flows: DataFrame with flow data over time columns starting at initial_col\n",
    "    - df_flows_baseline: Baseline DataFrame with same structure as df_flows\n",
    "    - initial_col: int, index of the first time column in the DataFrames\n",
    "\n",
    "    Returns:\n",
    "    - df_ts: DataFrame with dates, movements, baseline, filled values, rolling means,\n",
    "             and percentage change metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    evo_movs = []\n",
    "    evo_movs_baseline = []\n",
    "\n",
    "    # Aggregate sum of movements and baseline for each time column, ignoring NaNs\n",
    "    for column in df_flows.columns[initial_col:]:\n",
    "        sums_mov = []\n",
    "        sums_baseline = []\n",
    "        for i in range(len(df_flows)):\n",
    "            val_mov = df_flows.loc[i, column]\n",
    "            val_base = df_flows_baseline.loc[i, column]\n",
    "            if not pd.isna(val_mov) and not pd.isna(val_base):\n",
    "                sums_mov.append(val_mov)\n",
    "                sums_baseline.append(val_base)\n",
    "        if sums_mov:\n",
    "            evo_movs.append(np.sum(sums_mov))\n",
    "            evo_movs_baseline.append(np.sum(sums_baseline))\n",
    "        else:\n",
    "            evo_movs.append(np.nan)\n",
    "            evo_movs_baseline.append(np.nan)\n",
    "\n",
    "    # Create DataFrame with date and aggregated sums\n",
    "    df_ts = pd.DataFrame({\n",
    "        'date': df_flows.columns[initial_col:],\n",
    "        'movements': evo_movs,\n",
    "        'baseline': evo_movs_baseline\n",
    "    })\n",
    "\n",
    "    # Function to fill zeros and NaNs using mean of closest 15 observations in time series\n",
    "    def fill_zeros_and_nans(series, fill_column_name):\n",
    "        series.replace(0, np.nan, inplace=True)\n",
    "        series.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "        is_na = series.isna()\n",
    "        filled_series = series.copy()\n",
    "\n",
    "        # Extract rows where values are not NaN for reference\n",
    "        valid_idx = series.dropna().index\n",
    "        valid_vals = series.dropna()\n",
    "\n",
    "        # For each NaN, find 15 nearest valid observations by index distance and take their mean\n",
    "        for idx in series[is_na].index:\n",
    "            distances = abs(valid_idx - idx)\n",
    "            nearest_idx = distances.nsmallest(15).index\n",
    "            filled_series.loc[idx] = valid_vals.loc[nearest_idx].mean()\n",
    "\n",
    "        return filled_series\n",
    "\n",
    "    # Fill movements and baseline columns\n",
    "    df_ts['movements_fill'] = fill_zeros_and_nans(df_ts['movements'], 'movements_fill')\n",
    "    df_ts['rolling'] = df_ts['movements_fill'].rolling(window=15, min_periods=1).mean()\n",
    "\n",
    "    df_ts['baseline_fill'] = fill_zeros_and_nans(df_ts['baseline'], 'baseline_fill')\n",
    "    df_ts['rolling_baseline'] = df_ts['baseline_fill'].rolling(window=15, min_periods=1).mean()\n",
    "\n",
    "    # Calculate percentage change between movements and baseline\n",
    "    df_ts['perchange'] = (df_ts['movements_fill'] - df_ts['baseline_fill']) / df_ts['baseline_fill'] * 100\n",
    "    df_ts['rolling_perchange'] = df_ts['perchange'].rolling(window=30, min_periods=1).mean()\n",
    "\n",
    "    return df_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e01eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_df_ts_weekly(df_ts):\n",
    "    \"\"\"\n",
    "    Aggregate daily time series data into weekly summaries.\n",
    "\n",
    "    Parameters:\n",
    "    - df_ts: DataFrame containing daily time series with at least the following columns:\n",
    "             'date', 'movements', 'baseline', 'movements_fill', 'baseline_fill'\n",
    "\n",
    "    Returns:\n",
    "    - df_ts_weekly: DataFrame aggregated by week with sums and percentage change.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate number of full weeks in the data (each week has 7 days)\n",
    "    num_weeks = len(df_ts) // 7\n",
    "\n",
    "    # Initialise DataFrame for weekly aggregation\n",
    "    df_ts_weekly = pd.DataFrame({'week_no': range(num_weeks)})\n",
    "\n",
    "    # Aggregate by week:\n",
    "    # - 'week_start' is the date of the first day of the week\n",
    "    # - sum the columns over each week block of 7 days\n",
    "    df_ts_weekly['week_start'] = [df_ts.loc[i * 7, 'date'] for i in range(num_weeks)]\n",
    "    df_ts_weekly['movements'] = [np.sum(df_ts.loc[i * 7:(i + 1) * 7 - 1, 'movements']) for i in range(num_weeks)]\n",
    "    df_ts_weekly['baseline'] = [np.sum(df_ts.loc[i * 7:(i + 1) * 7 - 1, 'baseline']) for i in range(num_weeks)]\n",
    "    df_ts_weekly['movements_fill'] = [np.sum(df_ts.loc[i * 7:(i + 1) * 7 - 1, 'movements_fill']) for i in range(num_weeks)]\n",
    "    df_ts_weekly['baseline_fill'] = [np.sum(df_ts.loc[i * 7:(i + 1) * 7 - 1, 'baseline_fill']) for i in range(num_weeks)]\n",
    "\n",
    "    # Compute weekly percentage change between filled movements and baseline\n",
    "    df_ts_weekly['perchange'] = [\n",
    "        (df_ts_weekly.loc[i, 'movements_fill'] - df_ts_weekly.loc[i, 'baseline_fill']) / df_ts_weekly.loc[i, 'baseline_fill'] * 100\n",
    "        for i in range(num_weeks)\n",
    "    ]\n",
    "\n",
    "    return df_ts_weekly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851078cc",
   "metadata": {},
   "source": [
    "# Read some additional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dd9d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load COVID-19 stringency data from CSV file\n",
    "df_stringency = pd.read_csv(wd + '/data/inputs/covid-stringency/owid-covid-data.csv')\n",
    "\n",
    "# Filter the data for the specified country (case-insensitive, capitalizes first letter)\n",
    "df_stringency = df_stringency[df_stringency['location'] == str(country).capitalize()].reset_index(drop=True)                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266885dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load baseline population data with exogenous variables from a GeoPackage file\n",
    "baseline_pop_imput = gpd.read_file(\n",
    "    wd + '/data/outputs/' + country_short + '/grids-with-data/movcell-baseline-imput-pop-with-exo-var/movcell-baseline-imput-pop-with-exo-var.gpkg'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30534ac2",
   "metadata": {},
   "source": [
    "# Set filename suffixes based on processing options:\n",
    "- `dist`: whether to include movements with distance >=0 (adds '_dist' if True) <br>\n",
    "- `raw`: whether using raw data (adds '_raw' if True) <br>\n",
    "- `adjust`: whether data is adjusted (adds '_adjust' if True) <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3a8d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = True\n",
    "raw = False\n",
    "adjust = True\n",
    "\n",
    "# Initialise suffix strings based on boolean flags\n",
    "\n",
    "# Assign suffix '_dist' if dist is True, else empty string\n",
    "dist = '_dist' if dist else ''\n",
    "\n",
    "# Assign suffix '_raw' if raw is True, else empty string\n",
    "raw = '_raw' if raw else ''\n",
    "\n",
    "# Assign suffix '_adjust' if adjust is True, else empty string\n",
    "adjust = '_adjust' if adjust else ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b911410",
   "metadata": {},
   "source": [
    "# Read movement data as time series for each tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0851bda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read mobility evolution data from CSV file, drop the first unnamed index column\n",
    "df_mov_evo = pd.read_csv(\n",
    "    wd + '/data/outputs/' + country_short + '/evo/mov_evo' + dist + raw + adjust + '.csv'\n",
    ").drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# Read baseline mobility evolution data, drop the first unnamed index column\n",
    "df_mov_evo_baseline = pd.read_csv(\n",
    "    wd + '/data/outputs/' + country_short + '/evo/mov_evo_baseline' + dist + raw + '.csv'\n",
    ").drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47634f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Only uncomment and run this block when needed â€” it may take time\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Compute outflows and inflows from mobility evolution data\n",
    "# df_outflows = compute_flows(df_mov_evo, 'outflows')\n",
    "# df_inflows = compute_flows(df_mov_evo, 'inflows')\n",
    "\n",
    "# Compute outflows and inflows from baseline mobility data\n",
    "# df_outflows_baseline = compute_flows(df_mov_evo_baseline, 'outflows')\n",
    "# df_inflows_baseline = compute_flows(df_mov_evo_baseline, 'inflows')\n",
    "\n",
    "# Save the computed dataframes to CSV files\n",
    "# df_outflows.to_csv(\n",
    "#     wd + '/data/outputs/' + country_short + '/mov-analysis/outflows' +\n",
    "#     dist + raw + adjust + '_sample.csv'\n",
    "# )\n",
    "# df_inflows.to_csv(\n",
    "#     wd + '/data/outputs/' + country_short + '/mov-analysis/inflows' +\n",
    "#     dist + raw + adjust + '_sample.csv'\n",
    "# )\n",
    "# df_outflows_baseline.to_csv(\n",
    "#     wd + '/data/outputs/' + country_short + '/mov-analysis/outflows_baseline' +\n",
    "#     dist + raw + '_sample.csv'\n",
    "# )\n",
    "# df_inflows_baseline.to_csv(\n",
    "#     wd + '/data/outputs/' + country_short + '/mov-analysis/inflows_baseline' +\n",
    "#     dist + raw + '_sample.csv'\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f363ee4a",
   "metadata": {},
   "source": [
    "# Read movement data as time series for inflows or outflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0e900d",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Set the type of flow to analyze ('movs', 'inflows', or 'outflows')\n",
    "flows = 'outflows'  # change to 'movs', 'inflows', or 'outflows' as needed\n",
    "\n",
    "# Load appropriate flow data depending on the selected flow type\n",
    "if flows in ['inflows', 'outflows']:\n",
    "    # Load computed flow data and baseline from CSV, dropping the index column\n",
    "    df_flows = pd.read_csv(\n",
    "        wd + '/data/outputs/' + country_short + '/mov-analysis/' +\n",
    "        flows + dist + raw + adjust + '.csv'\n",
    "    ).drop('Unnamed: 0', axis=1)\n",
    "\n",
    "    df_flows_baseline = pd.read_csv(\n",
    "        wd + '/data/outputs/' + country_short + '/mov-analysis/' +\n",
    "        flows + '_baseline' + dist + raw + '.csv'\n",
    "    ).drop('Unnamed: 0', axis=1)\n",
    "\n",
    "    # Set the initial column index for further processing\n",
    "    initial_col = 1\n",
    "\n",
    "else:\n",
    "    # Use raw mobility evolution data directly if 'movs' is selected\n",
    "    df_flows = df_mov_evo\n",
    "    df_flows_baseline = df_mov_evo_baseline\n",
    "    initial_col = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca203a1",
   "metadata": {},
   "source": [
    "# Compute total inflows or outflows, as a sum, handling missing values\n",
    "\n",
    "And visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11306038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute time-series data from flows and baseline\n",
    "df_ts = compute_df_ts(df_flows, df_flows_baseline, initial_col)\n",
    "\n",
    "# -----------------------------\n",
    "# Plot 1: Raw Movements Over Time\n",
    "# -----------------------------\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Uncomment below to set custom y-axis range\n",
    "# ax.set_ylim([-2000, 45000])\n",
    "\n",
    "# Plot different mobility indicators\n",
    "ax.plot(np.arange(len(df_ts)), df_ts['movements_fill'], color='steelblue', lw=1, alpha=0.7)\n",
    "ax.plot(np.arange(len(df_ts)), df_ts['rolling'], color='darkred', lw=1.5)\n",
    "ax.plot(np.arange(len(df_ts)), df_ts['rolling_baseline'], color='darkblue', lw=1.5)\n",
    "\n",
    "# Prepare stringency index for background coloring\n",
    "stringencies = []\n",
    "for date in df_ts['date']:\n",
    "    try:\n",
    "        stringency_value = df_stringency[df_stringency['date'] == date].reset_index(drop=True).loc[0, 'stringency_index']\n",
    "    except IndexError:\n",
    "        stringency_value = stringencies[-1] if stringencies else 0\n",
    "    stringencies.append(stringency_value)\n",
    "\n",
    "# Add background shading by stringency level\n",
    "for k in range(len(df_ts)):\n",
    "    try:\n",
    "        rgba = matplotlib.cm.gist_heat(\n",
    "            1 - (stringencies[k] - min(stringencies)) / max(stringencies)\n",
    "        )\n",
    "    except Exception:\n",
    "        rgba = matplotlib.cm.gist_heat(\n",
    "            1 - (stringencies[k - 1] - min(stringencies)) / max(stringencies)\n",
    "        )\n",
    "    x = [k - 0.5, k + 0.5]\n",
    "    ax.fill_between(\n",
    "        x,\n",
    "        0,\n",
    "        max(df_ts['movements_fill']),\n",
    "        color=rgba,\n",
    "        alpha=0.6,\n",
    "        edgecolor='None',\n",
    "        linewidth=0,\n",
    "        zorder=0\n",
    "    )\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# Plot 2: Weekly % Change\n",
    "# -----------------------------\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Remove tick marks but style them\n",
    "ax.tick_params(axis='both', which='both', width=0, length=0, labelsize=20, pad=9)\n",
    "\n",
    "# Compute weekly aggregation and rolling percent change\n",
    "df_ts_weekly = compute_df_ts_weekly(df_ts)\n",
    "df_ts_weekly['rolling_perchange'] = df_ts_weekly['perchange'].rolling(window=4).mean()\n",
    "\n",
    "# Plot rolling % change (smoothed)\n",
    "ax.plot(\n",
    "    np.arange(len(df_ts_weekly['rolling_perchange'])) * 7,\n",
    "    df_ts_weekly['rolling_perchange'],\n",
    "    color='black',\n",
    "    lw=2,\n",
    "    zorder=3\n",
    ")\n",
    "\n",
    "# Add baseline line at 0\n",
    "ax.plot(\n",
    "    np.arange(len(df_ts_weekly['rolling_perchange']) * 7),\n",
    "    np.zeros(len(df_ts_weekly['rolling_perchange']) * 7),\n",
    "    linestyle=':',\n",
    "    color='k'\n",
    ")\n",
    "\n",
    "# Re-use stringency values for coloring\n",
    "stringencies = []\n",
    "for date in df_ts['date']:\n",
    "    try:\n",
    "        stringency_value = df_stringency[df_stringency['date'] == date].reset_index(drop=True).loc[0, 'stringency_index']\n",
    "    except IndexError:\n",
    "        stringency_value = stringencies[-1] if stringencies else 0\n",
    "    stringencies.append(stringency_value)\n",
    "\n",
    "# Y-axis limits\n",
    "ymin = int(min([-100, np.min(df_ts_weekly['rolling_perchange'])]))\n",
    "ymax = int(max([101, np.max(df_ts_weekly['rolling_perchange']) + 1]))\n",
    "\n",
    "# Add background shading\n",
    "for k in range(len(df_ts)):\n",
    "    try:\n",
    "        rgba = matplotlib.cm.gist_heat(\n",
    "            1 - (stringencies[k] - min(stringencies)) / max(stringencies)\n",
    "        )\n",
    "    except Exception:\n",
    "        rgba = matplotlib.cm.gist_heat(\n",
    "            1 - (stringencies[k - 1] - min(stringencies)) / max(stringencies)\n",
    "        )\n",
    "    x = [k - 0.5, k + 0.5]\n",
    "    ax.fill_between(\n",
    "        x,\n",
    "        -100,\n",
    "        100,\n",
    "        color=rgba,\n",
    "        alpha=0.6,\n",
    "        edgecolor='None',\n",
    "        linewidth=0,\n",
    "        zorder=0\n",
    "    )\n",
    "\n",
    "# Format x-axis with selected date labels\n",
    "xticks = [i for i in range(0, len(df_ts['rolling_perchange'])) if i % 183 == 0]\n",
    "xtick_labels = ['Apr 2020', 'Oct 2020', 'Apr 2021', 'Oct 2021', 'Apr 2022']\n",
    "ax.set_xticks(xticks, xtick_labels)\n",
    "ax.tick_params(axis='x', bottom=True, labelsize=10, pad=6, rotation=90)\n",
    "\n",
    "# Format y-axis\n",
    "yticks = [i for i in range(ymin, ymax) if i % 25 == 0]\n",
    "ax.set_yticks(yticks)\n",
    "for y in yticks:\n",
    "    ax.plot([0, len(df_ts['rolling_perchange'])], [y, y], color='gray', lw=0.7, zorder=0)\n",
    "ax.tick_params(axis='y', labelsize=10, pad=6)\n",
    "\n",
    "# Save figure (uncomment when ready to save)\n",
    "# plt.savefig(\n",
    "#     wd + '/plots/evolution/' + flows + '/total/' + country_short +\n",
    "#     '/evo' + dist + raw + adjust + '.pdf',\n",
    "#     bbox_inches='tight'\n",
    "# )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db405764",
   "metadata": {},
   "source": [
    "# By density class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db738eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of classes for population density classification\n",
    "n_class_density = 5\n",
    "\n",
    "# Compute natural breaks (Jenks) for the 'density' column\n",
    "breaks_density = jenkspy.jenks_breaks(\n",
    "    baseline_pop_imput.dropna(subset=['density'])['density'],\n",
    "    n_classes=n_class_density\n",
    ")\n",
    "\n",
    "# Slightly adjust the first break to ensure inclusion of the minimum value\n",
    "breaks_density[0] -= 10**(-10)\n",
    "\n",
    "# Classify 'density' values into discrete bins using Jenks natural breaks\n",
    "baseline_pop_imput['class_density'] = pd.cut(\n",
    "    baseline_pop_imput['density'],\n",
    "    bins=breaks_density,\n",
    "    labels=[i for i in range(n_class_density)]\n",
    ")\n",
    "\n",
    "# Ensure resulting class labels are treated as numeric\n",
    "baseline_pop_imput['class_density'] = pd.to_numeric(baseline_pop_imput['class_density'])\n",
    "\n",
    "# Get unique population density classes (excluding NaNs)\n",
    "class_density = np.unique(baseline_pop_imput['class_density'])\n",
    "n_class_density = len(class_density[~np.isnan(class_density)])\n",
    "\n",
    "# Initialise array to store weekly percent change for each density class\n",
    "df_ts_weekly_class_density = np.zeros((n_class_density, len(df_ts_weekly)))\n",
    "\n",
    "# Iterate over each density class\n",
    "for i in range(n_class_density):\n",
    "\n",
    "    # Get indices of locations belonging to the current density class\n",
    "    indexes = set(baseline_pop_imput[baseline_pop_imput['class_density'] == i].index)\n",
    "\n",
    "    # Create a mask to filter flow data depending on flow direction\n",
    "    if flows == 'movs':\n",
    "        mask = df_flows['O'].isin(indexes) | df_flows['D'].isin(indexes)\n",
    "    elif flows == 'outflows':\n",
    "        mask = df_flows['O'].isin(indexes)\n",
    "    elif flows == 'inflows':\n",
    "        mask = df_flows['D'].isin(indexes)\n",
    "\n",
    "    # Filter both current and baseline flow datasets\n",
    "    df_flows_class_density = df_flows[mask].reset_index(drop=True)\n",
    "    df_flows_class_density_baseline = df_flows_baseline[mask].reset_index(drop=True)\n",
    "\n",
    "    # Compute time-series for this class\n",
    "    df_ts_class_density = compute_df_ts(\n",
    "        df_flows_class_density,\n",
    "        df_flows_class_density_baseline,\n",
    "        initial_col\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0afd633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Plot option 1: weekly % change by density class\n",
    "# -----------------------------\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.tick_params(axis='both', which='both', width=0, length=0, labelsize=20, pad=9)\n",
    "\n",
    "viridis = plt.cm.get_cmap('viridis')\n",
    "norm = plt.Normalize(0, n_class_density - 1)\n",
    "\n",
    "for i in range(n_class_density):\n",
    "    color = viridis(norm(i))\n",
    "    df_class = pd.DataFrame({'perchange_class': df_ts_weekly_class_density[i, :]})\n",
    "    df_class['rolling_perchange'] = df_class['perchange_class'].rolling(window=4).mean()\n",
    "    ax.plot(np.arange(len(df_class['rolling_perchange'])) * 7, df_class['rolling_perchange'], color=color, lw=2, zorder=3)\n",
    "\n",
    "ax.plot(np.arange(len(df_class['rolling_perchange']) * 7), np.zeros(len(df_class['rolling_perchange']) * 7), linestyle=':', color='k')\n",
    "\n",
    "# Stringency shading\n",
    "stringencies = []\n",
    "for date in df_ts['date']:\n",
    "    try:\n",
    "        val = df_stringency[df_stringency['date'] == date].reset_index(drop=True).loc[0, 'stringency_index']\n",
    "    except IndexError:\n",
    "        val = np.nan\n",
    "    stringencies.append(val)\n",
    "\n",
    "ymin = int(min(-100, np.nanmin(df_ts_weekly_class_density)))\n",
    "ymax = int(max(101, np.nanmax(df_ts_weekly_class_density)) + 1)\n",
    "\n",
    "for k in range(len(df_ts)):\n",
    "    try:\n",
    "        rgba = matplotlib.cm.gist_heat(1 - (stringencies[k] - np.nanmin(stringencies)) / np.nanmax(stringencies))\n",
    "    except:\n",
    "        rgba = matplotlib.cm.gist_heat(1 - (stringencies[k - 1] - np.nanmin(stringencies)) / np.nanmax(stringencies))\n",
    "    ax.fill_between([k - 0.5, k + 0.5], ymin, ymax, color=rgba, alpha=0.6, edgecolor='none', linewidth=0, zorder=0)\n",
    "\n",
    "# Axis ticks\n",
    "xticks = [i for i in range(0, len(df_ts['rolling_perchange'])) if i % 183 == 0]\n",
    "xtick_labels = ['Apr 2020', 'Oct 2020', 'Apr 2021', 'Oct 2021', 'Apr 2022']\n",
    "ax.set_xticks(xticks, xtick_labels)\n",
    "ax.tick_params(axis='x', bottom=True, labelsize=10, pad=6, rotation=90)\n",
    "\n",
    "yticks = [i for i in range(ymin, ymax) if i % 25 == 0]\n",
    "ax.set_yticks(yticks)\n",
    "for y in yticks:\n",
    "    ax.plot([0, len(df_ts['rolling_perchange'])], [y, y], color='gray', lw=0.7, zorder=0)\n",
    "ax.tick_params(axis='y', labelsize=10, pad=6)\n",
    "\n",
    "# plt.savefig(wd + '/plots/evolution/' + flows + '/by-density/' + country_short + '/evo' + dist + raw + adjust + '.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5ae10f",
   "metadata": {},
   "source": [
    "# Plotting weekly rolling % change in flows by population density class\n",
    " And trend decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec54d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Plot option 2: weekly % change by density class\n",
    "# -----------------------------\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    1,\n",
    "    n_class_density,\n",
    "    sharey=True,\n",
    "    gridspec_kw={'hspace': 0.1, 'wspace': 0.1},\n",
    "    figsize=(40, 7.5),\n",
    ")\n",
    "df_trend = pd.DataFrame(\n",
    "    columns=[df_ts_weekly.loc[i, 'week_start'] for i in range(len(df_ts_weekly))]\n",
    ")\n",
    "\n",
    "for i in range(n_class_density):\n",
    "    axs[i].tick_params(axis='both', which='both', width=0, length=0, color='k', labelsize=20, pad=9)\n",
    "\n",
    "    viridis = plt.cm.get_cmap('viridis')\n",
    "    norm = plt.Normalize(0, n_class_density - 1)\n",
    "\n",
    "    color = viridis(norm(i))\n",
    "    df_ts_weekly_class_density_plot = pd.DataFrame({'perchange_class': df_ts_weekly_class_density[i, :]})\n",
    "    df_ts_weekly_class_density_plot.loc[:, 'rolling_perchange'] = df_ts_weekly_class_density_plot[\n",
    "        'perchange_class'\n",
    "    ].rolling(window=4).mean()\n",
    "    axs[i].plot(\n",
    "        np.arange(len(df_ts_weekly_class_density_plot['rolling_perchange'])) * 7,\n",
    "        df_ts_weekly_class_density_plot['rolling_perchange'],\n",
    "        color=color,\n",
    "        lw=8,\n",
    "        zorder=6,\n",
    "    )\n",
    "\n",
    "    axs[i].plot(\n",
    "        np.arange(len(df_ts_weekly_class_density_plot['rolling_perchange']) * 7),\n",
    "        np.zeros(len(df_ts_weekly_class_density_plot['rolling_perchange']) * 7),\n",
    "        lw=4,\n",
    "        linestyle=':',\n",
    "        color='k',\n",
    "        zorder=5,\n",
    "    )\n",
    "\n",
    "    series = pd.DataFrame({\n",
    "        'index': pd.to_datetime(df_ts_weekly['week_start']),\n",
    "        'value': df_ts_weekly_class_density[i, :],\n",
    "    })\n",
    "    series.index = series['index']\n",
    "    series = series.drop(['index'], axis=1)\n",
    "    try:\n",
    "        result = seasonal_decompose(series, model='additive', extrapolate_trend='freq')\n",
    "        df_trend.loc[i] = result.trend\n",
    "        # axs[i,j].plot(np.arange(len(df_ts_weekly['week_start']))*7, result.trend, color='white', lw=2, linestyle='-', zorder=4)\n",
    "    except:\n",
    "        print('not possible for this ', i)\n",
    "\n",
    "    stringencies = []\n",
    "    for date in df_ts['date']:\n",
    "        stringencies.append(df_stringency[df_stringency['date'] == date].reset_index(drop=True).loc[0, 'stringency_index'])\n",
    "\n",
    "    ymin = int(min([-100, np.min(df_ts_weekly_class_density)]))\n",
    "    try:\n",
    "        ymax = int(\n",
    "            max(\n",
    "                [101, np.max([i for i in df_ts_weekly_class_density.flatten() if i < np.max(df_ts_weekly_class_density)]) + 1]\n",
    "            )\n",
    "        )\n",
    "    except:\n",
    "        ymax = 101\n",
    "\n",
    "    for l in range(len(df_ts)):\n",
    "        try:\n",
    "            rgba = matplotlib.cm.gray(1 - (stringencies[l] - min(stringencies)) / max(stringencies))\n",
    "        except:\n",
    "            rgba = matplotlib.cm.gray(1 - (stringencies[l - 1] - min(stringencies)) / max(stringencies))\n",
    "        x = [l - 0.50, l + 0.50]\n",
    "        axs[i].fill_between(x, ymin, ymax, color=rgba, alpha=0.4, edgecolor='None', linewidth=0, zorder=0)\n",
    "\n",
    "    xticks = []\n",
    "    xticks_labels = ['Apr 2020', 'Oct 2020', 'Apr 2021', 'Oct 2021', 'Apr 2022']\n",
    "    for l in range(0, len(df_ts['rolling_perchange'])):\n",
    "        if l % 183 == 0:\n",
    "            xticks.append(l)\n",
    "    axs[i].set_xticks(xticks, xticks_labels)\n",
    "    axs[i].tick_params(axis='x', bottom=True, labelsize=35, pad=12, rotation=90)\n",
    "\n",
    "    yticks = []\n",
    "    for l in range(ymin, ymax):\n",
    "        if l % 50 == 0:\n",
    "            yticks.append(l)\n",
    "    axs[i].set_yticks(yticks, yticks)\n",
    "    for y in yticks:\n",
    "        axs[i].plot([0, len(df_ts['rolling_perchange'])], [y, y], color='gray', lw=1.5, zorder=0)\n",
    "    axs[i].tick_params(axis='y', labelsize=40, pad=12, rotation=0)\n",
    "\n",
    "# plt.savefig(wd + '/plots/evolution/' + flows + '/by-density/' + country_short + '/evo' + dist + raw + adjust + '_by_origin.pdf', bbox_inches = 'tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b087cc9d",
   "metadata": {},
   "source": [
    "# Transforming the trend DataFrame to long format and saving it as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864c5bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = []\n",
    "cat = []\n",
    "y = []\n",
    "\n",
    "for i in range(len(df_trend)):\n",
    "    for j in range(len(df_trend.columns)):\n",
    "        time.append(j)\n",
    "        cat.append(i)\n",
    "        y.append(df_trend.loc[i, df_trend.columns[j]])\n",
    "\n",
    "df_trend_long = pd.DataFrame({'time': time, 'cat': cat, 'y': y})\n",
    "\n",
    "df_trend_long.to_csv(\n",
    "    wd + '/data/outputs/' + country_short + '/mov-analysis/by-density/data_trend_new.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9afb69",
   "metadata": {},
   "source": [
    "# By rdi class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8718c0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class_rdi = 3  # Number of RDI classes to create\n",
    "\n",
    "# Calculate Jenks natural breaks for 'rdi' values, excluding NaNs\n",
    "breaks_rdi = jenkspy.jenks_breaks(baseline_pop_imput.dropna(subset=['rdi'])['rdi'], n_classes=n_class_rdi)\n",
    "\n",
    "# Adjust first break slightly to include the minimum value\n",
    "breaks_rdi[0] = breaks_rdi[0] - 10**(-10)\n",
    "\n",
    "# Categorise 'rdi' values into classes based on Jenks breaks\n",
    "# (alternative qcut method commented out)\n",
    "baseline_pop_imput['class_rdi'] = pd.cut(\n",
    "    baseline_pop_imput['rdi'],\n",
    "    bins=breaks_rdi,\n",
    "    labels=[i for i in range(n_class_rdi)]\n",
    ")\n",
    "baseline_pop_imput['class_rdi'] = pd.to_numeric(baseline_pop_imput['class_rdi'])\n",
    "\n",
    "# Get unique class labels and count valid classes\n",
    "class_rdi = np.unique(baseline_pop_imput['class_rdi'])\n",
    "n_class_rdi = len(class_rdi[~np.isnan(class_rdi)])\n",
    "\n",
    "# Initialise array to store weekly time series data per RDI class\n",
    "df_ts_weekly_class_rdi = np.zeros((n_class_rdi, len(df_ts_weekly)))\n",
    "\n",
    "# Loop over each RDI class to compute flows and weekly changes\n",
    "for i in range(n_class_rdi):\n",
    "    # Find indices belonging to current RDI class\n",
    "    indexes = set(baseline_pop_imput[baseline_pop_imput['class_rdi'] == i].index)\n",
    "    \n",
    "    # Define mask depending on flow type\n",
    "    if flows == 'movs':\n",
    "        mask = df_flows['O'].isin(indexes) | df_flows['D'].isin(indexes)\n",
    "    elif flows == 'outflows':\n",
    "        mask = df_flows['O'].isin(indexes)\n",
    "    elif flows == 'inflows':\n",
    "        mask = df_flows['D'].isin(indexes)\n",
    "    \n",
    "    # Filter flows based on mask and reset index\n",
    "    df_flows_class_rdi = df_flows[mask].reset_index(drop=True)\n",
    "    df_flows_class_rdi_baseline = df_flows_baseline[mask].reset_index(drop=True)\n",
    "    \n",
    "    # Compute time series for current RDI class\n",
    "    df_ts_class_rdi = compute_df_ts(df_flows_class_rdi, df_flows_class_rdi_baseline, initial_col)\n",
    "    \n",
    "    # Compute weekly percent change and store in array\n",
    "    df_ts_weekly_class_rdi[i, :] = compute_df_ts_weekly(df_ts_class_rdi)['perchange']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3655d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Plot option 1: weekly % change by RDI class\n",
    "# -----------------------------\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Configure axis ticks style\n",
    "ax.tick_params(axis='both', which='both', width=0, length=0, color='k', labelsize=20, pad=9)\n",
    "\n",
    "# Colormap and normalization for RDI classes\n",
    "viridis = plt.cm.get_cmap('viridis_r')\n",
    "norm = plt.Normalize(0, n_class_rdi - 1)\n",
    "\n",
    "# Plot rolling mean percent changes for each RDI class\n",
    "for i in range(n_class_rdi):\n",
    "    color = viridis(norm(i))\n",
    "    df_ts_weekly_class_rdi_plot = pd.DataFrame({'perchange_class': df_ts_weekly_class_rdi[i, :]})\n",
    "    df_ts_weekly_class_rdi_plot['rolling_perchange'] = df_ts_weekly_class_rdi_plot['perchange_class'].rolling(window=4).mean()\n",
    "    ax.plot(np.arange(len(df_ts_weekly_class_rdi_plot['rolling_perchange'])) * 7,\n",
    "            df_ts_weekly_class_rdi_plot['rolling_perchange'],\n",
    "            color=color, lw=2, zorder=3)\n",
    "\n",
    "# Plot horizontal zero line\n",
    "ax.plot(np.arange(len(df_ts_weekly_class_rdi_plot['rolling_perchange']) * 7),\n",
    "        np.zeros(len(df_ts_weekly_class_rdi_plot['rolling_perchange']) * 7),\n",
    "        linestyle=':', color='k')\n",
    "\n",
    "# Prepare stringency index shading background\n",
    "stringencies = [df_stringency[df_stringency['date'] == date].reset_index(drop=True).loc[0, 'stringency_index'] for date in df_ts['date']]\n",
    "\n",
    "ymin = int(min([-100, np.min(df_ts_weekly_class_rdi)]))\n",
    "ymax = int(max([101, np.max([i for i in df_ts_weekly_class_density.flatten() if i < np.max(df_ts_weekly_class_density)]) + 1]))\n",
    "\n",
    "# Add shaded areas according to stringency index values\n",
    "for k in range(len(df_ts)):\n",
    "    try:\n",
    "        rgba = matplotlib.cm.gist_heat(1 - (stringencies[k] - min(stringencies)) / max(stringencies))\n",
    "    except:\n",
    "        rgba = matplotlib.cm.gist_heat(1 - (stringencies[k-1] - min(stringencies)) / max(stringencies))\n",
    "    x = [k - 0.5, k + 0.5]\n",
    "    ax.fill_between(x, ymin, ymax, color=rgba, alpha=0.6, edgecolor='None', linewidth=0, zorder=0)\n",
    "\n",
    "# Set x-axis ticks and labels\n",
    "xticks = [i for i in range(0, len(df_ts['rolling_perchange'])) if i % 183 == 0]\n",
    "xticks_labels = ['Apr 2020', 'Oct 2020', 'Apr 2021', 'Oct 2021', 'Apr 2022']\n",
    "ax.set_xticks(xticks)\n",
    "ax.set_xticklabels(xticks_labels)\n",
    "ax.tick_params(axis='x', bottom=True, labelsize=10, pad=6, rotation=90)\n",
    "\n",
    "# Set y-axis ticks and grid lines\n",
    "yticks = [i for i in range(ymin, ymax) if i % 25 == 0]\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_yticklabels(yticks)\n",
    "for y in yticks:\n",
    "    ax.plot([0, len(df_ts['rolling_perchange'])], [y, y], color='gray', lw=0.7, zorder=0)\n",
    "ax.tick_params(axis='y', labelsize=10, pad=6, rotation=0)\n",
    "\n",
    "# Uncomment to save the figure\n",
    "# plt.savefig(wd + '/plots/evolution/' + flows + '/by-rdi/' + country_short + '/evo' + dist + raw + adjust + '.pdf', bbox_inches='tight')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e33f506",
   "metadata": {},
   "source": [
    "# Plotting weekly rolling % change in flows by RDI class\n",
    "And trend decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a360969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Plot option 2: weekly % change by RDI class\n",
    "# -----------------------------\n",
    "\n",
    "fig, axs = plt.subplots(\n",
    "    1,\n",
    "    n_class_rdi,\n",
    "    sharey=True,\n",
    "    gridspec_kw={'hspace': 0.07, 'wspace': 0.07},\n",
    "    figsize=(24, 7.5)\n",
    ")\n",
    "\n",
    "# Prepare DataFrame to store trend components from seasonal decomposition\n",
    "df_trend = pd.DataFrame(columns=[df_ts_weekly.loc[i, 'week_start'] for i in range(len(df_ts_weekly))])\n",
    "\n",
    "for i in range(n_class_rdi):\n",
    "    # Customize tick appearance for each subplot\n",
    "    axs[i].tick_params(axis='both', which='both', width=0, length=0, color='k', labelsize=20, pad=9)\n",
    "\n",
    "    # Set colormap and normalization\n",
    "    viridis = plt.cm.get_cmap('viridis')\n",
    "    norm = plt.Normalize(0, n_class_rdi - 1)\n",
    "    color = viridis(norm(i))\n",
    "\n",
    "    # Create DataFrame with percent change data and calculate rolling mean\n",
    "    df_ts_weekly_class_rdi_plot = pd.DataFrame({'perchange_class': df_ts_weekly_class_rdi[i, :]})\n",
    "    df_ts_weekly_class_rdi_plot['rolling_perchange'] = df_ts_weekly_class_rdi_plot['perchange_class'].rolling(window=4).mean()\n",
    "\n",
    "    # Plot rolling percent change\n",
    "    axs[i].plot(\n",
    "        np.arange(len(df_ts_weekly_class_rdi_plot['rolling_perchange'])) * 7,\n",
    "        df_ts_weekly_class_rdi_plot['rolling_perchange'],\n",
    "        color=color, lw=7, zorder=6\n",
    "    )\n",
    "\n",
    "    # Plot horizontal zero line for reference\n",
    "    axs[i].plot(\n",
    "        np.arange(len(df_ts_weekly_class_rdi_plot['rolling_perchange']) * 7),\n",
    "        np.zeros(len(df_ts_weekly_class_rdi_plot['rolling_perchange']) * 7),\n",
    "        lw=4, linestyle=':', color='k', zorder=5\n",
    "    )\n",
    "\n",
    "    # Prepare time series for seasonal decomposition\n",
    "    series = pd.DataFrame({\n",
    "        'index': pd.to_datetime(df_ts_weekly['week_start']),\n",
    "        'value': df_ts_weekly_class_rdi[i, :]\n",
    "    })\n",
    "    series.index = series['index']\n",
    "    series = series.drop(['index'], axis=1)\n",
    "\n",
    "    # Apply seasonal decomposition and store trend; skip if fails\n",
    "    try:\n",
    "        result = seasonal_decompose(series, model='additive', extrapolate_trend='freq')\n",
    "        df_trend.loc[i] = result.trend\n",
    "    except:\n",
    "        print('not possible for this ', i)\n",
    "\n",
    "    # Prepare stringency index values for shading\n",
    "    stringencies = [\n",
    "        df_stringency[df_stringency['date'] == date].reset_index(drop=True).loc[0, 'stringency_index']\n",
    "        for date in df_ts['date']\n",
    "    ]\n",
    "\n",
    "    ymin = int(min([-100, np.min(df_ts_weekly_class_rdi)]))\n",
    "    try:\n",
    "        ymax = int(max([101, np.max([val for val in df_ts_weekly_class_rdi.flatten() if val < np.max(df_ts_weekly_class_rdi)]) + 1]))\n",
    "    except:\n",
    "        ymax = 101\n",
    "\n",
    "    # Add shaded background reflecting stringency levels\n",
    "    for l in range(len(df_ts)):\n",
    "        try:\n",
    "            rgba = matplotlib.cm.gray(1 - (stringencies[l] - min(stringencies)) / max(stringencies))\n",
    "        except:\n",
    "            rgba = matplotlib.cm.gray(1 - (stringencies[l - 1] - min(stringencies)) / max(stringencies))\n",
    "        x = [l - 0.50, l + 0.50]\n",
    "        axs[i].fill_between(x, ymin, ymax, color=rgba, alpha=0.4, edgecolor='None', linewidth=0, zorder=0)\n",
    "\n",
    "    # Define x-axis ticks and labels\n",
    "    xticks = [l for l in range(0, len(df_ts['rolling_perchange'])) if l % 183 == 0]\n",
    "    xticks_labels = ['Apr 2020', 'Oct 2020', 'Apr 2021', 'Oct 2021', 'Apr 2022']\n",
    "    axs[i].set_xticks(xticks, xticks_labels)\n",
    "    axs[i].tick_params(axis='x', bottom=True, labelsize=35, pad=10, rotation=90)\n",
    "\n",
    "    # Define y-axis ticks and draw grid lines\n",
    "    yticks = [l for l in range(ymin, ymax) if l % 50 == 0]\n",
    "    axs[i].set_yticks(yticks, yticks)\n",
    "    for y in yticks:\n",
    "        axs[i].plot([0, len(df_ts['rolling_perchange'])], [y, y], color='gray', lw=1.5, zorder=0)\n",
    "    axs[i].tick_params(axis='y', labelsize=40, pad=10, rotation=0)\n",
    "\n",
    "# Uncomment to save figure\n",
    "# plt.savefig(wd + '/plots/evolution/' + flows + '/by-rdi/' + country_short + '/evo' + dist + raw + adjust + '_by_origin.pdf', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b3e732",
   "metadata": {},
   "source": [
    "# Transforming the trend DataFrame to long format and saving it as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28eeb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare lists to convert wide-format df_trend into long-format DataFrame\n",
    "time = []\n",
    "cat = []\n",
    "y = []\n",
    "\n",
    "# Iterate over rows and columns of df_trend to reshape data\n",
    "for i in range(len(df_trend)):\n",
    "    for j in range(len(df_trend.columns)):\n",
    "        time.append(j)               # time index (column position)\n",
    "        cat.append(i)                # category (row index)\n",
    "        y.append(df_trend.loc[i, df_trend.columns[j]])  # trend value\n",
    "\n",
    "# Create long-format DataFrame suitable for analysis or plotting\n",
    "df_trend_long = pd.DataFrame({'time': time, 'cat': cat, 'y': y})\n",
    "\n",
    "# Save to CSV file\n",
    "df_trend_long.to_csv(wd + '/data/outputs/' + country_short + '/mov-analysis/by-rdi/data_trend_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ce75d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
